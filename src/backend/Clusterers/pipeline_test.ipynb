{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import itertools\n",
    "from chromadb.utils import embedding_functions\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from utils.helper_functions import clean_code\n",
    "from Clusterers.title_generator import TitleGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ryounis/Documents/Zurich/PEACHLab/backend/data/disaster_tweet_test_2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data from JSON file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ryounis/Documents/Zurich/PEACHLab/backend/data/disaster_tweet_test_2.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      4\u001b[0m cells \u001b[38;5;241m=\u001b[39m [cell \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m cell[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cell[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of cells: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cells)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ryounis/Documents/Zurich/PEACHLab/backend/data/disaster_tweet_test_2.json'"
     ]
    }
   ],
   "source": [
    "# Load data from JSON file\n",
    "file_path = '/home/ryounis/Documents/Zurich/PEACHLab/backend/data/disaster_tweet_test_2.json'\n",
    "with open(file_path, 'r') as file: data = json.load(file)\n",
    "cells = [cell for cell in data[\"cells\"] if cell[\"cell_type\"] == \"code\" and len(cell[\"source\"])]\n",
    "print(f\"Number of cells: {len(cells)}\")\n",
    "cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(code: str, summary: str = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Embeddes the given code and summary (if provided).\n",
    "\n",
    "    Args:\n",
    "        code (str): The code to be embedded.\n",
    "        summary (str, optional): An NL-summary of the code for better embedding. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The tokenized code and summary (if provided) embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    code_tokens = _tokenizer.tokenize(code)\n",
    "    # code_tokens = [] # TODO\n",
    "    tokens = []\n",
    "    if summary:\n",
    "        nl_tokens = _tokenizer.tokenize(summary)\n",
    "        tokens = [_tokenizer.cls_token] + nl_tokens + [_tokenizer.sep_token]\n",
    "    tokens += code_tokens + [_tokenizer.eos_token]\n",
    "    tokens_ids = _tokenizer.convert_tokens_to_ids(tokens)\n",
    "    context_embeddings = _model(torch.tensor(tokens_ids)[None,:].to(device))[0]\n",
    "    return context_embeddings.detach().numpy().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "_model.to(device)\n",
    "\n",
    "def process_code(code_str, max_length=512, stride=256):\n",
    "    # Tokenization with chunking for long code strings\n",
    "    tokens = _tokenizer(code_str, return_tensors='pt', max_length=max_length, stride=stride, truncation=True).to(device)\n",
    "    \n",
    "    outputs = []\n",
    "    for i in range(0, tokens.input_ids.size(1), stride):\n",
    "        chunk = tokens.input_ids[:, i:i + max_length]\n",
    "        attention_mask_chunk = tokens.attention_mask[:, i:i + max_length]\n",
    "        output_chunk = _model(chunk, attention_mask=attention_mask_chunk)[0]\n",
    "        outputs.append(torch.mean(output_chunk, dim=1))  # Average over the sequence length\n",
    "    \n",
    "    # Average across all chunks\n",
    "    final_output = torch.mean(torch.stack(outputs), dim=0)\n",
    "    return final_output\n",
    "\n",
    "def process_summary(summary_str):\n",
    "    # Tokenization without chunking for short summary strings\n",
    "    tokens = _tokenizer(summary_str, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    # Directly pass through the model\n",
    "    outputs = _model(**tokens)\n",
    "    summary_output = torch.mean(outputs.last_hidden_state, dim=1)  # Average over the sequence length\n",
    "    return summary_output\n",
    "\n",
    "def embed_cell(code_str: str, desc_str: str):\n",
    "    code_embedding = process_code(code_str)\n",
    "    desc_embedding = process_summary(desc_str)\n",
    "    return torch.mean(torch.stack([code_embedding, desc_embedding]), dim=0).detach().numpy().reshape(-1).tolist()\n",
    "\n",
    "# Example inputs\n",
    "code_str = \"Your long code snippet here...\"\n",
    "summary_str = \"A brief summary of the code.\"\n",
    "\n",
    "# Process the code and summary separately\n",
    "code_embedding = process_code(code_str)  # This should return [1, 768]\n",
    "summary_embedding = process_summary(summary_str)  # This should return [1, 768]\n",
    "\n",
    "# Combine the embeddings if needed (e.g., by concatenating or averaging)\n",
    "final_embedding = torch.mean(torch.stack([code_embedding, summary_embedding]), dim=0)\n",
    "\n",
    "# final_embedding now contains the combined representation\n",
    "print(final_embedding.shape)  # Should be [1, 768]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.helper_functions import clean_code\n",
    "import numpy as np\n",
    "\n",
    "idx = 5\n",
    "code = cells[idx][\"source\"]\n",
    "desc = cells[idx][\"metadata\"][\"desc\"]\n",
    "embedding = embed_cell(code, desc)\n",
    "np.array(embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [01:51<00:00,  7.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for cell in tqdm(cells):\n",
    "    cell[\"metadata\"][\"embeddings\"] = embed_cell(clean_code(cell[\"source\"]), cell[\"metadata\"][\"desc\"])\n",
    "\n",
    "new_file_path = \"/home/ryounis/Documents/Zurich/PEACHLab/backend/data/embedded_disaster_tweets3.json\"\n",
    "with open(new_file_path, \"w\") as file: json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_path = \"/home/ryounis/Documents/Zurich/PEACHLab/backend/data/embedded_disaster_tweets2.json\"\n",
    "with open(new_file_path, \"r\") as file: data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [cell[\"metadata\"][\"embeddings\"] for cell in data[\"cells\"] if cell[\"cell_type\"] == \"code\" and len(cell[\"source\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Export: 44\n",
      "Data Export: 3\n",
      "\n",
      "Data Extraction: 66\n",
      "Data Extraction: 5\n",
      "\n",
      "Data Transform: 271\n",
      "Data Transform: 16\n",
      "\n",
      "Debug: 10\n",
      "Debug: 1\n",
      "\n",
      "Environment: 74\n",
      "Environment: 5\n",
      "\n",
      "Exploratory Data Analysis: 94\n",
      "Exploratory Data Analysis: 5\n",
      "\n",
      "Hyperparam Tuning: 16\n",
      "Hyperparam Tuning: 3\n",
      "\n",
      "Model Evaluation: 39\n",
      "Model Evaluation: 3\n",
      "\n",
      "Model Interpretation: 20\n",
      "Model Interpretation: 4\n",
      "\n",
      "Model Train: 71\n",
      "Model Train: 6\n",
      "\n",
      "Other: 31\n",
      "Other: 2\n",
      "\n",
      "Visualization: 67\n",
      "Visualization: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "clusterer = HDBSCAN(\n",
    "    min_cluster_size=4,\n",
    "    min_samples=4,\n",
    "    cluster_selection_epsilon=.1,\n",
    "    max_cluster_size=None,\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "clusters = {}\n",
    "# grouped_cells = itertools.groupby(cells, lambda x: x[\"metadata\"][\"class\"])\n",
    "grouped_cells = {k: list(v) for k, v in itertools.groupby(cells, lambda x: x[\"metadata\"][\"class\"])}\n",
    "for key, group in grouped_cells.items(): \n",
    "    print(f\"{key}: {len(group)}\")\n",
    "    X = [cell[\"metadata\"][\"embeddings\"] for cell in group]\n",
    "    clusterer.fit(X)\n",
    "    clusters[key] = clusterer.labels_\n",
    "    print(f\"{key}: {len(set(clusterer.labels_))}\\n\")\n",
    "\n",
    "    for i, cluster in enumerate(clusterer.labels_):\n",
    "        group[i][\"metadata\"][\"cluster\"] = cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data Export': array([ 0, -1, -1, -1,  0,  0,  0, -1, -1,  0, -1,  0,  1, -1,  1, -1, -1,\n",
       "         1,  1,  0, -1,  0,  0,  1, -1,  1, -1,  1,  0, -1,  1,  0, -1,  0,\n",
       "        -1, -1,  1,  1, -1,  1,  0, -1, -1,  1]),\n",
       " 'Data Extraction': array([ 2, -1,  2,  2,  1,  2,  3,  1,  2,  1,  2, -1,  2,  0, -1,  1, -1,\n",
       "         2,  2,  2,  3,  2,  0,  1, -1,  3,  2, -1, -1, -1, -1, -1, -1, -1,\n",
       "         2, -1, -1, -1,  2,  1,  3,  3,  1, -1, -1,  2,  0,  1,  3,  2,  0,\n",
       "         1,  3, -1, -1, -1,  3,  3,  3,  3, -1,  2, -1,  2, -1,  2]),\n",
       " 'Data Transform': array([-1, -1, -1,  8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  7, -1,  7,\n",
       "        -1,  7,  7, -1, -1, -1, -1, -1, -1, 12, -1, -1, -1,  8,  0, -1, -1,\n",
       "        -1,  9, 10,  2, -1, -1, -1, -1,  4, -1, -1, -1, -1, -1, -1, 12, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1,  8, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, 12, 12, -1, 11,  6, 11,  6,  8,  6, 11,  6, -1, -1, -1, -1,\n",
       "        -1, -1, 12,  1,  9, 10, -1,  2, -1, -1,  8, -1, -1, -1, -1, -1, -1,\n",
       "        -1,  8, -1, -1, -1, -1, -1, -1,  3,  0,  8, -1, -1, -1, -1,  0, -1,\n",
       "        -1, 11,  6, 11,  6,  8,  6, -1,  6, -1, 12,  1,  9, 10,  2,  0,  8,\n",
       "        -1, -1,  3, -1, -1, -1, -1, -1, -1, -1, -1,  0,  8, -1, 12,  1,  9,\n",
       "        10,  2, -1, -1, -1, -1,  9, 13, 14, 13, 14, 13, 14, 13, 14, -1, 14,\n",
       "        10, -1, 12, -1,  3, 12, -1, 12, -1, 11,  5, 11,  5,  8,  5, 11,  5,\n",
       "        -1, -1, 12,  1,  9, 10,  2, -1, 12, -1, -1, 11,  6, 11,  6,  8,  6,\n",
       "        -1,  6, -1, 12,  1,  9, 10,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         3, -1, -1, -1,  1, -1, -1, -1, -1, -1,  9, -1, -1, 12, 12,  9, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, 12,  8, 12, -1, 12,  9, -1, -1, -1, -1,\n",
       "         4, -1,  4, 11,  4, -1, -1, -1, -1,  4, -1,  9, -1, -1, -1, -1]),\n",
       " 'Debug': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
       " 'Environment': array([ 2,  3,  0, -1,  0, -1,  1, -1,  3,  3, -1,  2, -1, -1, -1,  0,  2,\n",
       "        -1, -1,  2, -1, -1, -1, -1,  1, -1, -1,  0, -1, -1, -1, -1, -1,  2,\n",
       "        -1,  2, -1, -1,  3, -1,  3, -1,  2, -1, -1, -1, -1,  0,  2,  3,  0,\n",
       "         3,  2, -1,  2,  0,  2, -1,  0, -1, -1, -1, -1, -1, -1,  3, -1, -1,\n",
       "         1, -1,  1,  3,  2,  2]),\n",
       " 'Exploratory Data Analysis': array([ 2,  2,  2,  2,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  0,\n",
       "        -1,  0, -1,  3,  2,  1,  2, -1,  2,  2,  2,  1,  2,  3,  2,  2,  2,\n",
       "         2,  2, -1, -1, -1,  2,  0, -1,  2,  1,  2,  2,  2,  1,  0,  1,  0,\n",
       "         1, -1,  2,  2,  2,  2,  2,  2,  2, -1, -1,  3,  3, -1,  2,  3,  2,\n",
       "         3,  2,  2, -1, -1,  2,  3,  2,  3, -1, -1, -1, -1,  2,  2,  2,  2,\n",
       "         2, -1, -1,  0,  1,  1,  1,  1,  1]),\n",
       " 'Hyperparam Tuning': array([ 0, -1, -1,  0, -1,  1,  1,  1, -1, -1, -1, -1,  0,  0,  1,  1]),\n",
       " 'Model Evaluation': array([ 0,  0, -1,  0, -1,  0, -1,  0,  0, -1,  0,  0, -1, -1,  1, -1, -1,\n",
       "         0,  0,  0,  0,  0, -1, -1, -1,  0,  0,  1,  1,  1, -1, -1,  1, -1,\n",
       "         0, -1,  0,  1,  1]),\n",
       " 'Model Interpretation': array([ 1, -1,  2,  2,  2,  1,  1,  1,  1,  2,  0,  0,  0,  0,  1,  1,  2,\n",
       "         2,  2,  2]),\n",
       " 'Model Train': array([-1,  3,  0,  2, -1, -1,  2,  4,  2,  0,  0,  2,  2,  2, -1,  1, -1,\n",
       "        -1, -1, -1,  2,  2, -1,  0,  0,  2, -1, -1, -1, -1, -1, -1,  2,  2,\n",
       "         4, -1, -1, -1,  2, -1, -1,  2,  1, -1,  2,  3,  1,  3,  1,  3,  1,\n",
       "         3,  2,  2,  2,  2, -1,  2,  4,  2,  4, -1, -1,  2,  2, -1,  2,  2,\n",
       "        -1,  2,  2]),\n",
       " 'Other': array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 'Visualization': array([-1, -1, -1, -1, -1,  2,  2,  2,  2, -1,  1,  1,  1,  1, -1,  1, -1,\n",
       "        -1, -1, -1, -1,  0,  0,  0, -1,  0,  0, -1, -1, -1, -1,  2,  2,  2,\n",
       "        -1,  1,  1,  1, -1,  1, -1,  2,  2,  2,  1,  1,  1,  1, -1,  1, -1,\n",
       "        -1, -1,  2,  2,  2,  2,  2,  2, -1,  2,  2,  2,  2, -1, -1,  2])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': None,\n",
       " 'metadata': {'start_cell': True,\n",
       "  'cell_id': 14,\n",
       "  'class': 'Data Export',\n",
       "  'subclass': 'save_to_csv',\n",
       "  'subclass_id': 25,\n",
       "  'predicted_subclass_probability': 0.999161,\n",
       "  'notebook_id': 2,\n",
       "  'desc': 'This code exports the preprocessed training and testing datasets to CSV files.',\n",
       "  'embeddings': [-0.29024219512939453,\n",
       "   0.40751779079437256,\n",
       "   0.2908839285373688,\n",
       "   0.09821147471666336,\n",
       "   -0.1225736066699028,\n",
       "   -0.220683291554451,\n",
       "   -0.10773362219333649,\n",
       "   0.21706432104110718,\n",
       "   0.26601797342300415,\n",
       "   0.41933661699295044,\n",
       "   -0.27640753984451294,\n",
       "   0.7368866205215454,\n",
       "   -0.11890184879302979,\n",
       "   -0.31496381759643555,\n",
       "   0.6846251487731934,\n",
       "   0.07755774259567261,\n",
       "   0.34362536668777466,\n",
       "   0.42988091707229614,\n",
       "   0.00030302442610263824,\n",
       "   0.1580064594745636,\n",
       "   -0.20486080646514893,\n",
       "   -0.02505023404955864,\n",
       "   0.5175704956054688,\n",
       "   -0.6334050297737122,\n",
       "   0.15057049691677094,\n",
       "   0.4327700436115265,\n",
       "   -0.2546074390411377,\n",
       "   0.6430734992027283,\n",
       "   -0.5093332529067993,\n",
       "   0.8320399522781372,\n",
       "   -0.38636326789855957,\n",
       "   0.08831711113452911,\n",
       "   1.514847993850708,\n",
       "   -0.012588217854499817,\n",
       "   0.4583745002746582,\n",
       "   -0.3554568290710449,\n",
       "   -0.41892650723457336,\n",
       "   0.16224540770053864,\n",
       "   -0.1374051868915558,\n",
       "   -0.3604363799095154,\n",
       "   -0.14945529401302338,\n",
       "   0.5921176075935364,\n",
       "   -1.1133315563201904,\n",
       "   0.0012261532247066498,\n",
       "   0.5087770819664001,\n",
       "   0.44554975628852844,\n",
       "   0.3128158152103424,\n",
       "   -0.30668458342552185,\n",
       "   -0.15981270372867584,\n",
       "   0.4732167720794678,\n",
       "   0.6486190557479858,\n",
       "   0.30858826637268066,\n",
       "   -0.5734175443649292,\n",
       "   -0.2835956811904907,\n",
       "   0.5510627627372742,\n",
       "   0.5025690197944641,\n",
       "   -1.1296151876449585,\n",
       "   -0.525294840335846,\n",
       "   -0.3576141595840454,\n",
       "   -0.2724704444408417,\n",
       "   0.04292851686477661,\n",
       "   -0.37209606170654297,\n",
       "   -0.18320046365261078,\n",
       "   -0.3139379322528839,\n",
       "   1.4128986597061157,\n",
       "   0.367584764957428,\n",
       "   0.48867082595825195,\n",
       "   0.7892484664916992,\n",
       "   -0.1223580539226532,\n",
       "   0.31443125009536743,\n",
       "   -0.3276286721229553,\n",
       "   -0.568489670753479,\n",
       "   -0.2100622057914734,\n",
       "   -0.5496554374694824,\n",
       "   -0.6958473920822144,\n",
       "   0.5844195485115051,\n",
       "   -0.5128803253173828,\n",
       "   -8.529294967651367,\n",
       "   0.23571914434432983,\n",
       "   0.6977205276489258,\n",
       "   0.2226155698299408,\n",
       "   -0.556797981262207,\n",
       "   1.4510095119476318,\n",
       "   0.5898182392120361,\n",
       "   -0.7283890247344971,\n",
       "   0.046627409756183624,\n",
       "   -0.1597989946603775,\n",
       "   0.40051835775375366,\n",
       "   -0.7704702615737915,\n",
       "   -0.2380521297454834,\n",
       "   0.41316482424736023,\n",
       "   0.2203940451145172,\n",
       "   0.5946130752563477,\n",
       "   0.2318304032087326,\n",
       "   -0.2919764220714569,\n",
       "   0.7669386267662048,\n",
       "   0.6046154499053955,\n",
       "   -0.4017260670661926,\n",
       "   0.2535792887210846,\n",
       "   -0.3278423845767975,\n",
       "   -0.020395278930664062,\n",
       "   -0.5234982967376709,\n",
       "   0.7248178720474243,\n",
       "   0.3677886426448822,\n",
       "   0.30712705850601196,\n",
       "   -0.9319329261779785,\n",
       "   0.496709942817688,\n",
       "   -0.6593371033668518,\n",
       "   0.3334487974643707,\n",
       "   -9.020417928695679e-05,\n",
       "   0.2956662178039551,\n",
       "   -0.5850872993469238,\n",
       "   0.6038326621055603,\n",
       "   0.25312894582748413,\n",
       "   0.22767186164855957,\n",
       "   -0.48818498849868774,\n",
       "   0.17709633708000183,\n",
       "   0.05439303442835808,\n",
       "   0.0058256834745407104,\n",
       "   -0.25075972080230713,\n",
       "   -0.713779628276825,\n",
       "   0.39884042739868164,\n",
       "   -0.2973235845565796,\n",
       "   1.0497069358825684,\n",
       "   -0.40255415439605713,\n",
       "   0.46620070934295654,\n",
       "   -0.1948142945766449,\n",
       "   0.0516473762691021,\n",
       "   0.3552950620651245,\n",
       "   0.37434589862823486,\n",
       "   -1.0797436237335205,\n",
       "   -0.41000258922576904,\n",
       "   -0.27907660603523254,\n",
       "   0.9504514336585999,\n",
       "   0.5313899517059326,\n",
       "   -0.5624892711639404,\n",
       "   0.5681574940681458,\n",
       "   0.07693330198526382,\n",
       "   -0.4919549524784088,\n",
       "   0.4868689179420471,\n",
       "   -0.44879502058029175,\n",
       "   -0.3342834711074829,\n",
       "   0.08243519812822342,\n",
       "   -0.018307074904441833,\n",
       "   0.7118057012557983,\n",
       "   -0.05811401456594467,\n",
       "   0.13493609428405762,\n",
       "   0.5530945062637329,\n",
       "   0.45422255992889404,\n",
       "   -0.3703359365463257,\n",
       "   -0.8891619443893433,\n",
       "   -0.05986775830388069,\n",
       "   1.3042240142822266,\n",
       "   -0.280748188495636,\n",
       "   -0.07203909754753113,\n",
       "   -1.5858724117279053,\n",
       "   0.02846509963274002,\n",
       "   0.47446954250335693,\n",
       "   0.34054744243621826,\n",
       "   -0.5020866394042969,\n",
       "   0.3688805103302002,\n",
       "   -0.2704102694988251,\n",
       "   -0.2576791048049927,\n",
       "   0.5067882537841797,\n",
       "   0.5073889493942261,\n",
       "   0.3286628723144531,\n",
       "   -0.25825849175453186,\n",
       "   -0.1904643326997757,\n",
       "   0.1383950114250183,\n",
       "   0.9963964223861694,\n",
       "   -0.6015720367431641,\n",
       "   -0.5908052921295166,\n",
       "   -0.5363940596580505,\n",
       "   -0.08664160966873169,\n",
       "   0.33569467067718506,\n",
       "   0.5951507091522217,\n",
       "   0.37254148721694946,\n",
       "   -0.10585197806358337,\n",
       "   -0.31598803400993347,\n",
       "   1.1392333507537842,\n",
       "   0.5605841875076294,\n",
       "   -0.25538912415504456,\n",
       "   0.2598416209220886,\n",
       "   -0.4139859080314636,\n",
       "   -0.39876943826675415,\n",
       "   0.4080255627632141,\n",
       "   -0.4631800055503845,\n",
       "   0.7803601026535034,\n",
       "   -0.24288079142570496,\n",
       "   -0.32593369483947754,\n",
       "   -0.1730947494506836,\n",
       "   -0.12749382853507996,\n",
       "   0.23732119798660278,\n",
       "   0.9980605840682983,\n",
       "   0.03204062581062317,\n",
       "   0.1740790456533432,\n",
       "   0.065067820250988,\n",
       "   0.3281077444553375,\n",
       "   0.6636852025985718,\n",
       "   0.2236834615468979,\n",
       "   -0.39840319752693176,\n",
       "   0.5473984479904175,\n",
       "   0.48460766673088074,\n",
       "   0.4267837405204773,\n",
       "   -0.10614077001810074,\n",
       "   0.2268865406513214,\n",
       "   -0.31313472986221313,\n",
       "   0.4915107488632202,\n",
       "   0.4065812826156616,\n",
       "   1.311834692955017,\n",
       "   1.7039936780929565,\n",
       "   -0.17770075798034668,\n",
       "   0.14519335329532623,\n",
       "   -0.24603040516376495,\n",
       "   -0.6778858304023743,\n",
       "   0.1233346089720726,\n",
       "   -0.7861708402633667,\n",
       "   -1.3748517036437988,\n",
       "   -0.4047152101993561,\n",
       "   0.0974358469247818,\n",
       "   -1.43357253074646,\n",
       "   0.25245964527130127,\n",
       "   -0.2896970510482788,\n",
       "   -0.26662346720695496,\n",
       "   0.06297651678323746,\n",
       "   -0.11095329374074936,\n",
       "   0.3979724049568176,\n",
       "   -0.11141546070575714,\n",
       "   -0.3345201313495636,\n",
       "   0.3384011387825012,\n",
       "   -0.42252957820892334,\n",
       "   -0.03977430239319801,\n",
       "   -0.7580562829971313,\n",
       "   -0.2501847743988037,\n",
       "   -0.2001984417438507,\n",
       "   -0.2664741575717926,\n",
       "   -0.329054057598114,\n",
       "   0.2535419464111328,\n",
       "   0.4510338306427002,\n",
       "   -0.9845678806304932,\n",
       "   -0.3086892366409302,\n",
       "   0.18047378957271576,\n",
       "   0.5753234028816223,\n",
       "   0.7394928932189941,\n",
       "   0.1994227170944214,\n",
       "   -0.45560455322265625,\n",
       "   0.33216163516044617,\n",
       "   0.13675086200237274,\n",
       "   0.6071063280105591,\n",
       "   0.5778967142105103,\n",
       "   0.22798064351081848,\n",
       "   0.3528215289115906,\n",
       "   0.21022407710552216,\n",
       "   -0.11628250777721405,\n",
       "   0.06209958717226982,\n",
       "   -0.33386513590812683,\n",
       "   -0.36987408995628357,\n",
       "   -0.39001572132110596,\n",
       "   0.8945332765579224,\n",
       "   1.8595784902572632,\n",
       "   0.3922869861125946,\n",
       "   0.3520130515098572,\n",
       "   0.7906022071838379,\n",
       "   -0.48544275760650635,\n",
       "   0.5663855075836182,\n",
       "   -0.17281101644039154,\n",
       "   0.3138545751571655,\n",
       "   0.2719305157661438,\n",
       "   0.5373979210853577,\n",
       "   0.4551928639411926,\n",
       "   1.5714521408081055,\n",
       "   0.4461304247379303,\n",
       "   -0.2518191337585449,\n",
       "   0.36378976702690125,\n",
       "   0.2676403522491455,\n",
       "   0.20420967042446136,\n",
       "   0.4657531976699829,\n",
       "   0.3225680887699127,\n",
       "   -0.8517271280288696,\n",
       "   -0.2677176892757416,\n",
       "   -0.5249148011207581,\n",
       "   -0.5405298471450806,\n",
       "   0.48126304149627686,\n",
       "   -0.10987453162670135,\n",
       "   -0.32332444190979004,\n",
       "   -0.3064982295036316,\n",
       "   0.5251582264900208,\n",
       "   0.6854435205459595,\n",
       "   0.11977879703044891,\n",
       "   -0.3792625069618225,\n",
       "   0.4181634187698364,\n",
       "   -0.48290854692459106,\n",
       "   0.9351484775543213,\n",
       "   -0.02939101867377758,\n",
       "   -0.3740417957305908,\n",
       "   0.19217708706855774,\n",
       "   0.3565766215324402,\n",
       "   0.7199720144271851,\n",
       "   0.3143325746059418,\n",
       "   -0.537794291973114,\n",
       "   0.27921178936958313,\n",
       "   0.08928072452545166,\n",
       "   -0.25031381845474243,\n",
       "   0.3341587781906128,\n",
       "   -0.32059812545776367,\n",
       "   -0.40220898389816284,\n",
       "   -0.41303062438964844,\n",
       "   0.41503435373306274,\n",
       "   0.29633259773254395,\n",
       "   -0.04543672874569893,\n",
       "   0.2699349522590637,\n",
       "   -1.0777024030685425,\n",
       "   -0.18706688284873962,\n",
       "   -0.1580665111541748,\n",
       "   0.40048927068710327,\n",
       "   -0.486972451210022,\n",
       "   -0.2125011384487152,\n",
       "   0.2980654239654541,\n",
       "   -0.416959673166275,\n",
       "   0.3209169805049896,\n",
       "   0.4422430992126465,\n",
       "   -0.3076217770576477,\n",
       "   0.9964114427566528,\n",
       "   -0.8785157203674316,\n",
       "   0.7401823997497559,\n",
       "   0.6025121808052063,\n",
       "   -0.6615858674049377,\n",
       "   -0.7857392430305481,\n",
       "   -1.6957428455352783,\n",
       "   0.07728990167379379,\n",
       "   -0.5387005805969238,\n",
       "   1.5615429878234863,\n",
       "   0.4253973364830017,\n",
       "   1.454848051071167,\n",
       "   -0.8666501641273499,\n",
       "   -0.47444888949394226,\n",
       "   0.49529534578323364,\n",
       "   -0.3319462537765503,\n",
       "   0.012456722557544708,\n",
       "   -0.49555420875549316,\n",
       "   -1.1553008556365967,\n",
       "   0.6016534566879272,\n",
       "   0.2646815776824951,\n",
       "   -0.26055610179901123,\n",
       "   0.1851455271244049,\n",
       "   0.8385584354400635,\n",
       "   -0.3855677545070648,\n",
       "   0.1486896276473999,\n",
       "   1.376471996307373,\n",
       "   0.5216208696365356,\n",
       "   -0.6041885614395142,\n",
       "   -0.8785303831100464,\n",
       "   -0.49305659532546997,\n",
       "   -0.45789816975593567,\n",
       "   0.35591068863868713,\n",
       "   1.939478874206543,\n",
       "   0.6884524822235107,\n",
       "   0.14376243948936462,\n",
       "   0.23369865119457245,\n",
       "   -0.7033928632736206,\n",
       "   0.003435768187046051,\n",
       "   0.04699719697237015,\n",
       "   0.2987937331199646,\n",
       "   1.972907543182373,\n",
       "   0.7185498476028442,\n",
       "   -0.0030638277530670166,\n",
       "   -1.0516951084136963,\n",
       "   0.1464669555425644,\n",
       "   -0.23314106464385986,\n",
       "   0.3618261218070984,\n",
       "   -0.14350226521492004,\n",
       "   -0.1271379292011261,\n",
       "   0.16004012525081635,\n",
       "   0.7895209789276123,\n",
       "   0.3014247417449951,\n",
       "   -0.23425397276878357,\n",
       "   0.5067489147186279,\n",
       "   -0.40997883677482605,\n",
       "   0.23147708177566528,\n",
       "   0.04901533201336861,\n",
       "   -0.45262569189071655,\n",
       "   0.3553241789340973,\n",
       "   0.2208581268787384,\n",
       "   -0.12123635411262512,\n",
       "   0.578529953956604,\n",
       "   -1.671006679534912,\n",
       "   0.626244306564331,\n",
       "   -0.35558098554611206,\n",
       "   1.2242629528045654,\n",
       "   -0.05507946386933327,\n",
       "   0.12456083297729492,\n",
       "   0.08651360124349594,\n",
       "   0.30451154708862305,\n",
       "   -0.4375251531600952,\n",
       "   -0.16005444526672363,\n",
       "   0.47461649775505066,\n",
       "   -0.13627703487873077,\n",
       "   0.14047397673130035,\n",
       "   -0.16890379786491394,\n",
       "   -0.6893888711929321,\n",
       "   -0.4646201431751251,\n",
       "   0.13145363330841064,\n",
       "   -0.26023560762405396,\n",
       "   0.05388424172997475,\n",
       "   -0.27243515849113464,\n",
       "   0.20993831753730774,\n",
       "   0.03462730348110199,\n",
       "   -0.09212476015090942,\n",
       "   -0.33555129170417786,\n",
       "   1.0509380102157593,\n",
       "   -0.4985751509666443,\n",
       "   1.72245454788208,\n",
       "   -0.33716580271720886,\n",
       "   0.160964235663414,\n",
       "   -0.14120642840862274,\n",
       "   0.2893678545951843,\n",
       "   0.5416901111602783,\n",
       "   -0.9510120749473572,\n",
       "   0.25800296664237976,\n",
       "   0.38122206926345825,\n",
       "   0.30435502529144287,\n",
       "   0.2219069004058838,\n",
       "   0.6493780612945557,\n",
       "   -0.5221644639968872,\n",
       "   0.5961600542068481,\n",
       "   -0.09782552719116211,\n",
       "   0.13990715146064758,\n",
       "   0.1511741280555725,\n",
       "   -0.7882776856422424,\n",
       "   -0.43651139736175537,\n",
       "   -0.5953502655029297,\n",
       "   0.1505853682756424,\n",
       "   0.14313559234142303,\n",
       "   0.2608290910720825,\n",
       "   -0.6953048706054688,\n",
       "   -0.45789241790771484,\n",
       "   -0.49492335319519043,\n",
       "   -0.08125296980142593,\n",
       "   0.4979651868343353,\n",
       "   0.37983018159866333,\n",
       "   0.3171699345111847,\n",
       "   0.35393548011779785,\n",
       "   0.4080136716365814,\n",
       "   0.48854702711105347,\n",
       "   0.06337197870016098,\n",
       "   0.24730287492275238,\n",
       "   -0.4696502089500427,\n",
       "   1.2637577056884766,\n",
       "   0.5869313478469849,\n",
       "   -0.3375459909439087,\n",
       "   0.2947080731391907,\n",
       "   0.46622395515441895,\n",
       "   0.3030349910259247,\n",
       "   1.1355881690979004,\n",
       "   0.5971701145172119,\n",
       "   -0.4924226403236389,\n",
       "   0.20797514915466309,\n",
       "   -0.1410205215215683,\n",
       "   0.5228136777877808,\n",
       "   0.42515507340431213,\n",
       "   -0.11800545454025269,\n",
       "   0.04554792493581772,\n",
       "   0.36303234100341797,\n",
       "   -0.2616018056869507,\n",
       "   0.326486736536026,\n",
       "   -1.5771163702011108,\n",
       "   0.5887565612792969,\n",
       "   -0.3662680685520172,\n",
       "   0.26671794056892395,\n",
       "   0.14415109157562256,\n",
       "   -0.921930730342865,\n",
       "   0.11612951010465622,\n",
       "   -0.31446191668510437,\n",
       "   -0.6379929780960083,\n",
       "   -0.4761170744895935,\n",
       "   0.0020943358540534973,\n",
       "   -0.3218090534210205,\n",
       "   1.7238399982452393,\n",
       "   0.48296359181404114,\n",
       "   1.5527763366699219,\n",
       "   -0.021184034645557404,\n",
       "   -0.624061107635498,\n",
       "   -0.13862192630767822,\n",
       "   -0.709660530090332,\n",
       "   0.5368750691413879,\n",
       "   0.6044968366622925,\n",
       "   0.008100811392068863,\n",
       "   -0.54336017370224,\n",
       "   -0.03887144476175308,\n",
       "   -0.3649832308292389,\n",
       "   -0.715725839138031,\n",
       "   -0.10320577025413513,\n",
       "   -0.18363434076309204,\n",
       "   0.7341520190238953,\n",
       "   -0.530908465385437,\n",
       "   0.08892175555229187,\n",
       "   -0.0464947372674942,\n",
       "   0.3512435555458069,\n",
       "   -0.2723594307899475,\n",
       "   0.6350224018096924,\n",
       "   -0.12501636147499084,\n",
       "   0.20270243287086487,\n",
       "   0.20902974903583527,\n",
       "   1.459729552268982,\n",
       "   -0.13315534591674805,\n",
       "   0.44508495926856995,\n",
       "   -0.4563896059989929,\n",
       "   1.0013220310211182,\n",
       "   0.5671795606613159,\n",
       "   -0.04800909012556076,\n",
       "   -0.00017631053924560547,\n",
       "   0.5083500146865845,\n",
       "   0.9415615797042847,\n",
       "   0.008245237171649933,\n",
       "   -0.027536708861589432,\n",
       "   0.1869073212146759,\n",
       "   -0.4883020520210266,\n",
       "   -0.6076533794403076,\n",
       "   -0.4608387053012848,\n",
       "   1.810310959815979,\n",
       "   0.4698851704597473,\n",
       "   0.34245288372039795,\n",
       "   -0.29509782791137695,\n",
       "   0.0637972354888916,\n",
       "   1.4179905652999878,\n",
       "   -0.17014539241790771,\n",
       "   -1.020339012145996,\n",
       "   -0.93068528175354,\n",
       "   -0.048292309045791626,\n",
       "   -0.6700253486633301,\n",
       "   -0.8828282952308655,\n",
       "   -0.209167942404747,\n",
       "   0.4483051896095276,\n",
       "   -0.0811583623290062,\n",
       "   0.5855625867843628,\n",
       "   -0.2809688150882721,\n",
       "   -0.21819224953651428,\n",
       "   0.04976373165845871,\n",
       "   -0.09054845571517944,\n",
       "   0.3255693018436432,\n",
       "   -0.38786041736602783,\n",
       "   -0.4303387999534607,\n",
       "   1.5747476816177368,\n",
       "   0.46174055337905884,\n",
       "   0.32269465923309326,\n",
       "   -0.25147882103919983,\n",
       "   -0.5213603377342224,\n",
       "   -1.51600182056427,\n",
       "   -0.30194348096847534,\n",
       "   -0.27312713861465454,\n",
       "   0.35931774973869324,\n",
       "   -0.09725093841552734,\n",
       "   -0.4426657259464264,\n",
       "   -0.1393217146396637,\n",
       "   0.488136887550354,\n",
       "   0.18399080634117126,\n",
       "   -0.2859543561935425,\n",
       "   0.24421703815460205,\n",
       "   -0.06515666842460632,\n",
       "   0.015809131786227226,\n",
       "   -0.5237062573432922,\n",
       "   0.45916008949279785,\n",
       "   0.09665174782276154,\n",
       "   -0.5036344528198242,\n",
       "   0.5062834620475769,\n",
       "   0.19420187175273895,\n",
       "   -0.27439379692077637,\n",
       "   -0.18144486844539642,\n",
       "   0.30711179971694946,\n",
       "   -0.2956518530845642,\n",
       "   -1.801723599433899,\n",
       "   0.5862616896629333,\n",
       "   0.322159081697464,\n",
       "   -0.4712459444999695,\n",
       "   0.5732818841934204,\n",
       "   -0.1943555474281311,\n",
       "   0.6492810249328613,\n",
       "   -0.5321670770645142,\n",
       "   0.3912386894226074,\n",
       "   0.13391631841659546,\n",
       "   0.4014802873134613,\n",
       "   1.3871028423309326,\n",
       "   0.2340160608291626,\n",
       "   0.13372139632701874,\n",
       "   -0.12820965051651,\n",
       "   0.7745894193649292,\n",
       "   0.5102818608283997,\n",
       "   0.4207143187522888,\n",
       "   5.421360969543457,\n",
       "   -0.46713322401046753,\n",
       "   1.3829351663589478,\n",
       "   0.5576758980751038,\n",
       "   0.29908570647239685,\n",
       "   -0.12980018556118011,\n",
       "   -1.062997579574585,\n",
       "   -0.2992095649242401,\n",
       "   -0.3355106711387634,\n",
       "   -0.07894694805145264,\n",
       "   -0.3029620051383972,\n",
       "   0.5989187955856323,\n",
       "   -0.5306985378265381,\n",
       "   -0.30716371536254883,\n",
       "   0.5544519424438477,\n",
       "   -0.6573153734207153,\n",
       "   -0.757636308670044,\n",
       "   0.20084568858146667,\n",
       "   0.08810417354106903,\n",
       "   -0.1725480854511261,\n",
       "   0.2974257469177246,\n",
       "   0.2300686091184616,\n",
       "   0.39852339029312134,\n",
       "   -0.16146109998226166,\n",
       "   0.3816361427307129,\n",
       "   -0.007033256813883781,\n",
       "   0.596980094909668,\n",
       "   0.5128329396247864,\n",
       "   -0.39823949337005615,\n",
       "   -0.32103344798088074,\n",
       "   -0.18489281833171844,\n",
       "   0.7268341183662415,\n",
       "   -0.3248341381549835,\n",
       "   -0.3841012716293335,\n",
       "   -0.5827604532241821,\n",
       "   1.7644426822662354,\n",
       "   0.7402528524398804,\n",
       "   -0.5872052311897278,\n",
       "   0.0014581689611077309,\n",
       "   -1.3957629203796387,\n",
       "   0.46406662464141846,\n",
       "   -0.29112017154693604,\n",
       "   0.3381025791168213,\n",
       "   -0.20981347560882568,\n",
       "   -0.009435631334781647,\n",
       "   -0.13486991822719574,\n",
       "   -0.6590714454650879,\n",
       "   0.4939100444316864,\n",
       "   -0.07872447371482849,\n",
       "   -0.0612405389547348,\n",
       "   0.35685139894485474,\n",
       "   0.6834153532981873,\n",
       "   -0.4995627999305725,\n",
       "   -0.10646674036979675,\n",
       "   0.6066667437553406,\n",
       "   0.31458690762519836,\n",
       "   -0.8463800549507141,\n",
       "   -0.7067728638648987,\n",
       "   -0.8802419900894165,\n",
       "   -0.515379786491394,\n",
       "   0.23466745018959045,\n",
       "   0.7121683359146118,\n",
       "   0.3089342713356018,\n",
       "   -1.0745588541030884,\n",
       "   -0.6601663827896118,\n",
       "   -0.38686609268188477,\n",
       "   -0.4078097343444824,\n",
       "   0.008833887986838818,\n",
       "   0.5188864469528198,\n",
       "   0.28231140971183777,\n",
       "   1.5922510623931885,\n",
       "   0.8940296173095703,\n",
       "   0.4747033417224884,\n",
       "   0.03411756455898285,\n",
       "   -0.11913090944290161,\n",
       "   -0.5100504159927368,\n",
       "   1.2892986536026,\n",
       "   -0.48070240020751953,\n",
       "   0.10336081683635712,\n",
       "   -0.4885874390602112,\n",
       "   -0.33981430530548096,\n",
       "   0.25406450033187866,\n",
       "   -0.8462444543838501,\n",
       "   -0.6170337200164795,\n",
       "   0.416511595249176,\n",
       "   0.15994437038898468,\n",
       "   0.8281225562095642,\n",
       "   0.3333688974380493,\n",
       "   1.512168288230896,\n",
       "   -0.4763142466545105,\n",
       "   0.268063485622406,\n",
       "   -0.1766173243522644,\n",
       "   -0.9672307372093201,\n",
       "   0.21343302726745605,\n",
       "   -0.2122844159603119,\n",
       "   -0.4101507365703583,\n",
       "   -1.400124192237854,\n",
       "   0.18639086186885834,\n",
       "   0.549808144569397,\n",
       "   0.0778917446732521,\n",
       "   0.4908889830112457,\n",
       "   -0.5993396043777466,\n",
       "   0.2635784149169922,\n",
       "   0.11312906444072723,\n",
       "   0.05096885934472084,\n",
       "   -0.7192394137382507,\n",
       "   0.43706753849983215,\n",
       "   -0.5108075141906738,\n",
       "   0.6986860036849976,\n",
       "   0.07266314327716827,\n",
       "   -0.1193382740020752,\n",
       "   -0.4626035690307617,\n",
       "   -0.05101590231060982,\n",
       "   0.28463321924209595,\n",
       "   1.6526594161987305,\n",
       "   -0.36823686957359314,\n",
       "   -0.19141553342342377,\n",
       "   0.567827582359314,\n",
       "   0.2063482403755188,\n",
       "   -0.2498222142457962,\n",
       "   0.5197608470916748,\n",
       "   1.0657291412353516,\n",
       "   -0.3725314140319824,\n",
       "   -0.25927460193634033,\n",
       "   0.32943785190582275,\n",
       "   -0.09287004172801971,\n",
       "   -0.0717921108007431,\n",
       "   -0.28483352065086365,\n",
       "   -0.07828101515769958,\n",
       "   0.6153024435043335,\n",
       "   -0.6045452952384949,\n",
       "   0.4054013788700104,\n",
       "   0.7527740001678467,\n",
       "   1.33371901512146,\n",
       "   0.6461426019668579,\n",
       "   -0.3597521185874939,\n",
       "   -0.6709761619567871,\n",
       "   0.017104094848036766,\n",
       "   0.4630548655986786,\n",
       "   0.37929344177246094,\n",
       "   0.1568533480167389,\n",
       "   -0.4779549837112427,\n",
       "   0.24126215279102325,\n",
       "   0.2370336651802063,\n",
       "   -0.8933465480804443,\n",
       "   -0.48274707794189453,\n",
       "   0.7756105065345764,\n",
       "   0.2361520230770111,\n",
       "   -0.23300448060035706,\n",
       "   -0.31740260124206543,\n",
       "   -0.5669687986373901,\n",
       "   0.43257012963294983,\n",
       "   -0.45325130224227905,\n",
       "   0.7100863456726074,\n",
       "   0.6189151406288147,\n",
       "   -0.48515552282333374,\n",
       "   0.15341046452522278,\n",
       "   1.1045145988464355,\n",
       "   0.08741989731788635,\n",
       "   -0.6333414912223816,\n",
       "   0.5510149002075195,\n",
       "   -1.5481542348861694,\n",
       "   0.24062392115592957,\n",
       "   -0.1603967249393463,\n",
       "   0.9487506151199341,\n",
       "   0.29773029685020447,\n",
       "   0.567672848701477,\n",
       "   -0.15091241896152496,\n",
       "   0.6809021234512329,\n",
       "   -0.28176477551460266,\n",
       "   0.356382817029953,\n",
       "   -0.11558915674686432,\n",
       "   -0.36265087127685547,\n",
       "   0.43868836760520935,\n",
       "   -0.16852779686450958,\n",
       "   0.24997973442077637,\n",
       "   0.5814352035522461,\n",
       "   -0.7407112121582031,\n",
       "   -0.4541146457195282,\n",
       "   0.4964897930622101],\n",
       "  'cluster': -1},\n",
       " 'source': \"train.to_csv('preprocess_train.csv')\\ntest.to_csv('preprocess_test.csv')\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cells\"][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
