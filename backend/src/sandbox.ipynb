{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/ryounis/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: nbformat in /home/ryounis/.local/lib/python3.10/site-packages (5.10.4)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ryounis/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ryounis/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ryounis/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ryounis/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/ryounis/.local/lib/python3.10/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ryounis/.local/lib/python3.10/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/ryounis/.local/lib/python3.10/site-packages (from nbformat) (4.22.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/ryounis/.local/lib/python3.10/site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ryounis/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ryounis/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.18.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ryounis/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ryounis/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (23.2.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ryounis/.local/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import nbformat\n",
    "from typing import List\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_competition(competition_name: str, download_folder: str, verbose: bool = False):\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')\n",
    "    notebooks = []\n",
    "    \n",
    "    if verbose: print(\"Loading notebook names...\")\n",
    "    os.system(f'kaggle kernels list --competition {competition_name} --csv > {download_folder}/notebooks.csv')\n",
    "    df = pd.read_csv(f'{download_folder}/notebooks.csv')\n",
    "    total_notebooks = len(df)\n",
    "    if verbose: print(f\"Downloading {total_notebooks} notebooks...\")\n",
    "    for index, row in df.iterrows():\n",
    "        if verbose: print(f\"{index+1}/{total_notebooks} : {row.iloc[0]}\", end='\\r')\n",
    "        os.system(f'kaggle kernels pull {row.iloc[0]}')\n",
    "    os.remove(f'{download_folder}/notebooks.csv')\n",
    "    for file_name in os.listdir(download_folder):\n",
    "        file_path = os.path.join(download_folder, file_name)\n",
    "        if os.path.isfile(file_path) and file_name.endswith('.ipynb'):\n",
    "            with open(file_path, 'r') as file:\n",
    "                json_object = json.load(file)\n",
    "                notebooks.append(json_object)\n",
    "    return notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading notebook names...\n",
      "Downloading 20 notebooks...\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/multiple-linear-regression.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction-optimized-with-optuna.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction-using-regression.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-predictions-with-82-accuracy.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-probability-prediction.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-probability-prediction-using-regression.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-probability-prediction-using-voting-ensemble.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/on-selecting-features.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/own-created-nn.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/ensemble-model-xgb-lgbm-cbr-xgbrf-ridge.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/test1.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/2-regression-with-a-flood-prediction.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/foold-prediction.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction-using-ann-with-r2-score-0-8448.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction-notebook.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction-featuring-data-eda-xgboost.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/flood-prediction-regression.ipynb\n",
      "Source code downloaded to /home/ryounis/Documents/Zurich/PEACHLab/backend/src/regression-with-a-flood-prediction-dataset.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "notebooks = []\n",
    "COMPETITION = \"playground-series-s4e5\"\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    notebooks = download_competition(COMPETITION, temp_dir, verbose=True)\n",
    "notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./multiple-linear-regression.ipynb'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kaggle\n",
    "import zipfile\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')\n",
    "\n",
    "api = kaggle.api\n",
    "api.get_config_value(\"username\")\n",
    "\n",
    "COMPETITION = \"playground-series-s4e5\"\n",
    "kernels = kaggle.api.kernels_list(\n",
    "    competition=COMPETITION,\n",
    "    page_size=10\n",
    ")\n",
    "kernel_refs = [vars(kernel)[\"ref\"] for kernel in kernels]\n",
    "# kaggle.api.valid_list_output_types\n",
    "\n",
    "kaggle.api.kernels_pull(kernel_refs[0], path=\".\", metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_pull_competiton(competition_name: str, path: str, n_notebooks: int = 20) -> List[dict]:\n",
    "    \"\"\"Download notebooks from a Kaggle competition.\n",
    "\n",
    "    Args:\n",
    "        competition_name (str): The name of the Kaggle competition.\n",
    "        path (str): The path to the folder where the notebooks will be downloaded. It is recommended to use a temporary folder.\n",
    "        n_notebooks (int, optional): The number of notebooks to download. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries representing the downloaded notebooks.\n",
    "    \"\"\"\n",
    "    # Validate kaggle api key\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')\n",
    "    \n",
    "    # Get the list of kernels (notebooks)\n",
    "    kernels = kaggle.api.kernels_list(\n",
    "        competition=COMPETITION,\n",
    "        page_size=10\n",
    "    )\n",
    "    \n",
    "    # Extract the kernel references to be able to pull them from kaggle\n",
    "    kernel_refs = [vars(kernel)[\"ref\"] for kernel in kernels]\n",
    "    \n",
    "    \n",
    "    for kernel_ref in kernel_refs:\n",
    "        # Pull each notebook using its reference\n",
    "        kaggle.api.kernels_pull(kernel_ref, path=path, metadata=False)\n",
    "        notebook_path = f\"{path}/{kernel_ref.split('/')[-1]}.ipynb\"\n",
    "        \n",
    "        with open(notebook_path, 'r') as file:\n",
    "            notebook = json.load(file)\n",
    "            notebooks.append(notebook)\n",
    "    return notebooks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'kernelspec': {'name': 'python3', 'display_name': 'Python 3', 'language': 'python'}, 'language_info': {'name': 'python', 'version': '3.10.13', 'mimetype': 'text/x-python', 'codemirror_mode': {'name': 'ipython', 'version': 3}, 'pygments_lexer': 'ipython3', 'nbconvert_exporter': 'python', 'file_extension': '.py'}, 'kaggle': {'accelerator': 'none', 'dataSources': [{'sourceId': 73278, 'databundleVersionId': 8121328, 'sourceType': 'competition'}], 'dockerImageVersionId': 30746, 'isInternetEnabled': True, 'language': 'python', 'sourceType': 'notebook', 'isGpuEnabled': False}}, 'nbformat_minor': 4, 'nbformat': 4, 'cells': [{'cell_type': 'code', 'source': \"import pandas as pd\\nimport numpy as np\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport plotly.express as px\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import StandardScaler\\nimport statsmodels.api as sm\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\", 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:36.683837Z', 'iopub.execute_input': '2024-07-13T14:46:36.685009Z', 'iopub.status.idle': '2024-07-13T14:46:36.690639Z', 'shell.execute_reply.started': '2024-07-13T14:46:36.684975Z', 'shell.execute_reply': '2024-07-13T14:46:36.689466Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': '### Read thee data\\n', 'metadata': {}}, {'cell_type': 'code', 'source': \"train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv', index_col='id')\\ntest = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv', index_col='id')\\n\", 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:36.69259Z', 'iopub.execute_input': '2024-07-13T14:46:36.692905Z', 'iopub.status.idle': '2024-07-13T14:46:38.825723Z', 'shell.execute_reply.started': '2024-07-13T14:46:36.692878Z', 'shell.execute_reply': '2024-07-13T14:46:38.824632Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': '### EDA\\n', 'metadata': {}}, {'cell_type': 'code', 'source': 'train.head()', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:38.827108Z', 'iopub.execute_input': '2024-07-13T14:46:38.827445Z', 'iopub.status.idle': '2024-07-13T14:46:38.846581Z', 'shell.execute_reply.started': '2024-07-13T14:46:38.827417Z', 'shell.execute_reply': '2024-07-13T14:46:38.845577Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'train.info()', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:38.847992Z', 'iopub.execute_input': '2024-07-13T14:46:38.848401Z', 'iopub.status.idle': '2024-07-13T14:46:38.890352Z', 'shell.execute_reply.started': '2024-07-13T14:46:38.848363Z', 'shell.execute_reply': '2024-07-13T14:46:38.889302Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'def convert_dtype_of_data(data , int64_to, float64_to):\\n    for column in data.columns:\\n        if data[column].dtype == \"int64\":\\n            data[column] = data[column].astype(int64_to)\\n        else:\\n            data[column] = data[column].astype(float64_to)\\n    return data', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:38.893492Z', 'iopub.execute_input': '2024-07-13T14:46:38.893925Z', 'iopub.status.idle': '2024-07-13T14:46:38.90017Z', 'shell.execute_reply.started': '2024-07-13T14:46:38.893889Z', 'shell.execute_reply': '2024-07-13T14:46:38.898998Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'convert_dtype_of_data(train,\"int8\", \"float32\")', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:38.901959Z', 'iopub.execute_input': '2024-07-13T14:46:38.902254Z', 'iopub.status.idle': '2024-07-13T14:46:39.141825Z', 'shell.execute_reply.started': '2024-07-13T14:46:38.902231Z', 'shell.execute_reply': '2024-07-13T14:46:39.140591Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'train.info()', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:39.143265Z', 'iopub.execute_input': '2024-07-13T14:46:39.14415Z', 'iopub.status.idle': '2024-07-13T14:46:39.179962Z', 'shell.execute_reply.started': '2024-07-13T14:46:39.144118Z', 'shell.execute_reply': '2024-07-13T14:46:39.178894Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'print(f\"we have {train.shape[0]} observations and {train.shape[1]} features\")', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:39.181454Z', 'iopub.execute_input': '2024-07-13T14:46:39.181872Z', 'iopub.status.idle': '2024-07-13T14:46:39.187924Z', 'shell.execute_reply.started': '2024-07-13T14:46:39.181833Z', 'shell.execute_reply': '2024-07-13T14:46:39.186927Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': \"From these 21 features we have :\\n\\n- One dependent feature (feature of interest) which is 'FloodProbability': the feature we are trying to estimate\\n- The rest of the features are the independent variables, the variables we are going to use to estimate the 'FloodProbability'\\n\", 'metadata': {}}, {'cell_type': 'code', 'source': 'dependent_feature = train.columns[-1]\\nflood_porb = train[dependent_feature]\\nindependt_features = [test.columns[i] for i in range(len(test.columns[:20]))]\\nprint(f\"The independent variables are {independt_features}\")', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:39.18929Z', 'iopub.execute_input': '2024-07-13T14:46:39.189651Z', 'iopub.status.idle': '2024-07-13T14:46:39.202602Z', 'shell.execute_reply.started': '2024-07-13T14:46:39.189621Z', 'shell.execute_reply': '2024-07-13T14:46:39.201378Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': \"Let's take a look at the variable of interest 'FloodProbability'\\n\", 'metadata': {}}, {'cell_type': 'code', 'source': 'descriptive_statistics = \"\"\\nfor stat_name, value in flood_porb.describe().items():\\n    descriptive_statistics += f\"{stat_name.capitalize()}: {value:.3f}\\\\n\"\\ndescriptive_statistics += f\"Mode: {flood_porb.mode()[0]:.2f}\\\\n\"\\ndescriptive_statistics += f\"Kurtosis: {flood_porb.kurtosis():.2f}\\\\n\"\\ndescriptive_statistics += f\"Skew: {flood_porb.skew():.2f}\\\\n\"\\n\\nprint(descriptive_statistics)', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:39.203922Z', 'iopub.execute_input': '2024-07-13T14:46:39.204263Z', 'iopub.status.idle': '2024-07-13T14:46:39.292717Z', 'shell.execute_reply.started': '2024-07-13T14:46:39.204236Z', 'shell.execute_reply': '2024-07-13T14:46:39.291496Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': 'From these descriptive statistics :\\n- The data ranges from 0.285 to 0.725\\n- We can assume that the distribution of the this variable is near symmetric because the mode, the mean and the median are almost equal around $0.5$ and a skewness of $0.05$ and a kurtosis near $0$, this might suggeest that the data normally distributed\\n\\nWe will investigate that more by using the kernal density estimation plot, i went with kde because of the huge number of observations in the data set and the continuous data type', 'metadata': {}}, {'cell_type': 'code', 'source': 'def kde_plot(data):\\n    plt.figure(figsize=(10, 6))\\n    sns.kdeplot(data, fill=True)\\n    plt.title(\"Density Plot of Traffic Time Series\")\\n    plt.xlabel(\"Traffic\")\\n    plt.ylabel(\"Density\")\\n    return plt.show()\\nkde_plot(flood_porb.sample(120000, random_state=123))', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:39.294382Z', 'iopub.execute_input': '2024-07-13T14:46:39.294711Z', 'iopub.status.idle': '2024-07-13T14:46:40.278611Z', 'shell.execute_reply.started': '2024-07-13T14:46:39.294685Z', 'shell.execute_reply': '2024-07-13T14:46:40.277572Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': 'Now we will take a look at the features', 'metadata': {}}, {'cell_type': 'code', 'source': 'features_df = train[independt_features]\\nfeatures_df.sample(120000, random_state=123).describe()', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:40.280075Z', 'iopub.execute_input': '2024-07-13T14:46:40.280696Z', 'iopub.status.idle': '2024-07-13T14:46:40.538506Z', 'shell.execute_reply.started': '2024-07-13T14:46:40.280665Z', 'shell.execute_reply': '2024-07-13T14:46:40.537375Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': \"# Create subplots\\nfig, axes = plt.subplots(nrows=5, ncols=4, figsize=(12, 10))\\n\\n# Flatten axes for easier iteration\\naxes = axes.flatten()\\n\\n# Iterate over each column in features_df\\nfor i, col in enumerate(features_df.columns):\\n    # Plot histogram for each feature\\n    # sns.histplot(features_df[col].sample(150000, random_state=123), bins=len(features_df[col].unique()), ax=axes[i])\\n    sns.histplot(features_df[col].sample(150000, random_state=123), bins=len(features_df[col].unique()), ax=axes[i])\\n    axes[i].set_title(f'{col}')\\n    axes[i].set_xlabel('')\\n    axes[i].set_ylabel('')\\n\\n# Adjust layout and show plot\\nplt.tight_layout()\\nplt.show()\", 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:40.53979Z', 'iopub.execute_input': '2024-07-13T14:46:40.54013Z', 'iopub.status.idle': '2024-07-13T14:46:47.777331Z', 'shell.execute_reply.started': '2024-07-13T14:46:40.540102Z', 'shell.execute_reply': '2024-07-13T14:46:47.776222Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'plt.figure(figsize=(12,10))\\nsns.heatmap(round((features_df.sample(150000, random_state=123)).corr(), 2), cmap=\"crest\", annot=True, annot_kws={\"fontsize\":10})\\nplt.show()', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:47.780855Z', 'iopub.execute_input': '2024-07-13T14:46:47.781209Z', 'iopub.status.idle': '2024-07-13T14:46:49.288112Z', 'shell.execute_reply.started': '2024-07-13T14:46:47.781179Z', 'shell.execute_reply': '2024-07-13T14:46:49.287108Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': 'As we can see from the heat map: all the features are independent due to the low correlation between variables', 'metadata': {}}, {'cell_type': 'markdown', 'source': 'We will try now to do some dimension reduction to see the variation between variables', 'metadata': {}}, {'cell_type': 'code', 'source': 'standarize = StandardScaler()\\nstandarize.fit(features_df)\\ndf_std = standarize.transform(features_df)', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:49.289431Z', 'iopub.execute_input': '2024-07-13T14:46:49.289797Z', 'iopub.status.idle': '2024-07-13T14:46:49.629723Z', 'shell.execute_reply.started': '2024-07-13T14:46:49.289768Z', 'shell.execute_reply': '2024-07-13T14:46:49.62859Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': '\\npca = PCA(n_components=20,svd_solver = \"auto\")\\npca.fit(df_std)', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:49.630925Z', 'iopub.execute_input': '2024-07-13T14:46:49.631256Z', 'iopub.status.idle': '2024-07-13T14:46:50.701452Z', 'shell.execute_reply.started': '2024-07-13T14:46:49.631226Z', 'shell.execute_reply': '2024-07-13T14:46:50.700279Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': 'pca.explained_variance_ratio_*100', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:50.702819Z', 'iopub.execute_input': '2024-07-13T14:46:50.703185Z', 'iopub.status.idle': '2024-07-13T14:46:50.711011Z', 'shell.execute_reply.started': '2024-07-13T14:46:50.703158Z', 'shell.execute_reply': '2024-07-13T14:46:50.710037Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': '\\nexp_var_cumul = np.cumsum(pca.explained_variance_)\\n\\npx.area(\\n    x=range(1, exp_var_cumul.shape[0] + 1),\\n    y=exp_var_cumul,\\n    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\\n)', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:50.712436Z', 'iopub.execute_input': '2024-07-13T14:46:50.712837Z', 'iopub.status.idle': '2024-07-13T14:46:50.775303Z', 'shell.execute_reply.started': '2024-07-13T14:46:50.712809Z', 'shell.execute_reply': '2024-07-13T14:46:50.774269Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': '- We can see that the first two eigenvalues captures only 10 % of the information of the variation between our 20 features...\\n- So it would be useless to vizualise it this could be to the non linearity of the data', 'metadata': {}}, {'cell_type': 'markdown', 'source': 'We will try to create a linear model to estimate flood probability', 'metadata': {}}, {'cell_type': 'code', 'source': 'features_df = sm.add_constant(features_df)\\nmodel = sm.OLS(train.FloodProbability,features_df).fit()\\nmodel.summary()', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:50.776798Z', 'iopub.execute_input': '2024-07-13T14:46:50.777105Z', 'iopub.status.idle': '2024-07-13T14:46:52.700355Z', 'shell.execute_reply.started': '2024-07-13T14:46:50.777081Z', 'shell.execute_reply': '2024-07-13T14:46:52.699206Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': 'We got a score of 84.49%', 'metadata': {}}, {'cell_type': 'code', 'source': 'model.rsquared*100', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:52.70212Z', 'iopub.execute_input': '2024-07-13T14:46:52.702791Z', 'iopub.status.idle': '2024-07-13T14:46:52.710952Z', 'shell.execute_reply.started': '2024-07-13T14:46:52.702754Z', 'shell.execute_reply': '2024-07-13T14:46:52.709891Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'markdown', 'source': 'Submission CV', 'metadata': {}}, {'cell_type': 'code', 'source': 'predictions = model.predict(sm.add_constant(test[independt_features]))\\npredictions_sub = pd.Series(predictions, index=test.index, name=\"FloodProbability\")\\npredictions_sub', 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:52.712633Z', 'iopub.execute_input': '2024-07-13T14:46:52.713266Z', 'iopub.status.idle': '2024-07-13T14:46:52.958765Z', 'shell.execute_reply.started': '2024-07-13T14:46:52.713224Z', 'shell.execute_reply': '2024-07-13T14:46:52.957343Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}, {'cell_type': 'code', 'source': \"predictions_sub.to_csv('submission.csv')\", 'metadata': {'execution': {'iopub.status.busy': '2024-07-13T14:46:52.960476Z', 'iopub.execute_input': '2024-07-13T14:46:52.96095Z', 'iopub.status.idle': '2024-07-13T14:46:54.617331Z', 'shell.execute_reply.started': '2024-07-13T14:46:52.960907Z', 'shell.execute_reply': '2024-07-13T14:46:54.616242Z'}, 'trusted': True}, 'execution_count': None, 'outputs': []}]}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "COMPETITION = \"playground-series-s4e5\"\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    notebooks = kaggle_pull_competiton(COMPETITION, temp_dir, n_notebooks=5)\n",
    "    print(notebooks[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'kaggle kernels list --competition {COMPETITION} --csv > notebooks.csv')\n",
    "        \n",
    "# Downloading notebooks\t\n",
    "df = pd.read_csv('notebooks.csv')\n",
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
