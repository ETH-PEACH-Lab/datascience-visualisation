{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 0,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 0,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test=pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df=pd.concat([train,test]) #merging the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Visualize the relationships\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='MonsoonIntensity', y='FloodProbability', data=train)\n",
    "plt.title('Monsoon Intensity vs Flood Probability')\n",
    "plt.xlabel('Monsoon Intensity')\n",
    "plt.ylabel('Flood Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='TopographyDrainage', y='FloodProbability', data=train)\n",
    "plt.title('Topography Drainage vs Flood Probability')\n",
    "plt.xlabel('Topography Drainage')\n",
    "plt.ylabel('Flood Probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='RiverManagement', y='FloodProbability', data=train)\n",
    "plt.title('River Management vs Flood Probability')\n",
    "plt.xlabel('River Management')\n",
    "plt.ylabel('Flood Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)['FloodProbability'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x=train.drop(['FloodProbability'],axis=1)\n",
    "y=train['FloodProbability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.drop(['id'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Best Performing Model.\n",
    "lr=LinearRegression()\n",
    "model=lr.fit(x,y)\n",
    "pred=lr.predict(test)\n",
    "submission=pd.DataFrame({'id':test['id'],'FloodProbability':pred})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('flood.pkl','wb'))\n",
    "pickle.dump(df,open('floodprediction.h5','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_columns = list(df.columns[: -1])\n",
    "\n",
    "len(train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "dataset_size = df.shape[0]\n",
    "\n",
    "for feature in train_columns:\n",
    "    feat_val_counts = df[feature].value_counts()\n",
    "    const_count = feat_val_counts[0]\n",
    "    if const_count > 0.1 * dataset_size:\n",
    "        print(f\"feature {feature} has {const_count / dataset_size} constants\")\n",
    "    print(f\"{feature} dtype: {df[feature].dtype}; count of values: {len(feat_val_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df[train_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[train_columns], df[\"FloodProbability\"], test_size=0.33, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, model_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_wsum = df[train_columns].sum(axis=1) * 0.00528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.hist(df[\"FloodProbability\"], label=\"FloodProbability\")\n",
    "plt.hist(df_wsum, alpha=0.5, label=\"Weighted sum of features\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model_catboost_base = CatBoostClassifier(random_seed=random_seed, loss_function=\"CrossEntropy\")\n",
    "\n",
    "model_catboost_base.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, model_catboost_base.predict_proba(X_test)[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model_catboost_feat_select = CatBoostClassifier(random_seed=random_seed, loss_function=\"CrossEntropy\")\n",
    "\n",
    "model_catboost_feat_select.select_features(X_train, y_train, features_for_select=train_columns, num_features_to_select=10, algorithm=\"RecursiveByShapValues\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, model_catboost_feat_select.predict_proba(X_test)[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df['sum'] = df[train_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[train_columns + ['sum']], df[\"FloodProbability\"], test_size=0.33, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model_catboost_sum = CatBoostClassifier(random_seed=random_seed, loss_function=\"CrossEntropy\")\n",
    "\n",
    "model_catboost_sum.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, model_catboost_sum.predict_proba(X_test)[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model_catboost_sum.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Ignore Warnings\n",
    "import warnings\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Transformation\n",
    "from sklearn.preprocessing import  RobustScaler, StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion  # Импорт классов Pipeline и make_pipeline из scikit-learn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # Импорт базовых классов BaseEstimator и TransformerMixin\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (mean_squared_error, make_scorer, r2_score)\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Metrics\n",
    "import math\n",
    "\n",
    "\n",
    "# Regression Algorithms\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "warnings.filterwarnings('ignore')  # Disabling warning outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Path to the CSV data file\n",
    "TRAIN_DATAPATH = '/kaggle/input/playground-series-s4e5/train.csv'\n",
    "TEST_DATAPATH = '/kaggle/input/playground-series-s4e5/test.csv'\n",
    "\n",
    "# # Reading data from the CSV file into a DataFrame\n",
    "train = pd.read_csv(TRAIN_DATAPATH) \n",
    "test = pd.read_csv(TEST_DATAPATH) \n",
    "\n",
    "# Concatenating train and test dataframes along axis 0 (rows) to combine them into a single dataframe.\n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Dropping the 'id' column from the dataframe.\n",
    "df.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Initialize empty lists to store object and non-object columns\n",
    "obj = []\n",
    "ints = []\n",
    "\n",
    "# Loop through DataFrame columns\n",
    "for col in df.columns:\n",
    "    # Check if column data type is object\n",
    "    if df[col].dtype == 'object':\n",
    "        # If object, append column name, unique values count, and count of missing values to 'obj' list\n",
    "        obj.append((col, df[col].nunique(), df[col].isna().sum()))\n",
    "    else:\n",
    "        # If non-object, append column name, unique values count, and count of missing values to 'ints' list\n",
    "        ints.append((col, df[col].nunique(), df[col].isna().sum(), df[col].skew()))\n",
    "\n",
    "# Determine the maximum length of 'obj' and 'ints' lists\n",
    "max_len = max(len(obj), len(ints))\n",
    "\n",
    "# Extend 'obj' and 'ints' lists with empty tuples to match the maximum length\n",
    "obj.extend([('', '', '')] * (max_len - len(obj)))\n",
    "ints.extend([('', '', '', '')] * (max_len - len(ints)))\n",
    "\n",
    "# Create a dictionary with keys representing column categories and values representing lists of corresponding data\n",
    "data = {\n",
    "    'Numeric_columns': [x[0] for x in ints],\n",
    "    'int_cols_uniques': [x[1] for x in ints],\n",
    "    'int_cols_missing': [x[2] for x in ints],\n",
    "    'int_cols_skew': [x[3] for x in ints]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Printing out the column names of the dataframe.\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# This line of code retrieves the shape of the DataFrame 'df'\n",
    "shape = df.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Displaying concise summary information about the DataFrame, including\n",
    "# data types, non-null values, and memory usage\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Displaying the data types of each column in the DataFrame\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of missing values for each column and reset the index, storing the result in a new DataFrame called 'isna'\n",
    "isna = df.isna().sum().reset_index(name=\"missing_values\")\n",
    "\n",
    "# Calculate the percentage of missing values for each column and add it as a new column called 'percentage' in the 'isna' DataFrame\n",
    "isna['percentage'] = round((isna['missing_values'] / df.shape[0]) * 100, 2)\n",
    "\n",
    "# Sort the 'isna' DataFrame by the 'missing_values' column in descending order and display the top 35 rows\n",
    "isna.sort_values(by='missing_values', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Counting the number of duplicated rows in the DataFrame \n",
    "df.duplicated().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the transformed column names\n",
    "new_columns = []\n",
    "\n",
    "# Iterate through the current column names in the DataFrame\n",
    "for j in df.columns.tolist():\n",
    "    # Convert each column name to a list of characters\n",
    "    col = list(j)\n",
    "    \n",
    "    # Find the indices of uppercase characters (excluding the first character) to insert underscores\n",
    "    upper_case_indices = [index for index, char in enumerate(j) if char.isupper() and index != 0]\n",
    "    \n",
    "    # Iterate through the uppercase indices in reverse order and insert underscores\n",
    "    for snake in reversed(upper_case_indices):\n",
    "        col.insert(snake, '_')\n",
    "    \n",
    "    # Join the characters back together to form the transformed column name and append it to the new_columns list\n",
    "    new_columns.append(''.join(col))\n",
    "\n",
    "# Assign the transformed column names to the DataFrame's columns attribute\n",
    "df.columns = new_columns\n",
    "\n",
    "# Convert all column names to lowercase\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "\n",
    "# Displaying the first few rows of the dataframe.\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for all numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Select numerical columns from the DataFrame\n",
    "numerics = df.select_dtypes(include=np.number)\n",
    "\n",
    "# Calculate the number of plots, rows, and columns for subplots\n",
    "num_plots = len(numerics.columns)\n",
    "num_columns = 3\n",
    "num_rows = num_plots // num_columns + (1 if num_plots % num_columns > 0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "# Set the figure size based on the number of rows\n",
    "plt.figure(figsize=(11, 4 * num_rows))\n",
    "\n",
    "# Iterate over each numerical column and create a histogram subplot\n",
    "for i, col in enumerate(numerics, 1):\n",
    "    plt.subplot(num_rows, num_columns, i)  # Create subplot\n",
    "    mean_values = numerics[col].mean()\n",
    "    median = numerics[col].median()\n",
    "\n",
    "    sns.kdeplot(numerics[col], fill=True, color='#638889')  # Plot histogram using seaborn\n",
    "    plt.axvline(x=mean_values, color='#F28585', linestyle='--', label='Mean')\n",
    "    plt.axvline(x=median, color='#747264', linestyle='--', label='Median')\n",
    "    plt.grid(True, alpha=0.8)  # Add grid lines to the plot\n",
    "    plt.title(f'{\" \".join(list(map(str.title, col.split(\"_\"))))} Distribution')  # Set title for the subplot\n",
    "    plt.savefig('/kaggle/working/kdeplot.png')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()  # Display the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a figure with custom size\n",
    "plt.figure(figsize=(11, 10))\n",
    "\n",
    "# Generate a heatmap of correlations for numerical columns in the DataFrame\n",
    "sns.heatmap(\n",
    "    df.select_dtypes(include=np.number).corr(),  # DataFrame correlation matrix for numerical columns\n",
    "    annot=True,  # Show correlation values in cells\n",
    "    cmap=['#638889', '#678788', '#6c8788', '#718788', '#768788', '#7b8788', '#808788', '#858788', '#8a8787', '#8f8787', \n",
    "          '#948687', '#998687', '#9e8687', '#a38687', '#a88687', '#ac8686', '#b18686', '#b68686', '#bb8686', '#c08686',\n",
    "          '#c58586', '#ca8586', '#cf8585', '#d48585', '#d98585', '#de8585', '#e38585', '#e88585', '#ed8585', '#f28585'],\n",
    "    annot_kws={\"fontsize\": 7}  # Annotation font size\n",
    ")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get list of columns excluding 'flood_probability'\n",
    "cols = df.drop(columns='flood_probability').columns.tolist()\n",
    "\n",
    "# Define statistical functions to apply\n",
    "funcs = [np.sum, np.mean, np.std, np.max, np.min, np.median]\n",
    "\n",
    "# Apply each statistical function to each row in the DataFrame\n",
    "for func in funcs:\n",
    "    df[f'features_{func.__name__}'] = df[cols].agg(func, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define feature groups with respective features\n",
    "feature_list = {'env_degradation_index' : ['deforestation', 'urbanization', 'wetland_loss', 'siltation'], \n",
    "                'infrastructure_vulnerability_score' : ['dams_quality', 'drainage_systems', 'deteriorating_infrastructure',\n",
    "                                                        'ineffective_disaster_preparedness'],\n",
    "                'human_impact_factor' : ['deforestation', 'urbanization', 'agricultural_practices', 'encroachments'], \n",
    "                'climate_stress_index' : ['monsoon_intensity', 'climate_change'], \n",
    "                'governance_planning_efficiency' : ['river_management', 'inadequate_planning', 'political_factors'], \n",
    "                'disaster_preparedness_index' : ['ineffective_disaster_preparedness', 'drainage_systems', 'dams_quality'], \n",
    "                'population_pressure_index' : ['population_score', 'urbanization', 'encroachments'], \n",
    "                'natural_hazard_risk_score' : ['landslides', 'coastal_vulnerability'], \n",
    "                'water_management_effectiveness' : ['watersheds', 'river_management', 'dams_quality'], \n",
    "                'developmental_impact_index' : ['urbanization', 'agricultural_practices', 'deforestation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Extract features and encode categorical variables using one-hot encoding\n",
    "X = df[:len(train)].drop(columns='flood_probability')\n",
    "TEST = df[len(train):]\n",
    "\n",
    "# Extract the target variable\n",
    "y = df[:len(train)]['flood_probability']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features in postlasso_df using StandardScaler\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "lasso_cv = LassoCV(alphas=[0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1],\n",
    "                   max_iter=1000, cv=5, random_state=42)\n",
    "\n",
    "# Fit the LassoCV model to the scaled feature matrix X_scaled and the target vector y\n",
    "lasso_cv.fit(X_scaled, y)\n",
    "\n",
    "# Extract the column names (features) where the coefficients are non-zero\n",
    "selected_features = X.columns[(lasso_cv.coef_ != 0).ravel()].tolist()\n",
    "\n",
    "# Print the number of selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with feature names and their coefficients from Lasso regression\n",
    "lasso_coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,  # Feature names\n",
    "    'Coefficient': lasso_cv.coef_  # Coefficients from Lasso regression\n",
    "})\n",
    "\n",
    "# Filter out features with non-zero coefficients\n",
    "lasso_filtered = lasso_coefficients[abs(lasso_coefficients['Coefficient']) > 0]\n",
    "\n",
    "# Sort the filtered DataFrame by coefficient values in descending order and reset index\n",
    "lasso_filtered_sorted = lasso_filtered.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(lasso_filtered_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Select only the columns (features) identified as important by the Lasso regression model\n",
    "postlasso_df = X[selected_features]\n",
    "\n",
    "# Splitting the data into train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(postlasso_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define models with their corresponding estimators\n",
    "models = {\n",
    "    'LGBMRegressor': LGBMRegressor(verbose=-1)\n",
    "}\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "params = {\n",
    "    'LGBMRegressor': {\n",
    "        'model__learning_rate': [0.01, 0.1, 0.3],\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__num_leaves': [15, 31, 63]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all the contents of DataFrame columns without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Set the display option to format float numbers with a precision of 5 decimal places\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "\n",
    "# Display the DataFrame results_df\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Store the counts in a list\n",
    "features = features_percentage_df['Feature'].tolist()\n",
    "counts = features_percentage_df['Importance (%)']\n",
    "\n",
    "# Define labels for the counts\n",
    "labels = list(map(lambda x: x.replace('_', ' ').title(), features))\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140,\n",
    "        colors=['#96ceb4', '#ffeead', '#ffcc5c', '#ff6f69', '#96897f'])\n",
    "\n",
    "# Draw a circle in the center to create a ring\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Feature Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Select only the columns (features) identified as important by the Lasso regression model in the testing dataset\n",
    "X = TEST[selected_features]\n",
    "\n",
    "# Use the best_model to predict the target variable for the testing dataset\n",
    "target_pred = grid_search.predict(X)\n",
    "\n",
    "# Read the sample submission file and set the 'Id' column as the index\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv', index_col='id')\n",
    "\n",
    "# Update the 'SalePrice' column in the submission DataFrame with the predicted target variable values\n",
    "submission['FloodProbability'] = target_pred\n",
    "\n",
    "# Save the submission DataFrame to a CSV file named 'submission.csv' in the './data' directory\n",
    "submission.to_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Data_Extraction",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "orig_features = train.columns[1:-1].to_list()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Checking null's\n",
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# No duplicates\n",
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "train.drop('id',axis=1).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Lets see the data present in the independent features\n",
    "for col in train.columns[1:-1]:\n",
    "    uniques = ', '.join(map(str, sorted(train[col].unique())))\n",
    "    print(f'Values in {col:<32}: {uniques:<69}| total={train[col].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train[orig_features])\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:,1:-1]\n",
    "y = train['FloodProbability']\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# For checking the model performance\n",
    "def cross_validate_print(alg, X, y, repeat=2, SINGLE_FOLD=False):\n",
    "    \n",
    "    start_time = time()\n",
    "    scores = []\n",
    "    oof_preds = np.full_like(y, np.nan, dtype=float)\n",
    "    \n",
    "    for fold,(train_idx, val_idx) in enumerate(kf.split(X, y.astype(str))):\n",
    "        x_cv_tr, y_cv_tr = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        x_cv_vl, y_cv_vl = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        y_pred = np.zeros_like(y_cv_vl, dtype=float)\n",
    "        for i in range(repeat):\n",
    "            m = clone(alg)\n",
    "            if repeat > 1:\n",
    "                mm = m\n",
    "                if isinstance(mm, Pipeline):\n",
    "                    mm = mm[-1]\n",
    "                mm.set_params(random_state=i)\n",
    "            m.fit(x_cv_tr, y_cv_tr)\n",
    "            y_pred += m.predict(x_cv_vl)\n",
    "        y_pred /= repeat   \n",
    "        \n",
    "        score = skm.r2_score(y_cv_vl, y_pred)\n",
    "        print(f'# Fold {fold}: R2 Score = {score:0.5f}')\n",
    "        scores.append(score)\n",
    "        oof_preds[val_idx] = y_pred\n",
    "        if SINGLE_FOLD: break\n",
    "        \n",
    "    total_time = time() - start_time\n",
    "    if isinstance(m, Pipeline):\n",
    "        model_name = m[-1].__class__.__name__\n",
    "    else:\n",
    "        model_name = m.__class__.__name__\n",
    "    print(f'{BlueBold}# Mean R2 Score = {np.mean(scores):0.5f} {RedBold}± {np.std(scores):0.5f} {BlueBold}for {model_name}\\n'\n",
    "          f'{\"Single Fold\" if SINGLE_FOLD else \"\"}'\n",
    "          f'Time Elapsed: {np.round((total_time / 60),0)} Min {end}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "temp = train['FloodProbability'].groupby(X.sum(axis=1)).mean()\n",
    "plt.figure(figsize=(10,4))\n",
    "sb.scatterplot(x=temp.index, y=temp, c=temp.index.isin(np.arange(72,76)), s=30, cmap='RdYlBu_r')\n",
    "plt.gca().xaxis.set_major_locator(MultipleLocator(5))\n",
    "plt.gca().xaxis.set_minor_locator(MultipleLocator(1))\n",
    "plt.gca().yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "plt.grid(True, which='major', linestyle='--')\n",
    "plt.grid(True, which='minor', linestyle=':')\n",
    "plt.xlabel('Feature sums (along column axis)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# For getting the unique values in train. Used later in feature engineering\n",
    "unique = []\n",
    "for col in train.iloc[:,1:-1].columns:\n",
    "    unique.extend(train[col].unique())\n",
    "unique = list(set(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = train_df\n",
    "y = train['FloodProbability']\n",
    "\n",
    "cross_validate_print(xgr_model, X, y)\n",
    "cross_validate_print(cbr_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Extraction",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_parallel_tree': trial.suggest_int('num_parallel_tree', 50, 1000),\n",
    "        'max_depth':         trial.suggest_int('max_depth', 1, 30),\n",
    "        'colsample_bynode':  trial.suggest_float('colsample_bynode', 0.05, 1),\n",
    "        'subsample':         trial.suggest_float('subsample', 0.05, 1),\n",
    "        'min_child_weight':  trial.suggest_int('min_child_weight', 1, 250),\n",
    "        'lambda':            trial.suggest_float('lambda', 1, 10)\n",
    "    }\n",
    "    \n",
    "    gc.collect()\n",
    "    xgrf = XGBRegressor(**params, **fixed_params_xgrf)\n",
    "    r2_score = cross_validate_tuner(xgrf, X, y, XGB=True)\n",
    "    \n",
    "    return r2_score\n",
    "\n",
    "TPESampler = optuna.samplers.TPESampler(multivariate=True, group=True)\n",
    "optimize_r2_xgrf = optuna.create_study(direction='maximize', sampler=TPESampler, study_name='Optimizing R2 for XGRF')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "editable": true,
    "notebook_id": 5,
    "slideshow": {
     "slide_type": ""
    },
    "start_cell": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'playground-series-s4e5:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F73278%2F8121328%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240528%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240528T155103Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0cdf00152e2d9da8616a0fb96ca0eb19f5d0d6fd696ac54a1bb4141a4c47820770d28611dc20da3b5f4f2d2a68a3bef84b8623dbf38002b7aa292109886b76ae8a48b3ff8b3b32434dae233a1dd57fc05ebe753e25ee8aa4860113ed9bf6ac3be3318ea97ca1830bd8257fa20d4bba9bbe218920c5fed9216f21aaf6a7e9769f85d47a4bab0ca62ec05dec8da4d7e62539859b3ce1d13653bf1ae02e97278e164a0534569c232fe490004c434705028e0c9a9e90d09a67282cf3682ec3ee0eddb50400b44a2b351ea11fa204143ba563c7e3bc72ef8fa8b035e051ca8d1a29d42651c8589ec127252966dcccebfc848331cb7d4acd4df5f8f95ff270ecd60e20'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "####### BOXPLOT FOR EVERY FEATURE ########\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "num_cols = len(df_train.columns)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=num_cols, figsize=(15, 5))\n",
    "\n",
    "for col in df_train.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=df_train[col])\n",
    "    plt.title(col)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df, threshold=1.5):\n",
    "    outlier_columns = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Calculate the first and third quartiles\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "\n",
    "        # Interquartile range (IQR)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Define the lower and upper bounds for outlier detection\n",
    "        lower_bound = q1 - threshold * iqr\n",
    "        upper_bound = q3 + threshold * iqr\n",
    "\n",
    "        # Find outliers\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "        if not outliers.empty:\n",
    "            outlier_columns.append(col)\n",
    "\n",
    "    return outlier_columns\n",
    "\n",
    "outlier_cols = detect_outliers(df_train)\n",
    "print(\"Columns with outliers: \\n\", outlier_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Plot numerical columns against 'FloodProbability' using scatter plots\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=df_train, x=col, y='FloodProbability', alpha=0.7)\n",
    "    plt.title(f'{col} vs. FloodProbability')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('FloodProbability')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot categorical columns against 'FloodProbability' using bar plots\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=df_train, x=col, y='FloodProbability', alpha=0.7)\n",
    "    plt.title(f'{col} vs. FloodProbability')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('FloodProbability')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Drop id\n",
    "df_train.drop(\"id\" , axis = 1  , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# NULL values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "## REMOVE OUTLIERS\n",
    "\n",
    "from scipy import stats\n",
    "def remove_outliers_zscore(df, threshold=3):\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Calculate Z-score for each numerical column\n",
    "    z_scores = np.abs(stats.zscore(df[numerical_cols]))\n",
    "    # Identify rows where any Z-score exceeds the threshold\n",
    "    outlier_rows = np.any(z_scores > threshold, axis=1)\n",
    "    # Remove outlier rows from DataFrame\n",
    "    df_cleaned = df[~outlier_rows]\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "df_train = remove_outliers_zscore(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''No need to perform standardization / normalization as all the features have a small and comparable scale'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "correlation_matrix = df_train.corr(method='pearson')\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_prob_corr = correlation_matrix['FloodProbability'].drop('FloodProbability')  # Drop 'FloodProbability' itself\n",
    "# Sort the correlation coefficients in decreasing order of magnitude\n",
    "sorted_corr = flood_prob_corr.abs().sort_values(ascending=False)\n",
    "# Print feature names and their corresponding correlation coefficients\n",
    "for feature in sorted_corr.index:\n",
    "    print(f\"Feature: {feature},     Correlation: {flood_prob_corr[feature]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "categorical_df = df_train\n",
    "\n",
    "chi2_results = {}\n",
    "for col in categorical_df.columns:\n",
    "    contingency_table = pd.crosstab(df_train[col], df_train['FloodProbability'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    chi2_results[col] = chi2\n",
    "\n",
    "# Sort the chi-square test results in decreasing order of magnitude\n",
    "sorted_chi2_results = {k: v for k, v in sorted(chi2_results.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Print feature names and their corresponding chi-square statistics\n",
    "for feature, chi2_statistic in sorted_chi2_results.items():\n",
    "    print(f\"Feature: {feature}, Chi-square statistic: {chi2_statistic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''Not dropping any feature since they all have practically the same correlation coefficient and Chi-square statistic'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Verify GPU is available\n",
    "if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
    "    print(\"GPU is available and will be used for training.\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "tuner.search(x_train , y_train , epochs = 10 , batch_size = 2056,validation_data = (x_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "# best_model = tuner.get_best_models()[0]\n",
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test_nanid = df_test.drop(\"id\" , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x_target = df_test_nanid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "outputs = best_model.predict(x_target)\n",
    "output_df = pd.DataFrame(outputs , columns =  [\"FloodProbability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "id = df_test[[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df = pd.concat([id, output_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": 47,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": 48,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df = output_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": 49,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(\"target outputs.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": 50,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return 1 - ss_res / (ss_tot + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_id": 51,
    "class": "Data_Extraction",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('/kaggle/input/best_model_flood_prediction/tensorflow2/v2/1/best_flood_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sample=pd.read_csv(\"/kaggle/input/playground-series-s4e5/sample_submission.csv\",sep=\",\")\n",
    "train=pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\",sep=\",\")\n",
    "test=pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sample.shape,train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y=train[\"FloodProbability\"]\n",
    "df=train.drop([\"FloodProbability\",\"id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df.shape,y.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.size,y.size,train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test=test.drop([\"id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(clip=True)\n",
    "df=scaler.fit_transform(df)\n",
    "test=scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(train)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca=PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# train=pca.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# pca.explained_variance_ratio_\n",
    "# pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# best=SelectKBest(k=15).fit_transform(train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y=pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "feature=df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "feature.shape,df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test=pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression , Ridge ,Lasso ,BayesianRidge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model3=DecisionTreeRegressor(random_state=0,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "# # Assuming 'X' and 'y' are your features and target variable respectively\n",
    "# kernel = DotProduct() + WhiteKernel()\n",
    "# gpr = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# gpr.fit(xtrain, ytrain)\n",
    "# y_pred, y_std = gpr.predict(xtrain, return_std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": 47,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model2.fit(xtrain,ytrain)           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": 48,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": 49,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model2 = Pipeline([\n",
    "#     ('poly', PolynomialFeatures(degree=2,interaction_only=False)),\n",
    "#     ('Ridge', Ridge(fit_intercept=True,random_state=0,alpha=1.5))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": 50,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_id": 51,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model2=SVR(kernel=\"rbf\",gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": 52,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model2=BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_id": 53,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_id": 54,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# new_df.hist(bins=50,figsize=(20,15))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cell_id": 57,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# model2=GaussianProcessRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cell_id": 63,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "prediction ,testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_id": 68,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(model2,xtrain,ytrain,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_id": 69,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "r2_score(yval,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cell_id": 71,
    "class": "Data_Extraction",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "submission=pd.DataFrame(columns=[\"id\",\"FloodProbability\"])\n",
    "submission[\"id\"]=[i for i in range(1117957,len(testf)+1117957)]\n",
    "submission[\"FloodProbability\"]=predict\n",
    "submission.to_csv(\"submission.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "####### BOXPLOT FOR EVERY FEATURE ########\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "num_cols = len(df_train.columns)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=num_cols, figsize=(15, 5))\n",
    "\n",
    "for col in df_train.columns:\n",
    "    plt.figure(figsize=(8, 5))  \n",
    "    sns.boxplot(x=df_train[col])\n",
    "    plt.title(col)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Drop id\n",
    "df_train.drop(\"id\" , axis = 1  , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def remove_outliers_zscore(df, threshold=3):\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Calculate Z-score for each numerical column\n",
    "    z_scores = np.abs(stats.zscore(df[numerical_cols]))\n",
    "    # Identify rows where any Z-score exceeds the threshold\n",
    "    outlier_rows = np.any(z_scores > threshold, axis=1)\n",
    "    # Remove outlier rows from DataFrame\n",
    "    df_cleaned = df[~outlier_rows]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "df_train = remove_outliers_zscore(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_prob_corr = correlation_matrix['FloodProbability'].drop('FloodProbability')  # Drop 'FloodProbability' itself\n",
    "# Sort the correlation coefficients in decreasing order of magnitude\n",
    "sorted_corr = flood_prob_corr.abs().sort_values(ascending=False)\n",
    "# Print feature names and their corresponding correlation coefficients\n",
    "for feature in sorted_corr.index:\n",
    "    print(f\"Feature: {feature},     Correlation: {flood_prob_corr[feature]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "categorical_df = df_train\n",
    "\n",
    "chi2_results = {}\n",
    "for col in categorical_df.columns:\n",
    "    contingency_table = pd.crosstab(df_train[col], df_train['FloodProbability'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    chi2_results[col] = chi2\n",
    "\n",
    "# Sort the chi-square test results in decreasing order of magnitude\n",
    "sorted_chi2_results = {k: v for k, v in sorted(chi2_results.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Print feature names and their corresponding chi-square statistics\n",
    "for feature, chi2_statistic in sorted_chi2_results.items():\n",
    "    print(f\"Feature: {feature}, Chi-square statistic: {chi2_statistic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''Not dropping any feature since they all have practically the same correlation coefficient and Chi-square statistic'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# for k in range(3 , 7):\n",
    "#     knn_model = KNeighborsRegressor(n_neighbors = k)\n",
    "#     outputs = cross_val_score(knn_model, x, y,cv=5)\n",
    "#     print(\"K:\" , k)\n",
    "#     print(\"Outputs: \",outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# svr_model = SVR()\n",
    "# outputs = cross_val_score(svr_model, x_train, np.ravel(y_train), cv=10)\n",
    "# print(\"Outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Train the XGBoost model on the training data\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = xgb_model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = xgb_model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor model\n",
    "gbm_model = GradientBoostingRegressor()\n",
    "\n",
    "# Train the Gradient Boosting Regressor model on the training data\n",
    "gbm_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = gbm_model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = gbm_model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# adaboost_model = AdaBoostRegressor()\n",
    "# outputs = cross_val_score(adaboost_model, x, np.ravel(y), cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# # Convert outputs to positive values\n",
    "# outputs = -outputs\n",
    "\n",
    "# print(\"Outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test_nanid = df_test.drop(\"id\" , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x_target = df_test_nanid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "id = df_test[[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df = output_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Extraction",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import R2Score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Reading input files\n",
    "df = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "df_check = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "mean_less_than_30 = df.loc[df['FloodProbability'] < 0.3].mean()\n",
    "mean_more_than_70 = df.loc[df['FloodProbability'] > 0.7].mean()\n",
    "mean_between_30_and_70 = df.loc[(df['FloodProbability'] >= 0.3) & (df['FloodProbability'] <= 0.7)].mean()\n",
    "print(\"Mean for probability < 30:\", mean_less_than_30)\n",
    "print(\"Mean for probability > 70:\", mean_more_than_70)\n",
    "print(\"Mean for probability between 30 and 70:\", mean_between_30_and_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Dividing on data and target\n",
    "X = df.drop([\"FloodProbability\"], axis=1)\n",
    "Y = df[\"FloodProbability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_predicted, color='blue', alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predictions vs. Actual Values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ids = df_check[\"id\"]\n",
    "df_check = df_check.drop(\"id\", axis=1)\n",
    "df_check = scaler.fit_transform(df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'id': ids, 'FloodProbability': predictions.flatten()})\n",
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import r2_score\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R² Score:\", r2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 9,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 9,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "all_data=pd.read_csv('/kaggle/input/flood-prediction-features/data_all.csv',index_col='id')\n",
    "# df_test=pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv',index_col='id')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 9,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train = all_data[all_data['type']==0]\n",
    "df_test = all_data[all_data['type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 9,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(['FloodProbability', 'type'], axis=1)\n",
    "y = df_train['FloodProbability']\n",
    "df_test = df_test.drop(['FloodProbability', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 9,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate\n",
    "def objective(trial):\n",
    "    params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 300, 2000),\n",
    "            'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 15)\n",
    "            }\n",
    "\n",
    "\n",
    "    \n",
    "    clf = lgb.LGBMRegressor(**params,boosting_type= 'gbdt',random_state=0, device='gpu',verbosity=-1)\n",
    "    #交叉验证\n",
    "    cv_results = cross_validate(clf, X, y, cv=5, scoring='r2')\n",
    "    \n",
    "    validation_score = np.mean(cv_results['test_score'])\n",
    "    \n",
    "    return validation_score\n",
    "# def objective(trial):\n",
    "#     #定义参数范围\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 1)\n",
    "    \n",
    "#     print('Training the model with', X.shape[1], 'features')\n",
    "\n",
    "#     params = {'n_estimators': n_estimators,\n",
    "#               'learning_rate': learning_rate,\n",
    "#               'max_depth': max_depth}\n",
    "        \n",
    "#     clf = XGBRegressor(**params,tree_method='gpu_hist',random_state=0)\n",
    "#     #交叉验证\n",
    "#     cv_results = cross_validate(clf, X, y, cv=7, scoring='r2')\n",
    "    \n",
    "#     validation_score = np.mean(cv_results['test_score'])\n",
    "    \n",
    "#     return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "sub_df = pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = train_df.iloc[:, 1:-1]\n",
    "y = train_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "lr_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(lr_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "sgd_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(sgd_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "sgd_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(sgd_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "sgd_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(sgd_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "rfr_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(rfr_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "bgr_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(bgr_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "gbr_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(gbr_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "gbr_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(gbr_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "svr_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(svr_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "lgbm_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(lgbm_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": 47,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": 48,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define X_test (remove id column)\n",
    "X_test = test_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": 50,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Get y_pred\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_id": 51,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Add prediction column to submission df\n",
    "target_col = \"FloodProbability\"\n",
    "sub_df[target_col] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": 52,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_id": 53,
    "class": "Data_Extraction",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Save the submission dataframe to a CSV file\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv', index_col ='id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv', index_col ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cols = train.drop('FloodProbability', axis = 1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "round(train.agg(['min','mean','median','max','var','std','skew']),2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.isna().sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print('Shape before :',train.shape)\n",
    "train.dropna(how='any', inplace=True)\n",
    "print(\"Shape after :\",train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y = train['FloodProbability']\n",
    "X = train.drop('FloodProbability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Print the best estimators\n",
    "for name, estimator in best_estimators.items():\n",
    "    print(f\"Best estimator for {name}: {estimator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test.index, 'FloodProbability':y_preds})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "!pip install featuring-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from featuringdata.featuresEDA import FeaturesEDA\n",
    "from featuringdata.featureSelector import FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "eda = FeaturesEDA(report_prefix='Flood_Prediction', target_col=\"FloodProbability\",\n",
    "                  cols_to_drop=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 12,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "eda.master_columns_df.sort_values(by=[\"Random Forest\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('/kaggle/input/flood-prediction-factors/flood.csv')\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(['id'], axis=1)\n",
    "\n",
    "# Check if the order and name of columns of both datasets are the same or not\n",
    "data.columns == original_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# concat datasets\n",
    "data = pd.concat([data, original_data], )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# check data information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# check if there is duplicated data point\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Checking number of each column type\n",
    "\n",
    "num_cols = [col for col in data.columns if data[col].dtype=='int64']\n",
    "print('number of numerical columns: ', len(num_cols))\n",
    "\n",
    "cat_cols = [col for col in data.columns if data[col].dtype=='object']\n",
    "print('number of categorical columns: ', len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Checking unique values of each column\n",
    "\n",
    "for col in num_cols:\n",
    "    print(f'{col} contains: {set(data[col])} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4 * 5, 5 * 4))\n",
    "\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 5, i)\n",
    "    sns.boxplot(data=data, x=col);\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Check the number of outliers in each features\n",
    "data_out = data.copy()\n",
    "outlier_counts = {}\n",
    "\n",
    "for col in num_cols:\n",
    "    q1=data_out[col].quantile(0.25)\n",
    "    q3=data_out[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    outlier_counts[col]=[len(data_out[(data_out[col]<q1-1.5*iqr) | (data_out[col]>q3+1.5*iqr)])]\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_counts).T\n",
    "outlier_df.columns = ['Number of Outliers']\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Then We should drop duplicates\n",
    "check_ouliers = check_ouliers.drop_duplicates()\n",
    "# Check if still there are duplicated data\n",
    "check_ouliers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Replace with edge values\n",
    "# data_replaced = data.copy()\n",
    "# for col in num_cols:\n",
    "#   q1=data_replaced[col].quantile(0.25)\n",
    "#   q3=data_replaced[col].quantile(0.75)\n",
    "#   iqr = q3 - q1\n",
    "#   data_replaced.loc[(data_replaced[col] < q1 - 1.5*iqr), col] = q1 - 1.5*iqr\n",
    "#   data_replaced.loc[(data_replaced[col] > q3 + 1.5*iqr), col] = q3 + 1.5*iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "label = data['FloodProbability']\n",
    "data_replaced = data.drop('FloodProbability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "testset = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "ids = testset['id']\n",
    "testset = testset.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Replace with edge values\n",
    "testset_replaced = testset.copy()\n",
    "# for col in num_cols:\n",
    "#   q1=testset_replaced[col].quantile(0.25)\n",
    "#   q3=testset_replaced[col].quantile(0.75)\n",
    "#   iqr = q3 - q1\n",
    "#   testset_replaced.loc[(testset_replaced[col] < q1 - 1.5*iqr), col] = q1 - 1.5*iqr\n",
    "#   testset_replaced.loc[(testset_replaced[col] > q3 + 1.5*iqr), col] = q3 + 1.5*iqr\n",
    "\n",
    "# New Statistical features\n",
    "testset_new = transform(testset_replaced)\n",
    "\n",
    "# scaling\n",
    "testset_scaled = sc.transform(testset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "## You can predict with any of those models, but we prefer the merging one\n",
    "xgb_pred = xgb_model.predict(testset_scaled)\n",
    "cat_pred = cat_model.predict(testset_scaled)\n",
    "lgb_pred = lgb_model.predict(testset_scaled)\n",
    "preds = 0.33*xgb_pred + 0.33*cat_pred + 0.34*lgb_pred\n",
    "\n",
    "preds = pd.Series(preds, name='FloodProbability')\n",
    "submit = pd.concat([ids, preds], axis=1)\n",
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "test_data=pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")\n",
    "sample=pd.read_csv(\"/kaggle/input/playground-series-s4e5/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data.isin([np.nan,\"\",'?']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "co_mat=train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y=train_data['FloodProbability'].copy()\n",
    "X=train_data.drop(columns=['id','FloodProbability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "lg=LinearRegression(fit_intercept=True,n_jobs=-1)\n",
    "ri=Ridge(random_state=42)\n",
    "la=Lasso()\n",
    "pf=PolynomialFeatures(degree=2,interaction_only=True)\n",
    "pca=PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(gv.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_data_new=test_data.iloc[:,1:]\n",
    "head_id=test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "head_id=pd.DataFrame(head_id,columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_final=pd.DataFrame(test_final,columns=['FloodProbability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output=pd.concat([head_id,test_final],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_file_path='/kaggle/input/playground-series-s4e5/train.csv'\n",
    "test_file_path='/kaggle/input/playground-series-s4e5/test.csv'\n",
    "train_df=pd.read_csv(train_file_path)\n",
    "test_df=pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_describe=train_df.describe()\n",
    "fields=['mean','min','25%','50%','75%','max']\n",
    "train_describe=train_describe.loc[fields]\n",
    "train_describe.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_corr=train_df.corr()['FloodProbability'][:-1]\n",
    "df_corr.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "skew_limit=0.75\n",
    "df_skew=train_df.skew()\n",
    "df_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "feature_cols = [x for x in train_df.columns if x != \"FloodProbability\"]\n",
    "\n",
    "# Create a new column 'fsum' which is the sum of all feature columns for each row\n",
    "train_df['fsum'] = train_df[feature_cols].sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = train_df.loc[:, train_df.columns != \"FloodProbability\"]\n",
    "y = train_df['FloodProbability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define pipeline with Polynomial Regression degree = 2\n",
    "polynomial = Pipeline([\n",
    "    ('polynomial', PolynomialFeatures(include_bias=False, degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the instance on the data and then predict the expected value\n",
    "polynomial.fit(X_train, y_train)\n",
    "poly2_pred = polynomial.predict(X_test)\n",
    "\n",
    "# Calculate R^2 score for the polynomial regression model with degree 2\n",
    "r2_poly2 = r2_score(y_test, poly2_pred)\n",
    "\n",
    "# Display R^2 score\n",
    "print(r2_poly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "predictions_test = polynomial.predict(test_df)\n",
    "\n",
    "# result dataframe\n",
    "result = pd.DataFrame({'id' : test_ids, 'FloodProbability' : predictions_test.flatten()}, \n",
    "                                columns=['id', 'FloodProbability'])\n",
    "\n",
    "# print result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "test_set = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "uniques = pd.DataFrame(train_set.nunique())\n",
    "uniques[\"test\"] = pd.DataFrame(test_set.nunique())\n",
    "uniques = uniques.rename(columns={0:\"train_count\",\n",
    "                       \"test\":\"test_count\"})\n",
    "uniques[\"error\"] =  uniques[\"train_count\"]-uniques[\"test_count\"]\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_set_id = test_set[[\"id\"]]\n",
    "train_set = train_set.set_index(\"id\")\n",
    "test_set = test_set.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cat_columns=['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', \n",
    "          'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "          'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "          'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "          'CoastalVulnerability', 'Landslides', 'Watersheds', \n",
    "          'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "           'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_set.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_corr_df = pd.DataFrame(train_set.corr()['FloodProbability'].drop('FloodProbability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "columns = list(full_df.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sorted_corr = corr_df_X.sort_values(by='FloodProbability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr_df_X = pd.DataFrame(for_corr.corr()['FloodProbability'].drop('FloodProbability'))\n",
    "sorted_corr = corr_df_X.sort_values(by='FloodProbability', ascending=False)\n",
    "corr_more_02 = list(sorted_corr[(sorted_corr > 0.2) | (sorted_corr < -0.2)].dropna().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": 49,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'iterations': [500, 1000],\n",
    "#     'depth': [4, 6, 10],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'l2_leaf_reg': [1, 3, 5, 7],\n",
    "# }\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=cat_model, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best parameters for CatBoostRegressor:\")\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": 50,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# svc_model = SVR()\n",
    "# svc_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# print(f\"Training score {svc_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# SVR_score = r2_score(y_test,y_pred)\n",
    "# SVR_Tscore = svc_model.score(X_train,y_train)\n",
    "\n",
    "# # Training score 0.6892091193403993\n",
    "# # R2: 0.6879615201044295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_id": 51,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# knn_model = KNeighborsRegressor()\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# print(f\"Training score {knn_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# KNN_score = r2_score(y_test,y_pred)\n",
    "# KNN_Tscore = knn_model.score(X_train,y_train)\n",
    "\n",
    "# # Training score 0.7389672547153135\n",
    "# # R2: 0.6103305408520886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": 52,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# dt_model = DecisionTreeRegressor()\n",
    "# dt_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# print(f\"Training score {dt_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# DT_score = r2_score(y_test,y_pred)\n",
    "# DT_score = dt_model.score(X_train,y_train)\n",
    "\n",
    "# # Training score 1.0\n",
    "# # R2: 0.011373210481789964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_id": 53,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# rf_model = RandomForestRegressor()\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rf_model.predict(X_test)\n",
    "# print(f\"Training score {rf_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# RF_score = r2_score(y_test,y_pred)\n",
    "# RF_Tscore = rf_model.score(X_train,y_train)\n",
    "\n",
    "# # Training score 0.9473678172793106\n",
    "# # R2: 0.6280500145463217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_id": 55,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# ET_model = ExtraTreesRegressor()\n",
    "# ET_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = ET_model.predict(X_test)\n",
    "# print(f\"Training score {ET_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# ET_score = r2_score(y_test,y_pred)\n",
    "# ET_Tscore = ET_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cell_id": 66,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# SC_model = StackingRegressor(estimators)\n",
    "# SC_model.fit(X, y)\n",
    "\n",
    "# y_pred_SC = SC_model.predict(test_set)\n",
    "# print(f\"Training score {SC_model.score(X,y)}\")\n",
    "# # Training score 0.8509888812778332\n",
    "\n",
    "# # final\n",
    "# # Training score 0.868946761417187\n",
    "\n",
    "# # Training score 0.869303107297456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_id": 68,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# y_pred_xg = pd.DataFrame(y_pred_xg)\n",
    "# output_xg = test_set_id\n",
    "# output_xg[\"FloodProbability\"] = pd.DataFrame(y_pred_xg)\n",
    "# output_xg = output_xg.set_index(\"id\")\n",
    "# output_xg.to_csv(\"FloodProbability_OHE_project_FEng_xg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cell_id": 71,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# rf_model = RandomForestRegressor()\n",
    "# SC_model = StackingRegressor([(\"rf_model\",rf_model)])\n",
    "# SC_model.fit(X, y)\n",
    "\n",
    "# y_pred_SC = SC_model.predict(test_set)\n",
    "# print(f\"Training score {SC_model.score(X,y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cell_id": 72,
    "class": "Data_Extraction",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# y_pred_SC = pd.DataFrame(y_pred_SC)\n",
    "# output_SC = test_set_id\n",
    "# output_SC[\"FloodProbability\"] = pd.DataFrame(y_pred_SC)\n",
    "# output_SC = output_SC.set_index(\"id\")\n",
    "# output_SC.to_csv(\"FloodProbability_OHE_project_FEng_SC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 17,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 17,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_train =pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "flood_test =pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 17,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"float_format\",'{:.4f}'.format)\n",
    "print(\"shape\", flood_train.shape)\n",
    "print(\"shape\", flood_test.shape)\n",
    "print(\"Describe_train_data\", flood_train.describe())\n",
    "print(\"Describe_test_data\", flood_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 17,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print(\"missing_count_train\", flood_train.isna().sum())\n",
    "print(\"missing_count_test\", flood_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 17,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for col in flood_train.columns:\n",
    "    iqr = flood_train[col].quantile(0.75) - flood_train[col].quantile(0.25)\n",
    "    upper_bound = flood_train[col].quantile(0.75) + 1.5*iqr\n",
    "    lower_bound = flood_train[col].quantile(0.25) - 1.5*iqr\n",
    "    flood_train[col] = flood_train[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "for col in flood_test.columns:\n",
    "    iqr = flood_test[col].quantile(0.75) - flood_test[col].quantile(0.25)\n",
    "    upper_bound = flood_test[col].quantile(0.75) + 1.25*iqr\n",
    "    lower_bound = flood_test[col].quantile(0.25) - 1.5*iqr\n",
    "    flood_test[col] = flood_test[col].clip(lower= lower_bound, upper = upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 17,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "x = flood_train.drop([\"id\", \"FloodProbability\"], axis =1)\n",
    "y = flood_train[\"FloodProbability\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x)\n",
    "x_test_scaled = scaler.fit_transform(flood_test.drop([\"id\"], axis = 1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_scaled, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lm.predict(x_test)\n",
    "print(f\"r2 = {r2_score(y_test, y_pred) : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['FloodProbability'])\n",
    "y = df.FloodProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_test = df_test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "predictions1 = model_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_test.PoliticalFactors, y_test, marker='.')\n",
    "plt.scatter(x_test.PoliticalFactors, predictions1, marker='x' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id' : X_test.id,\n",
    "                           'FloodProbability' : predictions\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test = pd.read_csv(r'/kaggle/input/playground-series-s4e5/test.csv')\n",
    "train = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:, :-1]\n",
    "y = train.iloc[:, -1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X,y, test_size=0.1, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['r2_score'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "max(history2.history['val_r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test_df=pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Q1=train_df.quantile(0.25)\n",
    "Q3=train_df.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lower_bound=Q1-1.5*IQR\n",
    "upper_bound=Q3+1.5*IQR\n",
    "outliers = pd.DataFrame(np.logical_or(train_df < lower_bound, train_df > upper_bound), columns=train_df.columns)\n",
    "outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "sns.heatmap(train_df.iloc[:,1:].corr(),cmap=\"crest\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train=train_df.iloc[:,1:21]\n",
    "y_train=train_df.iloc[:,21:]\n",
    "X_test=test_df.iloc[:,1:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe=make_pipeline(RobustScaler(),RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]))\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred=pipe.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 20,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission=pd.DataFrame({\n",
    "    'id':test_df['id'],\n",
    "    'FloodProbability':y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Data = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\", index_col = None)\n",
    "Data = Data.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "\n",
    "Data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# divde the data into target and factors and run feature scaling \n",
    "\n",
    "\n",
    "target = Data['FloodProbability']\n",
    "\n",
    "X = Data.drop(['FloodProbability'], axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# divide the data into test train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# use gradient boosting\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_score = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R^2 score:\", r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "print(\"R2 error:\", r2_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2_score = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R^2 score:\", r2_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Polynomial regression\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn\n",
    "\n",
    "# Create a polynomial features object with degree 2\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Transform the training and testing features\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the transformed training data\n",
    "er = model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Evaluate the model on the transformed testing data\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2_score = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R^2 score:\", r2_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "#load the test dataset\n",
    "\n",
    "import pandas as pd\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")\n",
    "testing = test.drop(['id'], axis = 1)\n",
    "testing.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "testing = scaler.fit_transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Import the basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Load the training and test sets\n",
    "train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv', index_col = 'id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv', index_col = 'id')\n",
    "\n",
    "\n",
    "# Display the shape of the data frames\n",
    "print('Shape of the:')\n",
    "print('Training set: ', train.shape)\n",
    "print('Test set: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a function to compute the duplicates \n",
    "def duplicates(df, name_df):\n",
    "    print(f'The {name_df} set has %d duplicates.' %df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Determine the duplicates in the training set\n",
    "duplicates(train, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Determine the duplicates in the test set\n",
    "duplicates(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print(train.isna().sum().any())\n",
    "print(test.isna().sum().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = train.drop('FloodProbability', axis = 1)\n",
    "y = train['FloodProbability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_test = test.copy()\n",
    "\n",
    "print('For the training set:')\n",
    "print('Shape of the features: ', X_train.shape)\n",
    "print('Shape of the response variable: ', y_train.shape)\n",
    "print('*'*60)\n",
    "print('*'*60)\n",
    "print('For the validation set:')\n",
    "print('Shape of the features: ', X_val.shape)\n",
    "print('Shape of the response variable: ', y_val.shape)\n",
    "print('*'*60)\n",
    "print('*'*60)\n",
    "print('For the test set:')\n",
    "print('Shape of the features: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis = 1)\n",
    "train_df.isna().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Display the min and max values of the numerical variables\n",
    "min_val = [X_train[col].min() for col in X_train.columns]\n",
    "max_val = [X_train[col].max() for col in X_train.columns]\n",
    "\n",
    "minmax_df = pd.DataFrame({'feature': X_train.columns,\n",
    "                         'min_value': min_val,\n",
    "                         'max_value': max_val}).set_index('feature')\n",
    "minmax_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Format the plots\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('figure', autolayout = True)\n",
    "plt.rc('axes',\n",
    "      labelweight = 'bold',\n",
    "      labelsize = 'large',\n",
    "      titleweight = 'bold',\n",
    "      titlesize = 14,\n",
    "      titlepad = 10)\n",
    "\n",
    "palette = sns.color_palette('Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for col_name in X_train.columns:\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    cat_plot(train_df, col_name, re)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def compute_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores_df = pd.DataFrame({'feature': X.columns,\n",
    "                                 'mi_scores': mi_scores}).set_index('feature').sort_values(by = 'mi_scores', \n",
    "                                                                                           ascending = False)\n",
    "    return mi_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "compute_mi_scores(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "weather_features = ['MonsoonIntensity', 'ClimateChange']\n",
    "infrastructure_features = ['TopographyDrainage', 'RiverManagement', 'DamsQuality', \n",
    "                  'DrainageSystems', 'DeterioratingInfrastructure'] \n",
    "\n",
    "environmental_features = ['Deforestation',  'Siltation', 'CoastalVulnerability', 'WetlandLoss', 'Landslides', 'Watersheds']\n",
    "human_features = ['Urbanization', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', \n",
    "        'IneffectiveDisasterPreparedness', 'AgriculturalPractices', 'Encroachments']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Costruct a pairplot of the newly engineered features\n",
    "sns.pairplot(X_train_1[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Make a list of the algorithms that require scaling with their names\n",
    "models_need_scaling = [lin_reg, lasso, ridge, svr, kn_reg]\n",
    "name_models_need_scaling = ['Linear Regression', 'Lasso', 'Ridge', \n",
    "                            'Support Vector Regressor', 'K-Neighbors Regressor'] \n",
    "\n",
    "train_score, test_score, r2, mae, rmse = [], [], [], [], []\n",
    "\n",
    "# Apply the function defined in the previous code snippet\n",
    "for model, model_name in zip(models_need_scaling, name_models_need_scaling):\n",
    "    building_model(model, model_name, X_train_scaled, X_val_scaled)\n",
    "\n",
    "# Create a data frame that displays the metrics corresponding to each model \n",
    "scores_df1 = pd.DataFrame({'model': name_models_need_scaling,\n",
    "                          'train_score': train_score,\n",
    "                          'test_score': test_score,\n",
    "                          'r2_score': r2,\n",
    "                          'mean_absolute_error': mae,\n",
    "                          'root_mean_squared_error': rmse}).sort_values(by = 'r2_score',\n",
    "                                                                        ascending = False).set_index('model')\n",
    "scores_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Make a list of the algorithms that don't require scaling with their names\n",
    "models_without_scaling = [xgb_reg, tree, forest, grad_boost, lgbm] \n",
    "name_models_without_scaling = ['XGB Regression', 'Decision Tree Regression', \n",
    "                               'Random Forest Regression', 'Gradient Boosting Regressor', \n",
    "                               'Light GBM Regressor'] \n",
    "\n",
    "train_score, test_score, r2, mae, rmse = [], [], [], [], []\n",
    "\n",
    "# Apply the function defined in the previous code snippet\n",
    "for model, model_name in zip(models_without_scaling, name_models_without_scaling):\n",
    "    building_model(model, model_name, X_train_1[features], X_val_1[features])\n",
    "\n",
    "# Create a data frame that displays the metrics corresponding to each model \n",
    "scores_df2 = pd.DataFrame({'model': name_models_without_scaling,\n",
    "                          'train_score': train_score,\n",
    "                          'test_score': test_score,\n",
    "                          'r2_score': r2,\n",
    "                          'mean_absolute_error': mae,\n",
    "                          'root_mean_squared_error': rmse}).sort_values(by = 'r2_score',\n",
    "                                                                        ascending = False).set_index('model')\n",
    "\n",
    "scores_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "params_xgb = {'learning_rate': [0.01, 0.1],\n",
    "              'max_depth': [5, 7],\n",
    "              'min_child_weight': [3, 5],\n",
    "              'n_estimators' : [100, 500]}\n",
    "xgb_reg = XGBRegressor(objective = 'reg:squarederror')\n",
    "\n",
    "hyperparameter_tuning(xgb_reg, params_xgb, X_train_1[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "params_tree = {'max_depth': [10, None],\n",
    "               'min_samples_split': [2, 5],\n",
    "               'min_samples_leaf': [1, 2]}\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "hyperparameter_tuning(tree, params_tree, X_train_1[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "models_without_scaling = [tree, xgb]\n",
    "name_models_without_scaling = ['Decision Tree Regressor', 'XGB Regressor']\n",
    "\n",
    "train_score, test_score, r2, mae, rmse = [], [], [], [], []\n",
    "\n",
    "for model, model_name in zip(models_without_scaling, name_models_without_scaling):\n",
    "    building_model(model, model_name, X_train_1[features], X_val_1[features])\n",
    "\n",
    "scores_df4 = pd.DataFrame({'model': name_models_without_scaling,\n",
    "                          'train_score': train_score,\n",
    "                          'test_score': test_score,\n",
    "                          'r2_score': r2,\n",
    "                          'mean_absolute_error': mae,\n",
    "                          'root_mean_squared_error': rmse}).sort_values(by = 'r2_score',\n",
    "                                                                        ascending = False).set_index('model')\n",
    "\n",
    "scores_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "scores_df = pd.concat([scores_df3, scores_df4], axis = 0).sort_values(by = 'r2_score',\n",
    "                                                                      ascending = False)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                   min_child_weight = 3, n_estimators = 500)\n",
    "\n",
    "xgb.fit(X_train_1, y_train)\n",
    "y_pred = xgb.predict(X_test_1)\n",
    "\n",
    "print('Training score: %.4f' %xgb.score(X_train_1, y_train))\n",
    "print('Mean Absolute Error: %.4f' %mean_absolute_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: %.4f' %np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Data_Extraction",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "for i, column in enumerate(train_df.columns, 1):\n",
    "    plt.subplot(5, 5, i) \n",
    "    sns.boxplot(y=train_df[column])\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Q1=train_df.quantile(0.25)\n",
    "Q3=train_df.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "lower_bound=Q1-1.5*IQR\n",
    "upper_bound=Q3+1.5*IQR\n",
    "outliers = pd.DataFrame(np.logical_or(train_df < lower_bound, train_df > upper_bound), columns=train_df.columns)\n",
    "outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(x='FloodProbability',data=train_df,kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train=train_df.iloc[:,:20]\n",
    "y_train=train_df['FloodProbability']\n",
    "X_test=test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "pipe=make_pipeline(StandardScaler(),LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'FloodProbability': y_predict\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train= pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for i in features:\n",
    "    print(f' {i} values :',train[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,30))\n",
    "# train.drop(columns = ['id'], inplace = True)\n",
    "\n",
    "for i,col in enumerate(features,1):\n",
    "    plt.subplot(7,3,i)\n",
    "    sns.histplot(data  = train, x = train[col],kde = True, color = 'darkorchid', label = 'Train Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,30))\n",
    "features = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']\n",
    "for i,col in enumerate(features,1):\n",
    "    plt.subplot(7,3,i)\n",
    "    sns.countplot(data  = train, x = train[col], color = 'darkorchid',label = 'Train Data')\n",
    "    sns.countplot(data  = test, x = test[col], color = 'grey',label = 'Test Data')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "\n",
    "# Creating variable to store col names of independent features\n",
    "features = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']\n",
    "\n",
    "# Plot the boxplot for Outlier Detection \n",
    "for i,col in enumerate(features,1):\n",
    "    plt.subplot(4,5,i)\n",
    "    sns.boxplot(data  = train, x = train[col], color = 'darkorchid')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# What is the distribution of flood probability\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.histplot(data = train, x = 'FloodProbability',kde = True, color = 'green',fill = True)\n",
    "plt.title('Flood Probability Distribution Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "sns.heatmap(train[features].corr(),cmap = 'rocket',annot = True, fmt = '0.1f',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "import hyperopt\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cat_params = {\n",
    "    'iterations' : [300,500,700,800,1000],\n",
    "    'learning_rate' : [0.03,0.3,0.1,0.01,0.5,0.05],\n",
    "    'max_depth' : [3,5,7,9,10],\n",
    "    'l2_leaf_reg' : [1,3,5,7,9,12],\n",
    "    'bootstrap_type' : ['Bayessian','Bernoulli'],\n",
    "    'subsample': [0.5,0.6,0.7,0.8,0.9,1],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cat_cv = RandomizedSearchCV(estimator = CatBoostRegressor(), param_distributions = cat_params, cv = 3, scoring = 'r2',verbose = 3,n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cat_cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cat_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# y_cat = catBooster.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# light_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LGBMBooster = LGBMRegressor(n_estimators = 1200, learning_rate = 0.1, lambda_l2 = 1, lambda_l1 = 1, feature_extraction = 0.7, bagging_fraction = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": 49,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'n_estimators' : [200,400, 600,800,1000,1200],\n",
    "    'max_depth' : [1,3,5,7,9],\n",
    "    'subsample' : [0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'max_features' :['Auto','log2','sqrt'],\n",
    "    'learning_rate' : [0.03,0.3,0.1,0.01,0.5,0.05],\n",
    "    'min_samples_leaf' : [2,4,6,8,10],\n",
    "    'min_samples_split':[2,5,8,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": 50,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "gb_cv = RandomizedSearchCV(estimator = GradientBoostingRegressor(), param_distributions = gb_params, cv = 2, n_iter = 10, scoring = 'r2',verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_id": 56,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "checkFeatureImportance(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_id": 58,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "checkFeatureImportance(LGBMBooster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_id": 59,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "checkFeatureImportance(XGBooster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_id": 60,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "## The Separate Models are not giving much better results.\n",
    "## So Now i will use a voting regressor in order to increase the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cell_id": 61,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cell_id": 62,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('cat',catBooster),\n",
    "    ('xg', XGBooster),\n",
    "    ('lgbm',LGBMBooster),\n",
    "    ('gb',gb)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cell_id": 63,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "voter = VotingRegressor(estimators = estimators, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cell_id": 65,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_vote = voter.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_id": 67,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_id": 68,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "final_estimator = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cell_id": 71,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_stack = stack.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cell_id": 73,
    "class": "Data_Extraction",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "voter_result = pd.DataFrame(data = y_vote, index = test['id'],columns = ['FloodProbability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as ltb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")\n",
    "origin_col = test.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print((train.describe().T[\"std\"]).iloc[1:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print((test.describe().T[\"std\"]).iloc[1:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print(\"Train Histogramme\")\n",
    "sns.set(rc={'figure.figsize': (20, 16)})\n",
    "train.hist(color='blue');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(train.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Necessary Packages\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "feats = list(best_features_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def generate_new_data(df, num_samples):\n",
    "    new_data = []\n",
    "    for _ in range(num_samples):\n",
    "        new_row = {}\n",
    "        for col in df.columns:  # Exclure la colonne cible\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            new_row[col] = np.random.normal(mean, std)\n",
    "        new_data.append(new_row)\n",
    "    return pd.DataFrame(new_data)\n",
    "\n",
    "new_data = generate_new_data(train[feats+['FloodProbability']], 1000)\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "augmented_train_df = pd.concat([train, new_data])\n",
    "X_augmented = augmented_train_df[feats]\n",
    "y_augmented = augmented_train_df[\"FloodProbability\"]\n",
    "X_train_aug,  X_test_aug, y_train_aug, y_test_aug = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)\n",
    "\n",
    "model = ltb.LGBMRegressor()\n",
    "model.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "y_pred_aug = model.predict(X_test_aug)\n",
    "\n",
    "mse = mean_squared_error(y_test_aug, y_pred_aug)\n",
    "print(\"Score\", r2_score(y_test_aug, y_pred_aug))\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/input/playground-series-s4e5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.drop(columns=['id'],inplace=True)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "NumCols=df_train.columns\n",
    "NumCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "k=0\n",
    "fig,ax=plt.subplots(nrows=7,ncols=3,figsize=(18,30))\n",
    "for i,fea in enumerate(NumCols[:-1]):\n",
    "    if i==0:\n",
    "        j=0\n",
    "        k=0\n",
    "    elif i%3==0:\n",
    "        j=j+1\n",
    "        k=0\n",
    "    else:\n",
    "        k=k+1\n",
    "\n",
    "    ax[j,k].set_xlabel(fea)\n",
    "    sns.scatterplot(data=df_train,x=df_train[fea],y=df_train['FloodProbability'],ax=ax[j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "df_train.drop(columns=['id'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "NumCols=df_train.select_dtypes(exclude=['object','boolean']).columns\n",
    "NumCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_out=pd.DataFrame()\n",
    "for i in NumCols:\n",
    "    q1=0\n",
    "    q3=0\n",
    "    q1=df_train[i].quantile(.25)\n",
    "    q3=df_train[i].quantile(.75)\n",
    "    iqr=q3-q1\n",
    "    lf=q1-1.5*iqr\n",
    "    uf=q3+1.5*iqr\n",
    "    df_out=df_train[(df_train[i]>=lf) & (df_train[i]<=uf)]\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr=df_train.corr()*100\n",
    "plt.figure(figsize=(30,12))\n",
    "sns.heatmap(corr,mask=np.triu(corr),fmt='.2f',annot=True,cmap=\"Greens\",linewidths=.5, annot_kws={\"size\": 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Xout_train,Xout_test,yout_train,yout_test=train_test_split(Xout,yout,test_size=.3,random_state=42)\n",
    "print(Xout_train.shape,Xout_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Xout1_train,Xout1_test,yout1_train,yout1_test=train_test_split(Xout1,yout1,test_size=.3,random_state=42)\n",
    "print(Xout1_train.shape,Xout1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "df_train.drop(columns=['id'],inplace=True)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test.iloc[:,1:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Extraction",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/working/submission.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 27,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")\n",
    "df_test=pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")\n",
    "#\n",
    "print(\"Train:\",len(df_train))\n",
    "sample_sub=pd.read_csv(\"/kaggle/input/playground-series-s4e5/sample_submission.csv\")\n",
    "#\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "test_df=getFeats(test_df)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 28,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif, RFECV, SequentialFeatureSelector\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier,HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from lightgbm import LGBMClassifier,LGBMRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "num_features=int(np.ceil(1.5*(num_inf+num_red+num_dup)))\n",
    "columns=[f'I_{item}' for item in range(num_inf)]+[f'R_{item}' for item in range(num_red)]+[f'D_{item}' for item in range(num_dup)]  \n",
    "i=0\n",
    "while len(columns)<num_features:\n",
    "    columns.append(f'random_{i}')\n",
    "    i+=1\n",
    "dt_class,y_class=make_classification(n_samples=n_samples,\n",
    "                         n_informative=num_inf,\n",
    "                         n_redundant=num_red,\n",
    "                         n_repeated=num_dup,\n",
    "                         n_features=num_features,\n",
    "                         flip_y=1e-2,\n",
    "                         shuffle=False,\n",
    "                         n_classes=n_classes)\n",
    "dt_class=pd.DataFrame(dt_class,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "dt_gen['random_target']=np.random.normal(y_gen.mean(),y_gen.std(),y_gen.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 29,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "initial_features = list(test_data.drop(['id'], axis = 1).columns)\n",
    "initial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "unique_vals = []\n",
    "for df in [train_data, test_data]:\n",
    "    for col in initial_features:\n",
    "        unique_vals += list(df[col].unique())\n",
    "\n",
    "unique_vals = list(set(unique_vals))\n",
    "unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 30,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "n_repeats, n_splits, seed = 3, 5, 1984\n",
    "target = \"FloodProbability\"\n",
    "\n",
    "import os\n",
    "path, oofs_path = \".\", \"dataset/\"    # when I work on my own PC\n",
    "if os.path.isdir(\"/kaggle/input/\"):  #             on Kaggle\n",
    "    path, oofs_path = \"/kaggle/input\", \"/kaggle/input/pss4e05-dataset-oofs-preds/\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "def score_(y_trn, y_pred):\n",
    "    return r2_score(y_trn, y_pred)\n",
    "\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "end = \"\\033[0m\" # reset\n",
    "\n",
    "bold       = \"\\033[1m\" ; resetbold       = \"\\033[21m\"\n",
    "underline  = \"\\033[4m\" ; resetunderline  = \"\\033[24m\"\n",
    "blink      = \"\\033[5m\" ; resetblink      = \"\\033[25m\"\n",
    "reverse    = \"\\033[7m\" ; resetreverse    = \"\\033[27m\"\n",
    "\n",
    "Default      = \"\\033[39m\" ; Black        = \"\\033[30m\" ; White        = \"\\033[97m\"\n",
    "Red          = \"\\033[31m\" ; LightRed     = \"\\033[91m\"\n",
    "Green        = \"\\033[32m\" ; LightGreen   = \"\\033[92m\"\n",
    "Yellow       = \"\\033[33m\" ; LightYellow  = \"\\033[93m\"\n",
    "Blue         = \"\\033[34m\" ; LightBlue    = \"\\033[94m\"\n",
    "Magenta      = \"\\033[35m\" ; LightMagenta = \"\\033[95m\"\n",
    "Cyan         = \"\\033[36m\" ; LightCyan    = \"\\033[96m\"\n",
    "DarkGray     = \"\\033[90m\" ; LightGray    = \"\\033[37m\"\n",
    "\n",
    "BackgroundDefault     = \"\\033[49m\"  ; BackgroundBlack        = \"\\033[40m\"\n",
    "BackgroundRed         = \"\\033[41m\"  ; BackgroundLightRed     = \"\\033[101m\"\n",
    "BackgroundGreen       = \"\\033[42m\"  ; BackgroundLightGreen   = \"\\033[102m\"\n",
    "BackgroundYellow      = \"\\033[43m\"  ; BackgroundLightYellow  = \"\\033[103m\"\n",
    "BackgroundBlue        = \"\\033[44m\"  ; BackgroundLightBlue    = \"\\033[104m\"\n",
    "BackgroundMagenta     = \"\\033[45m\"  ; BackgroundLightMagenta = \"\\033[105m\"\n",
    "BackgroundCyan        = \"\\033[46m\"  ; BackgroundLightCyan    = \"\\033[106m\"\n",
    "BackgroundDarkGray    = \"\\033[100m\" ; BackgroundLightGray    = \"\\033[47m\"\n",
    "\n",
    "bold_blue = bold + LightBlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{path}/playground-series-s4e5/train.csv', index_col = \"id\")\n",
    "test = pd.read_csv(f'{path}/playground-series-s4e5/test.csv', index_col = \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "models = [f\"xgb{i}\" for i in [8, 10, 11, 12, 13]] + [f\"lgbm{i}\" for i in [5, 9, 16]] + [\n",
    "    f\"cb{i}\" for i in [2, 3, 7, 9, 12, 13]] + [\"bestlgbmcorr\"] + [f\"autog{i}\" for i in [3, 5]]\n",
    "\n",
    "oofs, preds = [], []\n",
    "for r in range(n_repeats):\n",
    "    \n",
    "    for i, m in enumerate(models):\n",
    "        \n",
    "        if i == 0:\n",
    "            oofs.append(pd.read_csv(f\"{oofs_path}oof_{m}_r{r+1}.csv\", index_col = \"id\").rename(columns = {target:m}))\n",
    "            preds.append(pd.read_csv(f\"{oofs_path}pred_{m}_r{r+1}.csv\", index_col = \"id\").rename(columns = {target:m}))\n",
    "        else:\n",
    "            oofs[r] = pd.concat([oofs[r], pd.read_csv(f\"{oofs_path}oof_{m}_r{r+1}.csv\", index_col = \"id\").rename(columns = {target:m})], axis = 1)        \n",
    "            preds[r] = pd.concat([preds[r], pd.read_csv(f\"{oofs_path}pred_{m}_r{r+1}.csv\", index_col = \"id\").rename(columns = {target:m})], axis = 1)        \n",
    "\n",
    "    oofs[r] = oofs[r]\n",
    "    oofs[r][target] = train[target]\n",
    "    preds[r] = preds[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def do_ensemble(train = train, target = target, features = test.columns, test = test, \n",
    "                folds = StratifiedKFold(n_splits = n_splits, random_state = seed, shuffle = True), \n",
    "                my_model = None, digit = 6, lib_metric = \"R2\", do_feat_imp = False):\n",
    "    \n",
    "    feat_imp = FeatureImportance(n_permutations = 2, lib_metric = lib_metric)\n",
    "    val_scores, trn_scores = [], []\n",
    "    oofs = pd.Series(0.0, name = target, index = train.index)\n",
    "    preds = pd.Series(0.0, name = target, index = test.index)\n",
    "    intercept, coefs = [], pd.DataFrame(0.0, index = features, columns = [f\"fold{i+1}\" for i in range(folds.get_n_splits())])\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds.split(train, (train[target]*400).astype(np.int16).astype(\"category\"))):\n",
    "        \n",
    "        X_trn, y_trn = train.loc[trn_idx, features], train.loc[trn_idx, target]\n",
    "        X_val, y_val = train.loc[val_idx, features], train.loc[val_idx, target]\n",
    "            \n",
    "        if (fold) % n_splits == 0:\n",
    "            oof = pd.Series(0.0, name = target, index = train.index)\n",
    "            pred = pd.Series(0.0, name = target, index = test.index)\n",
    "        \n",
    "        # Training\n",
    "        my_model.fit(X_trn, y_trn)\n",
    "        intercept.append(my_model.intercept_) ; coefs[f\"fold{fold+1}\"] += my_model.coef_\n",
    "\n",
    "        # Score & prediction\n",
    "        trn_scores.append(score_(y_trn, my_model.predict(X_trn)))\n",
    "        oof.iloc[val_idx] += my_model.predict(X_val)\n",
    "        val_scores.append(score_(y_val, oof.loc[val_idx]))\n",
    "        oofs.iloc[val_idx] += oof.loc[val_idx]\n",
    "        pred += my_model.predict(test[features]) / folds.get_n_splits()\n",
    "            \n",
    "        scores = []\n",
    "        for f in features:\n",
    "            scores.append(score_(y_val, X_val[f]))\n",
    "        \n",
    "        my_color = Green if np.max(scores) < val_scores[-1:][0] else LightRed\n",
    "        print(f\"    Fold {fold + 1:2} : {lib_metric} {val_scores[-1:][0]:.{digit}f} (max : {my_color}{np.max(scores):.{digit}f}{end} - \", end='')\n",
    "        my_color = Green if score_(y_val, X_val[features].mean(axis = 1)) < val_scores[-1:][0] else LightRed\n",
    "        print(f\"mean : {my_color}{np.mean(scores):.{digit}f}{end})\", end='')        \n",
    "        print(f\" | in train {trn_scores[-1:][0]:.{digit}f}\", end='')\n",
    "        print(f' | Overfitting {trn_scores[-1:][0] - val_scores[-1:][0]:.{digit}f}')\n",
    "        if (fold + 1) % n_splits == 0:\n",
    "            print(f'  {bold}Repeat {(fold + 1 ) // n_splits:2} : OOF {lib_metric} {bold_blue}{score_(train[target], oof):.{digit}f}{end} | ', end='')\n",
    "            print(f'Mean {lib_metric} {np.mean(val_scores[-n_splits:]):.{digit}f}')\n",
    "            preds += pred\n",
    "        \n",
    "        # Feature importance\n",
    "        if do_feat_imp:\n",
    "            for feat in features:\n",
    "                for i in range(feat_imp.n_permutations):\n",
    "                    df = X_val.copy()\n",
    "                    df[feat] = pd.Series(np.random.permutation(df[feat]), index=df.index).astype(X_val[feat].dtypes)\n",
    "                    feat_imp.append(feat, score_(y_val, my_model.predict(df)), val_scores[-1:][0])\n",
    "    # end of loop\n",
    "    \n",
    "    scores = []\n",
    "    for f in features:\n",
    "        scores.append(score_(train[target], train[f]))\n",
    "    print(f'OOF {lib_metric} {bold_blue}{score_(train[target], oofs):.{digit}f}{end}', end='')\n",
    "    my_color = Green if np.max(scores) < score_(train[target], oofs) else LightRed\n",
    "    print(f' (max was {my_color}{np.max(scores):.{digit}f}{end} - ', end='')\n",
    "    my_color = Green if np.mean(scores) < score_(train[target], oofs) else LightRed\n",
    "    print(f'mean {my_color}{np.mean(scores):.{digit}f}{end}) | ', end='')\n",
    "    print(f'Mean {lib_metric} : {bold_blue}{np.mean(val_scores):.{digit}f}{end}({bold+Red}±{np.std(val_scores):.{digit}f}){end}) | ', end='')\n",
    "    print(f'Overfitting : {np.mean(trn_scores)-np.mean(val_scores):.{digit}f}')\n",
    "    \n",
    "    feat_imp.plot()\n",
    "    \n",
    "    return {\"intercept\":intercept, \"coefs\":coefs.transpose(), \"oofs_score\":score_(train[target], oofs), \"oofs\":oofs, \"preds\":preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# データの読込\n",
    "train = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\", index_col=\"id\")\n",
    "print(train.shape)\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\", index_col=\"id\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# trainデータの確認\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# testデータの確認\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 欠損値の確認：trainデータ\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 欠損値の確認：testデータ\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 重複値の確認\n",
    "\n",
    "print(train.drop(columns=\"FloodProbability\").duplicated().sum())\n",
    "print(test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "min_max_tr = train.describe().T[['min', 'max']].add_suffix('_train')\n",
    "min_max_te = test.describe().T[['min', 'max']].add_suffix('_test')\n",
    "nunique_tr = train.nunique().rename('nunique_train')\n",
    "nunique_te = test.nunique().rename('nunique_test')\n",
    "counts_tr = pd.Series({ft: [train[ft].value_counts().round(3).iloc[:5].to_dict()] for ft in train.columns}, name='top_5_counts_train')\n",
    "counts_te = pd.Series({ft: [test[ft].value_counts().round(3).iloc[:5].to_dict()] for ft in test.columns}, name='top_5_counts_test')\n",
    "\n",
    "min_max_count = pd.concat(\n",
    "    [\n",
    "        min_max_tr,\n",
    "        min_max_te,\n",
    "        nunique_tr,\n",
    "        nunique_te,\n",
    "        counts_tr,\n",
    "        counts_te,\n",
    "    ],\n",
    "    axis=1)\n",
    "min_max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 各特徴量の分布\n",
    "\n",
    "n_bins = 50\n",
    "histplot_params = {\n",
    "    'kde': True,\n",
    "    'alpha': 0.4,\n",
    "    'stat': 'percent',\n",
    "    'bins': n_bins\n",
    "}\n",
    "\n",
    "columns = test.columns[test.dtypes!=object]\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(columns)/n_cols)\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(20, n_rows*4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    plot_axes = [ax[i]]\n",
    "    sns.kdeplot(train[column], label='Train', ax=ax[i])\n",
    "    sns.kdeplot(test[column], label='Test', ax=ax[i])\n",
    "    \n",
    "    ax[i].set_title(f'{column} Distribution')\n",
    "    ax[i].set_xlabel(None)\n",
    "    \n",
    "    plot_axes = [ax[i]]\n",
    "    handles = []\n",
    "    labels = []\n",
    "    for plot_ax in plot_axes:\n",
    "        handles += plot_ax.get_legend_handles_labels()[0]\n",
    "        labels += plot_ax.get_legend_handles_labels()[1]\n",
    "        plot_ax.legend().remove()\n",
    "\n",
    "for i in range(i+1, len(ax)):\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "fig.suptitle('Dataset Feature Distributions\\n\\n\\n', ha='center', fontweight='bold', fontsize=25)\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.95), fontsize=25, ncol=3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 実際に実行\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 特徴量のリスト\n",
    "features = [\"MonsoonIntensity\", \"TopographyDrainage\", \"RiverManagement\", \"Deforestation\", \n",
    "            \"Urbanization\", \"ClimateChange\", \"DamsQuality\", \"Siltation\", \n",
    "            \"AgriculturalPractices\", \"Encroachments\", \"IneffectiveDisasterPreparedness\", \n",
    "            \"DrainageSystems\", \"CoastalVulnerability\", \"Landslides\", \"Watersheds\", \n",
    "            \"DeterioratingInfrastructure\", \"PopulationScore\", \"WetlandLoss\", \n",
    "            \"InadequatePlanning\", \"PoliticalFactors\"]\n",
    "\n",
    "# MinMaxScalerのインスタンス化\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# trainデータの特徴量のスケーリング\n",
    "train[features] = scaler.fit_transform(train[features])\n",
    "\n",
    "# testデータの特徴量のスケーリング\n",
    "test[features] = scaler.transform(test[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# sample_submission.csvの読込\n",
    "sub = pd.read_csv(\"/kaggle/input/playground-series-s4e5/sample_submission.csv\")\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Save a file_path to data\n",
    "train_data_path = \"/kaggle/input/playground-series-s4e5/train.csv\"\n",
    "test_data_path = \"/kaggle/input/playground-series-s4e5/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Read & Store data\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Display basic info about the datasets\n",
    "print(\"Train Data Shape:\", train_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Display first 5 rows of train data\n",
    "print(\"Train Data Preview:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"Train Data Summary Statistics:\")\n",
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Train Data Missing Values:\")\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(train_data['FloodProbability'], bins=20, kde=True)\n",
    "plt.title('Distribution of FloodProbability')\n",
    "plt.xlabel('FloodProbability')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Encoding categorical features and target variable\n",
    "label_encoders = {}\n",
    "for column in train_data.select_dtypes(include=['object']).columns:\n",
    "    if column != 'FloodProbability':\n",
    "        le = LabelEncoder()\n",
    "        combined_data = pd.concat([train_data[column], test_data[column]], axis=0).fillna('missing')\n",
    "        le.fit(combined_data)\n",
    "        train_data[column] = le.transform(train_data[column].fillna('missing'))\n",
    "        test_data[column] = le.transform(test_data[column].fillna('missing'))\n",
    "        label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le_target = LabelEncoder()\n",
    "train_data['FloodProbability'] = le_target.fit_transform(train_data['FloodProbability'])\n",
    "label_encoders['FloodProbability'] = le_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Drop 'id' column from both training and test data\n",
    "X_train = train_data.drop(columns=['FloodProbability', 'id'])\n",
    "y_train = train_data['FloodProbability']\n",
    "test_features = test_data.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Calculate R2 score\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "print(f\"Validation R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'FloodProbability': test_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Print first five rows of submission file\n",
    "print(\"First five rows of submission file: \", submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Extraction",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset = pd.read_csv(\"/kaggle/input/playground-series-s4e5/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    addfeatures = df.columns.tolist()\n",
    "    df['std_features'] = df[addfeatures].std(axis=1)\n",
    "    df['mean_features'] = 0.1*df[addfeatures].mean(axis=1)\n",
    "    df['median_features'] = 0.1*df[addfeatures].median(axis=1)\n",
    "    df['max_features'] = df[addfeatures].max(axis=1)\n",
    "    df['min_features'] = df[addfeatures].min(axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df=flood_dataset.copy()\n",
    "flood_dataset_df.drop(['id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df = flood_dataset_df\n",
    "df1 = df.drop([\"FloodProbability\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df = add_features(df1)\n",
    "y = df[\"FloodProbability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def add_more_features(flood_dataset_df):\n",
    "    flood_dataset_df['weather'] = - flood_dataset_df['MonsoonIntensity'] - flood_dataset_df['ClimateChange']\n",
    "    flood_dataset_df['structure'] = flood_dataset_df['TopographyDrainage'] + flood_dataset_df['RiverManagement'] - flood_dataset_df['Deforestation'] + flood_dataset_df['DamsQuality'] + flood_dataset_df['Encroachments'] + flood_dataset_df['DrainageSystems'] - flood_dataset_df['Watersheds'] - flood_dataset_df['DeterioratingInfrastructure'] + flood_dataset_df['WetlandLoss'] \n",
    "    flood_dataset_df['population'] = - flood_dataset_df['Urbanization'] * flood_dataset_df['PopulationScore']\n",
    "    flood_dataset_df['soil_infrastructure'] = - flood_dataset_df['Siltation'] + flood_dataset_df['AgriculturalPractices'] - flood_dataset_df['Landslides']\n",
    "    flood_dataset_df['preparedness'] = - flood_dataset_df['IneffectiveDisasterPreparedness'] + flood_dataset_df['CoastalVulnerability'] - flood_dataset_df['InadequatePlanning'] - flood_dataset_df['PoliticalFactors'] \n",
    "    return flood_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.to_csv('train_without_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "del flood_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")\n",
    "\n",
    "flood_dataset_df=flood_dataset.copy()\n",
    "flood_dataset_df.drop(['id'], axis = 1, inplace = True)\n",
    "\n",
    "df = flood_dataset_df\n",
    "flood_dataset_df = add_features(df)\n",
    "\n",
    "flood_dataset_df = add_more_features(flood_dataset_df)\n",
    "\n",
    "flood_dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df = pd.read_csv(\"/kaggle/working/train_without_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df = pd.read_csv(\"/kaggle/working/test_data.csv\")\n",
    "flood_dataset_df = add_manipulated_features(flood_dataset_df)\n",
    "flood_dataset_df.to_csv('test_data_featured.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_test = pd.read_csv(\"/kaggle/working/test_data_featured.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "catb = CatBoostRegressor()\n",
    "catb_model = catb.fit(X_train, Y_train,\n",
    "                     verbose = 0)\n",
    "\n",
    "y_pred_catb = catb_model.predict(X_test)\n",
    "\n",
    "catb_rmse_calculator = np.sqrt(mean_squared_error(np.log(Y_test), np.log(y_pred_catb)))\n",
    "catboost_r2_metric = r2_score(y_test, y_pred_catb)\n",
    "\n",
    "print(f\"Category Boosting RMSE Metric: {catb_rmse_calculator}\")\n",
    "print(f\"Category Boosting R-squared Metric: {catboost_r2_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Extraction",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "testddata = pd.read_csv(\"/kaggle/working/test_data_featured.csv\")\n",
    "\n",
    "input_test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "\n",
    "id_no = input_test['id']\n",
    "test_pred_lgbm = lgbm_model.predict(testddata)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': id_no,\n",
    "    'FloodProbability': test_pred_lgbm\n",
    "})\n",
    "\n",
    "print(submission.head())\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "# Options\n",
    "pd.set_option('display.max_columns',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv')\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv', index_col='id')\n",
    "df_test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "  sns.catplot(data=df_train, x=col, kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = df_train.drop('FloodProbability', axis=1)\n",
    "y = df_train['FloodProbability']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Extraction",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Transform",
    "notebook_id": 0,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame\n",
    "cleaned_train_df = df.drop(['id', 'FloodProbability'], axis=1).copy()\n",
    "\n",
    "# Define the multiplier for identifying outliers based on standard deviation\n",
    "multiplier = 3\n",
    "\n",
    "# Calculate the upper outlier threshold for each column\n",
    "upper_thresholds = cleaned_train_df.mean() + multiplier * cleaned_train_df.std()\n",
    "\n",
    "# Identify rows containing outliers in each column\n",
    "outlier_rows = (cleaned_train_df > upper_thresholds).any(axis=1)\n",
    "\n",
    "# Drop outlier rows from the DataFrame\n",
    "cleaned_train_df = cleaned_train_df[~outlier_rows]\n",
    "cleaned_target_df = df.loc[~outlier_rows,'FloodProbability']\n",
    "\n",
    "# Print the shape of the cleaned DataFrame\n",
    "print(\"Original DataFrame shape:\", df.shape)\n",
    "print(\"Cleaned DataFrame shape:\", cleaned_train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Transform",
    "notebook_id": 0,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def r2_score_metric(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return 1 - SS_res/(SS_tot + K.epsilon())\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_train_df, cleaned_target_df, test_size=0.3, random_state=11)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l1_l2(\n",
    "                l1=hp.Float('l1_' + str(i), 1e-5, 1e-2, sampling='LOG'),\n",
    "                l2=hp.Float('l2_' + str(i), 1e-5, 1e-2, sampling='LOG')\n",
    "            )\n",
    "        ))\n",
    "        model.add(tf.keras.layers.Dropout(hp.Float('dropout_' + str(i), 0.0, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')\n",
    "        ),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[r2_score_metric]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create a tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train, epochs=11, validation_split=0.2)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score of the best model:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Data_Transform",
    "notebook_id": 2,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Transform",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(df[train_columns + [\"FloodProbability\"]].corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Transform",
    "notebook_id": 2,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.barh(train_columns, model_catboost_base.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Transform",
    "notebook_id": 3,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Define base features by dropping the target variable column\n",
    "BASE_FEATURES = df.drop(columns='flood_probability').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Transform",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Calculate weights for each feature group\n",
    "weights = [1/len(value) for key, value in feature_list.items()]\n",
    "\n",
    "# Initialize columns with zeros for each feature group\n",
    "for key in feature_list.keys():\n",
    "    df[key] = 0\n",
    "\n",
    "# Apply weighted sum for each feature group\n",
    "for weight, (name, features) in zip(weights, feature_list.items()):\n",
    "    for feature in features:\n",
    "        df[name] += (df[feature] * weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Transform",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df[feature_list.keys()].head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Transform",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a figure with custom size\n",
    "plt.figure(figsize=(11, 10))\n",
    "\n",
    "# Generate a heatmap of correlations for numerical columns, excluding base features\n",
    "sns.heatmap(\n",
    "    df.drop(columns=BASE_FEATURES).select_dtypes(include=np.number).corr(),  # DataFrame correlation matrix\n",
    "    annot=True,  # Show correlation values in cells\n",
    "    cmap=['#638889', '#678788', '#6c8788', '#718788', '#768788', '#7b8788', '#808788', '#858788', '#8a8787', '#8f8787', \n",
    "          '#948687', '#998687', '#9e8687', '#a38687', '#a88687', '#ac8686', '#b18686', '#b68686', '#bb8686', '#c08686',\n",
    "          '#c58586', '#ca8586', '#cf8585', '#d48585', '#d98585', '#de8585', '#e38585', '#e88585', '#ed8585', '#f28585'],\n",
    "    annot_kws={\"fontsize\": 7}  # Annotation font size\n",
    ")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Data_Transform",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate the root mean squared error (RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Create a custom scorer 'rmse_scorer' using make_scorer\n",
    "# 'greater_is_better=False' indicates that lower values of the scoring function are better\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Transform",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Access the best estimator from the grid search\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Access the regressor from the best estimator\n",
    "regressor = best_estimator.named_steps['model']\n",
    "\n",
    "# Check if the regressor has feature_importances_ attribute\n",
    "if hasattr(regressor, 'feature_importances_'):\n",
    "    # Get feature importances\n",
    "    feature_importances = regressor.feature_importances_\n",
    "    \n",
    "    # Access the 'features' pipeline from the best estimator\n",
    "    features_pipeline = best_estimator.named_steps['features']\n",
    "    \n",
    "    # Manually specify the feature names after transformation\n",
    "    numeric_feature_names = X_train.columns.tolist()  # Assuming all columns are numeric\n",
    "    \n",
    "    # Calculate the total importance sum of all features\n",
    "    total_importance = feature_importances.sum()\n",
    "    \n",
    "    # Calculate the percentage contribution of each feature\n",
    "    feature_importance_percentage = (feature_importances / total_importance) * 100\n",
    "    \n",
    "    # Create a DataFrame with the percentage contribution of each feature\n",
    "    features_percentage_df = pd.DataFrame({'Feature': numeric_feature_names,\n",
    "                                           'Importance (%)': feature_importance_percentage})\n",
    "    \n",
    "    # Sort the DataFrame by importance in descending order\n",
    "    features_percentage_df = features_percentage_df.sort_values(by='Importance (%)', ascending=False)\n",
    "    \n",
    "    # Display the top features with their percentage contributions\n",
    "    print(features_percentage_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "from time import time\n",
    "from joblib import load, dump\n",
    "from matplotlib.ticker import MaxNLocator,MultipleLocator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# For output text color\n",
    "end = \"\\033[0m\" ; bold = \"\\033[1m\" ; LightRed = \"\\033[91m\" ; LightBlue = \"\\033[94m\"\n",
    "BlueBold = LightBlue + bold ; RedBold = LightRed + bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def make_features(data, train_data=True, scaler=None):\n",
    "    '''\n",
    "    For feature engineering of both train and test data. Returns the data with new features added in standardized form.\n",
    "    The standardization parameters are learned only from the train data so as to avoid data leakage.\n",
    "    '''\n",
    "    df = data.copy()\n",
    "    with tqdm(total=12 ,desc='processing...') as pbar:\n",
    "        sort_cols = [f'col{i+1}' for i in range(len(orig_features))]\n",
    "        \n",
    "        df['sum'] = df.sum(axis=1)         \n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['linear_ft'] = df['sum'].isin(np.arange(72, 76)).astype(int)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['median'] = df[orig_features].median(axis=1)         \n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['std'] = df[orig_features].std(axis=1)         \n",
    "        pbar.update(1)\n",
    "        \n",
    "        df[sort_cols] = np.sort(df[orig_features].values, axis=1)         \n",
    "        pbar.update(1)\n",
    "        \n",
    "        for u in unique:\n",
    "            df[f'count_{u}'] = (df[orig_features] == u).sum(axis=1)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['mean'] = df[orig_features].mean(axis=1)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['max'] = df[orig_features].max(axis=1) \n",
    "        pbar.update(1)               \n",
    "        \n",
    "        df['min'] = df[orig_features].min(axis=1)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['skew'] = df[orig_features].skew(axis=1)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        df['kurt'] = df[orig_features].kurt(axis=1)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if train_data:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df)\n",
    "            df[df.columns.to_list()] = scaler.transform(df.values)\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            df[df.columns.to_list()] = scaler.transform(df.values)\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train_df, scaler = make_features(X)\n",
    "dump(train_df,'train_df.joblib')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_df, _ = make_features(test.iloc[:,1:], train_data=False, scaler=scaler)\n",
    "dump(test_df,'test_df.joblib')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "fixed_params_xgrf = {\n",
    "    'device'       : 'cuda',\n",
    "    'booster'      : 'gbtree',\n",
    "    'learning_rate': 1,\n",
    "    'tree_method'  : 'hist',\n",
    "    'n_estimators' : 1,\n",
    "    'objective'    : 'reg:squarederror',\n",
    "    'n_jobs'       : -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Transform",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Creating the predictions dataset for final prediction\n",
    "ensemble_train = np.c_[xgr_tr_pred1, cbr_tr_pred2, lgr_tr_pred3, xgrf_tr_pred4, ridge_tr_pred5]\n",
    "ensemble_test = np.c_[xgr_ts_pred1, cbr_ts_pred2, lgr_ts_pred3, xgrf_ts_pred4, ridge_ts_pred5]\n",
    "\n",
    "np.save('ensemble_train.npy', ensemble_train)\n",
    "np.save('ensemble_test.npy', ensemble_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Transform",
    "notebook_id": 5,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df_train.drop(\"FloodProbability\" , axis = 1)\n",
    "y = df_train[['FloodProbability']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Transform",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade tensorflow-gpu\n",
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Transform",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_model.save(\"best_flood_prediction_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# df.hist(bins=50,figsize=(20,15))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "new_df=pd.concat([df,feature+0.3,feature+0.3,feature+0.3,df.median(axis=1)+0.2,feature*df.median(axis=1)],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "testf=pd.concat([test,test.mean(axis=1)+0.3,test.mean(axis=1)+0.3,test.mean(axis=1)+0.3,test.median(axis=1)+0.2,test.mean(axis=1)*test.median(axis=1)],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "new_df.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# new_y=pd.concat([y,y.mean()],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xtrain,xval,ytrain,yval=train_test_split(new_df,y,random_state=0,test_size=0.15,stratify=y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Data_Transform",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model2=LinearRegression(fit_intercept=True)\n",
    "# model2=RandomForestRegressor(random_state=0,oob_score=True,warm_start=True,ccp_alpha=0.3)\n",
    "# model=KMeans()\n",
    "# model2=GradientBoostingRegressor()\n",
    "# model5=PolynomialFeatures(degree=2, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df, threshold=1.5):\n",
    "    outlier_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Calculate the first and third quartiles\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        \n",
    "        # Interquartile range (IQR)\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        # Define the lower and upper bounds for outlier detection\n",
    "        lower_bound = q1 - threshold * iqr\n",
    "        upper_bound = q3 + threshold * iqr\n",
    "        \n",
    "        # Find outliers\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        \n",
    "        if not outliers.empty:\n",
    "            outlier_columns.append(col)\n",
    "    \n",
    "    return outlier_columns\n",
    "\n",
    "outlier_cols = detect_outliers(df_train)\n",
    "print(\"Columns with outliers: \\n\", outlier_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Plot numerical columns against 'FloodProbability' using scatter plots\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=df_train, x=col, y='FloodProbability', alpha=0.7)\n",
    "    plt.title(f'{col} vs. FloodProbability')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('FloodProbability')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot categorical columns against 'FloodProbability' using bar plots\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=df_train, x=col, y='FloodProbability', alpha=0.7)\n",
    "    plt.title(f'{col} vs. FloodProbability')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('FloodProbability')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''No need to perform standardization / normalization as all the features have a small and comparable scale'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "correlation_matrix = df_train.corr(method='pearson')\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df_train.drop(\"FloodProbability\" , axis = 1)\n",
    "y = df_train[['FloodProbability']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = rf_model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df = pd.concat([id, output_df], axis=1)\n",
    "# output_df.name = 'FloodProbability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Data_Transform",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Transform",
    "notebook_id": 8,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "X = X.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Transform",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Data_Transform",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Transform",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Splitting on test and train data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Transform",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Predicting test data for submission\n",
    "predictions = model.predict(df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Transform",
    "notebook_id": 10,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "lr_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(lr_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Transform",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "lr_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(lr_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Transform",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "gbr_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(gbr_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": 49,
    "class": "Data_Transform",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Transform scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 11,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    col_iqr = iqr(train[col])\n",
    "    Q1, Q3 = np.quantile(train[col], [0.25, 0.75])\n",
    "    \n",
    "    # Convert outliers to np.nan\n",
    "    train.loc[train[col] < (Q1 - 1.5*col_iqr), col] = np.nan\n",
    "    train.loc[train[col] > (Q3 + 1.5*col_iqr), col] = np.nan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X[X.columns] = scaler.fit_transform(X)\n",
    "test[test.columns] = scaler.transform(test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =  987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Transform",
    "notebook_id": 13,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Checking Skewness of each feature\n",
    "\n",
    "skew = {}\n",
    "for col in num_cols:\n",
    "    skewness = data[col].skew()\n",
    "    skew[col] = [skewness]\n",
    "    print(f'Skewness of {col} feature is {skewness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Check how many data points are outliers\n",
    "data_check = data.copy()\n",
    "check_ouliers = pd.DataFrame()\n",
    "\n",
    "for col in num_cols:\n",
    "    q1=data_check[col].quantile(0.25)\n",
    "    q3=data_check[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if_outliers = data_check[(data_check[col] < q1 - 1.5*iqr) | (data_check[col] > q3 + 1.5*iqr)]\n",
    "    check_ouliers = pd.concat([check_ouliers, if_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Transform",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Check if there are duplicated data point\n",
    "check_ouliers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Transform",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Determine the number of outliers in the dataset\n",
    "print(len(check_ouliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Transform",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    features = df.columns.tolist()\n",
    "    sorted_new =  np.sort(df.values, axis=1)\n",
    "    df['mean_features'] = 0.1 * df[features].mean(axis=1)\n",
    "    df['std_features'] = df[features].std(axis=1)\n",
    "    df['max_features'] = df[features].max(axis=1)\n",
    "    df['min_features'] = df[features].min(axis=1)\n",
    "    df['median_features'] = 0.1 * df[features].median(axis=1)\n",
    "    df['sum_features'] = 0.1 * df[features].sum(axis=1)\n",
    "    df1 = pd.concat([df, pd.DataFrame(sorted_new, index=df.index)], axis=1)\n",
    "    df1 = df1.drop(features, axis=1)\n",
    "    df1.columns = df1.columns.astype('str')\n",
    "    return df\n",
    "\n",
    "data_new = transform(data_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Transform",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = data_new\n",
    "y = label\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Transform",
    "notebook_id": 14,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "pipe=Pipeline([('ss',ss)])\n",
    "X_train_t=pipe.fit_transform(X_train)\n",
    "X_test_t=pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 15,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge, SGDRegressor, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor,AdaBoostRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif, RFE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(train_set.drop(columns=[\"FloodProbability\"]))\n",
    "y = pd.DataFrame(train_set[\"FloodProbability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([X, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df[\"Mon-Climate\"] = (full_df[\"MonsoonIntensity\"] + full_df[\"ClimateChange\"])/2\n",
    "full_df[\"Topo-Drainage\"] = (full_df[\"TopographyDrainage\"] + full_df[\"DrainageSystems\"])/2\n",
    "full_df[\"Deforest-LandS\"] = (full_df[\"Deforestation\"] + full_df[\"Landslides\"])/2\n",
    "full_df[\"Urban-Planning\"] = (full_df[\"Urbanization\"] + full_df[\"InadequatePlanning\"])/2\n",
    "full_df[\"Dams-Siltation\"] = (full_df[\"DamsQuality\"] + full_df[\"Siltation\"])/2\n",
    "full_df[\"Wetland-CoastVul\"] = (full_df[\"WetlandLoss\"] + full_df[\"CoastalVulnerability\"])/2\n",
    "full_df[\"RivMan- WaterS\"] = (full_df[\"RiverManagement\"] + full_df[\"Watersheds\"])/2\n",
    "full_df[\"Agri-Encro\"] = (full_df[\"AgriculturalPractices\"] + full_df[\"Encroachments\"])/2\n",
    "full_df[\"InefDisPrep-DetInfra\"] = (full_df[\"IneffectiveDisasterPreparedness\"] + full_df[\"DeterioratingInfrastructure\"])/2\n",
    "full_df[\"PopScore-Urban\"] = (full_df[\"PopulationScore\"] + full_df[\"Urbanization\"])/2\n",
    "full_df[\"PFactors-Planning\"] = (full_df[\"PoliticalFactors\"] + full_df[\"InadequatePlanning\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df['mean'] = 0.1 * full_df[columns].mean(axis=1)\n",
    "full_df['std'] = 0.1 * full_df[columns].std(axis=1)\n",
    "full_df['var'] = 0.1 * full_df[columns].var(axis=1)\n",
    "full_df['skew'] = full_df[columns].skew(axis=1)\n",
    "full_df['kurtosis_features'] = full_df[columns].kurtosis(axis=1)\n",
    "full_df['cv'] = full_df['std'] / full_df['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df['geom_mean'] = 0.1 * np.exp(np.log(full_df[columns]+1).mean(axis=1))\n",
    "full_df['harm_mean'] = 0.1 * len(columns) / (1 / (full_df[columns]+1)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    " full_df['double'] = 0.1 * np.sqrt(np.sum(np.tril(full_df[columns].to_numpy()[:, :, None] * full_df[columns].to_numpy()[:, None, :], k=-1), axis=(1,2)) /380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# full_df_dum = pd.get_dummies(full_df[['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', \n",
    "#                               'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "#                               'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "#                               'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "#                               'CoastalVulnerability', 'Landslides', 'Watersheds', \n",
    "#                               'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "#                               'InadequatePlanning', 'PoliticalFactors']], columns = columns)\n",
    "# full_df = full_df.join(full_df_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# full_df_X_scale  = full_df.loc[:, list(cat_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "full_df[['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', \n",
    "                              'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "                              'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "                              'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "                              'CoastalVulnerability', 'Landslides', 'Watersheds', \n",
    "                              'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "                              'InadequatePlanning', 'PoliticalFactors']] = scaler.fit_transform(full_df[['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', \n",
    "                                                                                                         'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "                                                                                                         'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "                                                                                                         'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "                                                                                                         'CoastalVulnerability', 'Landslides', 'Watersheds', \n",
    "                                                                                                         'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "                                                                                                         'InadequatePlanning', 'PoliticalFactors']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "full_df[[\"Mon-Climate\", \"Topo-Drainage\", \"Deforest-LandS\", \"Urban-Planning\", \n",
    "           \"Dams-Siltation\", \"Wetland-CoastVul\", \"RivMan- WaterS\", \"Agri-Encro\", \n",
    "            \"InefDisPrep-DetInfra\", \"PopScore-Urban\", \"PFactors-Planning\"]] = scaler.fit_transform(full_df[[\"Mon-Climate\", \"Topo-Drainage\", \"Deforest-LandS\", \"Urban-Planning\", \n",
    "                                                                                                            \"Dams-Siltation\", \"Wetland-CoastVul\", \"RivMan- WaterS\", \"Agri-Encro\",\n",
    "                                                                                                            \"InefDisPrep-DetInfra\", \"PopScore-Urban\", \"PFactors-Planning\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = full_df[0:1117957]\n",
    "test_set = full_df[1117957:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for_corr = X.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr_df_X = pd.DataFrame(for_corr.corr()['FloodProbability'].drop('FloodProbability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr_df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sorted_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr_more_02 = list(sorted_corr[(sorted_corr > 0.2) | (sorted_corr < -0.2) ].dropna().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr_more_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "full_df['mean_highest'] = 0.1 * full_df[corr_more_02].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X = full_df[0:1117957]\n",
    "test_set = full_df[1117957:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for_corr = X.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sorted_corr.loc[[\"mean_highest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_id": 54,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# bc_model = BaggingRegressor(estimator=rf_model, n_estimators=100)\n",
    "# bc_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = bc_model.predict(X_test)\n",
    "# print(f\"Training score {bc_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# BagReg_score = r2_score(y_test,y_pred)\n",
    "# BagReg_Tscore = bc_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cell_id": 64,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_id": 70,
    "class": "Data_Transform",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# y_pred_cat = pd.DataFrame(y_pred_cat)\n",
    "# output_cat = test_set_id\n",
    "# output_cat[\"FloodProbability\"] = pd.DataFrame(y_pred_cat)\n",
    "# output_cat = output_cat.set_index(\"id\")\n",
    "# output_cat.to_csv(\"FloodProbability_OHE_project_FEng_cat_fulldf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Data_Transform",
    "notebook_id": 17,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "y_pred_sc = lm.predict(x_test_scaled)\n",
    "submission = pd.DataFrame({'id':flood_test.id, \"FloodProbability\" : y_pred_sc})\n",
    "submission.to_csv( \"submission.csv\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 18,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Transform",
    "notebook_id": 19,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "train.set_index(train['id'], inplace=True)\n",
    "train.drop(columns=['id'], inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Transform",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# do the same for the test\n",
    "test.set_index(test['id'], inplace=True)\n",
    "test.drop(columns=['id'], inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(tr_loss))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Transform",
    "notebook_id": 20,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Transform",
    "notebook_id": 21,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Drop id column from dataset\n",
    "\n",
    "Data.drop(columns = ['id'], inplace = True)\n",
    "Data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Transform",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for col in Data.columns:\n",
    "  Data[col] = np.log(Data[col] + 1)  # Add 1 to avoid log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Transform",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a heatmap/correlation matrix\n",
    "plt.figure(figsize=(20, 9))\n",
    "sns.heatmap(Data.corr(), annot=True)\n",
    "plt.title(\"Heatmap/Correlation Matrix of Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Transform",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Floodprobability = pd.DataFrame(FloodProbability)\n",
    "\n",
    "Submission = pd.concat([test['id'], Floodprobability], axis = 1)\n",
    "\n",
    "Submission.to_csv('Submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Transform",
    "notebook_id": 21,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Transform",
    "notebook_id": 22,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "X_train_1 = X_train.copy()\n",
    "X_val_1 = X_val.copy()\n",
    "X_test_1 = X_test.copy()\n",
    "\n",
    "X_train_1['weather_average'] = round(X_train_1[weather_features].mean(axis = 1), 2)\n",
    "X_val_1['weather_average'] = round(X_val_1[weather_features].mean(axis = 1), 2)\n",
    "X_test_1['weather_average'] = round(X_test_1[weather_features].mean(axis = 1), 2)\n",
    "\n",
    "X_train_1['infrastructure_average'] = round(X_train_1[infrastructure_features].mean(axis = 1), 2)\n",
    "X_val_1['infrastructure_average'] = round(X_val_1[infrastructure_features].mean(axis = 1), 2)\n",
    "X_test_1['infrastructure_average'] = round(X_test_1[infrastructure_features].mean(axis = 1), 2)\n",
    "\n",
    "X_train_1['environmental_average'] = round(X_train_1[environmental_features].mean(axis = 1), 2)\n",
    "X_val_1['environmental_average'] = round(X_val_1[environmental_features].mean(axis = 1), 2)\n",
    "X_test_1['environmental_average'] = round(X_test_1[environmental_features].mean(axis = 1), 2)\n",
    "\n",
    "X_train_1['human_average'] = round(X_train_1[human_features].mean(axis = 1), 2)\n",
    "X_val_1['human_average'] = round(X_val_1[human_features].mean(axis = 1), 2)\n",
    "X_test_1['human_average'] = round(X_test_1[human_features].mean(axis = 1), 2)\n",
    "\n",
    "X_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Transform",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "features = ['human_average', 'environmental_average', 'infrastructure_average', 'weather_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Data_Transform",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_1[features].copy()\n",
    "X_val_scaled = X_val_1[features].copy()\n",
    "X_test_scaled = X_test_1[features].copy()\n",
    "\n",
    "# Implement min-max scaling to make the range of all variables between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "X_val_scaled = scaler.transform(X_val_scaled)\n",
    "X_test_scaled = scaler.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Transform",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "params_kn = {'n_neighbors' : [5, 7, 9],\n",
    "             'weights' : ['uniform', 'distance'],\n",
    "             'metric' : ['minkowski', 'euclidean', 'manhattan']}\n",
    "kn_reg = KNeighborsRegressor()\n",
    "hyperparameter_tuning(kn_reg, params_kn, X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "features = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "scaler = StandardScaler()\n",
    "X = train[features]\n",
    "X = scaler.fit_transform(X)\n",
    "test_new = test.drop(columns = ['id'])\n",
    "X_test = scaler.fit_transform(test_new)\n",
    "y = train[['FloodProbability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cat_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "light_params = {\n",
    "    'n_estimators' :[200,400,600,800,1000,1200],\n",
    "    'learning_rate' : [0.03,0.3,0.1,0.01,0.5,0.05],\n",
    "    'bagging_fraction' : [0.5,0.7,1],\n",
    "    'feature_fraction': [0.4,0.5,0.7,0.9,1],\n",
    "    'lambda_l1' : [1,3,5,7,9,12],\n",
    "    'lambda_l2' : [1,3,5,7,9,12]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "light_cv = RandomizedSearchCV(estimator = LGBMRegressor(), param_distributions = light_params, cv = 3, scoring = 'r2',verbose = 1,n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# light_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_id": 54,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_id": 55,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a function in order to show bar plots \n",
    "\n",
    "def checkFeatureImportance(model, top_n = 20, random_state = 42):\n",
    "    \n",
    "    if hasattr(model, 'coef_'):\n",
    "        importances = np.round(model.coef_,2)\n",
    "        method = 'models\\'s coefficients'\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        importances = np.round(model.feature_importances_,2)\n",
    "        method = 'Feature importances'\n",
    "    \n",
    "    else:\n",
    "        result = permutation_importance(model, X, y, scoring = 'r2', n_jobs = -1)\n",
    "        importances = result.importances_mean\n",
    "        method = 'Permutation importance'\n",
    "    \n",
    "    cols = [i for i in features]\n",
    "    \n",
    "    importance_df = pd.DataFrame({'Feature': cols, 'Importance' : importances })\n",
    "    importance_df.head(top_n).plot(kind='bar', x='Feature', y='Importance', legend=False,color = 'darkorchid')\n",
    "    plt.title(f'Top {top_n} Feature Importance ({method})')\n",
    "    plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cell_id": 57,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "checkFeatureImportance(catBooster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cell_id": 66,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cell_id": 72,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cell_id": 74,
    "class": "Data_Transform",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "stack_result = pd.DataFrame(data = y_stack, index = test['id'],columns = ['FloodProbability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Transform",
    "notebook_id": 25,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "## 1. Creating new features\n",
    "\n",
    "def mode_or_mean(row):\n",
    "    mode = row.mode()\n",
    "    if len(mode) == 0:  # No mode found\n",
    "        return row.mean()\n",
    "    else:\n",
    "        return mode.iloc[0]\n",
    "\n",
    "\n",
    "train[\"sum\"] = train[origin_col].mean(axis=1)\n",
    "test[\"sum\"] = test[origin_col].mean(axis=1)\n",
    "train[\"max*min\"] = train[origin_col].max(axis=1)*train[origin_col].min(axis=1)\n",
    "test[\"max*min\"] = test[origin_col].max(axis=1) * test[origin_col].min(axis=1)\n",
    "train[\"min\"] = train[origin_col].min(axis=1)\n",
    "test[\"min\"] = test[origin_col].min(axis=1)\n",
    "train[\"max-min\"] = train[origin_col].max(axis=1)-train[origin_col].min(axis=1)\n",
    "test[\"max-min\"] = test[origin_col].max(axis=1) -  test[origin_col].min(axis=1)\n",
    "train[\"max\"] = train[origin_col].max(axis=1)\n",
    "test[\"max\"] = test[origin_col].max(axis=1)\n",
    "train[\"var\"] = train[origin_col].var(axis=1)\n",
    "test[\"var\"] = test[origin_col].var(axis=1)\n",
    "train[\"median\"] = train[origin_col].median(axis=1)\n",
    "test[\"median\"] = test[origin_col].median(axis=1)\n",
    "train[\"mean*median\"] = train[origin_col].mean(axis=1)*train[origin_col].median(axis=1)\n",
    "test[\"mean*median\"] = test[origin_col].mean(axis=1) * test[origin_col].median(axis=1)\n",
    "train[\"sum-div-max\"] = train[origin_col].sum(axis=1)/train[origin_col].max(axis=1)\n",
    "test[\"sum-div-max\"] = test[origin_col].sum(axis=1)/test[origin_col].max(axis=1)\n",
    "train[\"std-max\"] = train[origin_col].std(axis=1)-train[origin_col].max(axis=1)\n",
    "test[\"std-max\"] = test[origin_col].std(axis=1)-test[origin_col].max(axis=1)\n",
    "train[\"sum-std\"] = train[origin_col].sum(axis=1)/train[origin_col].std(axis=1)\n",
    "test[\"sum-std\"] = test[origin_col].sum(axis=1)/test[origin_col].std(axis=1)\n",
    "train[\"sum-var\"] = train[origin_col].sum(axis=1) / train[origin_col].var(axis=1)\n",
    "train[\"sum-median\"] = train[origin_col].sum(axis=1) / train[origin_col].median(axis=1)\n",
    "train[\"sum-median-std\"] = train[origin_col].sum(axis=1) / (train[origin_col].median(axis=1) - train[origin_col].std(axis=1))\n",
    "#train[\"mode\"] = train[origin_col].apply(lambda row: mode_or_mean(row), axis=1)\n",
    "test[\"sum-var\"] = test[origin_col].sum(axis=1) / test[origin_col].var(axis=1)\n",
    "test[\"sum-median\"] = test[origin_col].sum(axis=1) / test[origin_col].median(axis=1)\n",
    "test[\"sum-median-std\"] = test[origin_col].sum(axis=1) / (test[origin_col].median(axis=1) - test[origin_col].std(axis=1))\n",
    "#test[\"mode\"] = test[origin_col].apply(lambda row: mode_or_mean(row), axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "train.fillna(0, inplace=True)\n",
    "test.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Selecting features\n",
    "## Methode 1: SelectKBest with f_regression\n",
    "selector = SelectKBest(k=10) # nombre of features\n",
    "X_train_kbest = selector.fit_transform(X_train, y_train)\n",
    "best_features_kbest = X.columns[selector.get_support()]\n",
    "\n",
    "# Methode 2: RFE (Recursive Feature Elimination) with Linear Regression\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=10) \n",
    "selector = selector.fit(X_train, y_train)\n",
    "best_features_rfe = X.columns[selector.support_]\n",
    "\n",
    "# Methode 3: SequentialFeatureSelector (SFS) with Lasso\n",
    "lasso = Lasso(alpha=0.01) \n",
    "sfs = SFS(lasso, k_features=10, forward=True, scoring='neg_mean_squared_error', cv=5)\n",
    "sfs = sfs.fit(X_train.values, y_train.values)\n",
    "best_features_sfs = X.columns[list(sfs.k_feature_idx_)]\n",
    "\n",
    "# Showing results\n",
    "print(\"Meilleures caractéristiques avec SelectKBest:\", best_features_kbest)\n",
    "print(\"Meilleures caractéristiques avec RFE:\", best_features_rfe)\n",
    "print(\"Meilleures caractéristiques avec SequentialFeatureSelector:\", best_features_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Xout=df_out.iloc[:,:-1]\n",
    "yout=df_out['FloodProbability']\n",
    "Xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "RFEModel = LinearRegression()\n",
    "rfe=RFE(RFEModel)\n",
    "rfe.fit(Xout,yout)\n",
    "selected_indices = [i for i,data in enumerate(rfe.support_) if data == True]\n",
    "selected_column_name = [NumCols[i] for i in selected_indices]\n",
    "selected_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Xout1=df_out[selected_column_name]\n",
    "yout1=df_out['FloodProbability']\n",
    "print(Xout1.shape,yout1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Xall=df_train.iloc[:,:-1]\n",
    "yall=df_train.iloc[:,-1]\n",
    "print(Xall.shape,yall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "StdSca = StandardScaler()\n",
    "Xall_train_std=StdSca.fit_transform(Xall_train)\n",
    "Xall_test_std=StdSca.transform(Xall_test)\n",
    "Xall_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "RFReg = RandomForestRegressor()\n",
    "RFReg.fit(Xall_train_std, yall_train)\n",
    "RFReg_pred =RFReg.predict(Xall_test_std)\n",
    "mseRF=mean_squared_error(yall_test,RFReg_pred)\n",
    "rmseRF=np.sqrt(mseRF)\n",
    "maeRF=mean_absolute_error(yall_test,RFReg_pred)\n",
    "r2scoreRF = r2_score(yall_test,RFReg_pred)\n",
    "print('Mean Squared Error : ', mseRF)\n",
    "print('Root Mean Squared Error : ', rmseRF)\n",
    "print('Mean Absolute Error : ', maeRF)\n",
    "print('R2 Score : ' ,r2scoreRF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Transform",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_predictions = LR.predict(test_std)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Data_Transform",
    "notebook_id": 27,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "num_cols=['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']\n",
    "\n",
    "unique_vals = []\n",
    "for df in [df_train, df_test]:\n",
    "    for col in num_cols:\n",
    "        unique_vals += list(df[col].unique())\n",
    "\n",
    "unique_vals = list(set(unique_vals))\n",
    "#\n",
    "def getFeats(df):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    df['ClimateAnthropogenicInteraction'] = (df['MonsoonIntensity'] + df['ClimateChange']) * (df['Deforestation'] + df['Urbanization'] + df['AgriculturalPractices'] + df['Encroachments'])\n",
    "    df['InfrastructurePreventionInteraction'] = (df['DamsQuality'] + df['DrainageSystems'] + df['DeterioratingInfrastructure']) * (df['RiverManagement'] + df['IneffectiveDisasterPreparedness'] + df['InadequatePlanning'])\n",
    "    \n",
    "    df['sum'] = df[num_cols].sum(axis=1)\n",
    "    df['std']  = df[num_cols].std(axis=1)\n",
    "    df['mean'] = df[num_cols].mean(axis=1)\n",
    "    df['max']  = df[num_cols].max(axis=1)\n",
    "    df['min']  = df[num_cols].min(axis=1)\n",
    "    df['mode'] = df[num_cols].mode(axis=1)[0]\n",
    "    df['median'] = df[num_cols].median(axis=1)\n",
    "    df['q_25th'] = df[num_cols].quantile(0.25, axis=1)\n",
    "    df['q_75th'] = df[num_cols].quantile(0.75, axis=1)\n",
    "    df['skew'] = df[num_cols].skew(axis=1)\n",
    "    df['kurt'] = df[num_cols].kurt(axis=1)\n",
    "    df['sum_72_76'] = df['sum'].isin(np.arange(72, 76))\n",
    "    for i in range(10,100,10):\n",
    "        df[f'{i}th'] = df[num_cols].quantile(i/100, axis=1)\n",
    "    df['harmonic'] = len(num_cols) / df[num_cols].apply(lambda x: (1/x).mean(), axis=1)\n",
    "    df['geometric'] = df[num_cols].apply(lambda x: x.prod()**(1/len(x)), axis=1)\n",
    "    df['zscore'] = df[num_cols].apply(lambda x: (x - x.mean()) / x.std(), axis=1).mean(axis=1)\n",
    "    df['cv'] = df['std'] / df['mean']\n",
    "    df['Skewness_75'] = (df[num_cols].quantile(0.75, axis=1) - df[num_cols].mean(axis=1)) / df[num_cols].std(axis=1)\n",
    "    df['Skewness_25'] = (df[num_cols].quantile(0.25, axis=1) - df[num_cols].mean(axis=1)) / df[num_cols].std(axis=1)\n",
    "    df['2ndMoment'] = df[num_cols].apply(lambda x: (x**2).mean(), axis=1)\n",
    "    df['3rdMoment'] = df[num_cols].apply(lambda x: (x**3).mean(), axis=1)\n",
    "    df['entropy'] = df[num_cols].apply(lambda x: -1*(x*np.log(x)).sum(), axis=1)\n",
    "    df['rng'] = df['max'] - df['min']\n",
    "    \n",
    "    for v in unique_vals:\n",
    "        if v<16:\n",
    "            df['cnt_{}'.format(v)] = (df[num_cols] == v).sum(axis=1)\n",
    "    \n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Data_Transform",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train['typ']=0\n",
    "df_test['typ']=1\n",
    "#\n",
    "df_all=pd.concat([df_train,df_test],axis=0)\n",
    "df_all=getFeats(df_all)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Data_Transform",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_train=df_all[df_all['typ']==0]\n",
    "df_test=df_all[df_all['typ']==1]\n",
    "#\n",
    "cleaned_train_df=df_train.drop(['id','FloodProbability','typ'],axis=1)\n",
    "cleaned_target_df=df_train['FloodProbability']\n",
    "#\n",
    "feats=list(cleaned_trained_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "transpose=lambda x: list(zip(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def classify_columns(X,cat_limit=10,print_output=False):\n",
    "    '''\n",
    "    Naive features classificator\n",
    "    '''\n",
    "    \n",
    "    total=X.shape[0]\n",
    "\n",
    "    categorical_cols=[(item,X[item].nunique()) for item in X.columns  if str(X[item].dtype) in ['object','category'] ]\n",
    "   \n",
    "    catcols= [i[0] for i in categorical_cols]\n",
    "    discrete_cols=[(item,X[item].nunique()) for item in X.columns  if not item in catcols and X[item].nunique()<cat_limit and 'int' in str(type(X[item][0])) ] \n",
    "    discols=[i[0] for i in discrete_cols]\n",
    "    numerical_cols=[(item,X[item].nunique()) for item in X.columns if not (item in catcols or item in discols)]\n",
    "    numcols=[i[0] for i in numerical_cols]\n",
    "    X[numcols]=X[numcols].astype(float)\n",
    "    nan_cols=[(item,count) for item in X.columns if (count:=sum(X[item].isnull()))]\n",
    "    duplicates=X.duplicated().sum()\n",
    "    if print_output:\n",
    "        print(f'{total} rows')\n",
    "        if nan_cols:\n",
    "            print('Cols. with NaN:')\n",
    "            for item in nan_cols:\n",
    "                print(f'\\t{item[0]:>20}({\"Cat.\" if item[0] in catcols else \"Num.\"}): {item[1]} ({item[1]/total:.2%})')\n",
    "        if categorical_cols:\n",
    "            print('\\nCategorical cols.:')\n",
    "            for item in categorical_cols:\n",
    "                print(f'\\t{item[0]:>20}: {X[item[0]].unique()}')\n",
    "        if discrete_cols:\n",
    "            print('\\nDiscrete cols.:')\n",
    "            for item in discrete_cols:\n",
    "                print(f'\\t{item[0]:>20}: {X[item[0]].unique()}')\n",
    "        if numerical_cols:\n",
    "            print('\\nNumerical cols.:')\n",
    "\n",
    "            for item in numerical_cols:\n",
    "                print(f'\\t{item[0]:>20}({X[item[0]].dtype}): {item[1]} unique values')\n",
    "        if duplicates:\n",
    "            print(f'Duplicated rows: {duplicates} ({duplicates/total:.2%})')\n",
    "        else:\n",
    "            print('No duplicates')\n",
    "            \n",
    "    \n",
    "    return {'nan_cols':[item[0] for item in  nan_cols],\n",
    "            'cat_cols':[item[0] for item in categorical_cols],\n",
    "            'disc_cols':[item[0] for item in discrete_cols],\n",
    "            'num_cols':[item[0] for item in numerical_cols]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "#sklearn make_classification stuff\n",
    "n_samples=10000\n",
    "n_classes=3 # #classes in the categorical output\n",
    "num_inf=3 # # informative features\n",
    "num_red=3  # # redundant features\n",
    "num_dup=3  # # duplicated features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def sample_distribution(p,n=1):\n",
    "    '''\n",
    "    Simple function for sample an empirical probability distribution function.\n",
    "    Input:\n",
    "        p: list of float or int. Empirical distribution function. Each number correspond to frequency of a class. The classes are taken as 0, 1, ...\n",
    "        n: number of samples\n",
    "    Output:\n",
    "        int list. n random numbers accordingly p\n",
    "    '''\n",
    "    p=np.array(p)\n",
    "    p=p/p.sum()\n",
    "    p=p.cumsum()\n",
    "    #print(p)\n",
    "    r=[]\n",
    "    for i in range(n):\n",
    "        throw=np.random.uniform()\n",
    "        r.append(len([item for item in p if item<throw]))\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "empirical=dict(Counter(y_class))\n",
    "empirical={key:empirical[key] for key in range(n_classes)}\n",
    "\n",
    "dt_class['random_target']=sample_distribution(list(empirical.values()),n=y_class.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model=LGBMClassifier(verbose=-1,random_state=0)#HistGradientBoostinggenifier(random_state=0)#\n",
    "n_jobs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "dt_reg['random_target']=np.random.normal(y_reg.mean(),y_reg.std(),y_reg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "n_features=9\n",
    "n_cols=int(np.ceil(1.5*n_features))\n",
    "\n",
    "n_samples=10000\n",
    "\n",
    "\n",
    "dt_gen=pd.DataFrame(np.random.poisson(5,(n_samples,n_features)),columns=[f'feat_{i}' for i in range(n_features)]) \n",
    "\n",
    "std=dt_gen.mean(axis=1).std()\n",
    "\n",
    "rcols=[f'random_{i}' for i in range(n_cols-n_features)]\n",
    "\n",
    "dt_gen[rcols]=np.random.poisson(5,(n_samples,n_cols-n_features))#np.random.normal(0,std,(n_samples,n_cols-n_features))\n",
    "\n",
    "y_gen=0.075*(np.mean(dt_gen.iloc[:,:n_features],axis=1)+np.random.normal(0,std*0.5,(n_samples,)))+0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Data_Transform",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for data in [dt_gen]:\n",
    "    orig=[item for item in data.columns if 'feat' in item]\n",
    "    sort_cols=[f'rank_{i}' for i in range(len(orig))]\n",
    "    data[sort_cols]=np.sort(data[orig],axis=1)\n",
    "    #data['Sum']=np.sum(data[orig],axis=1)\n",
    "    #data['average']=np.mean(data[orig],axis=1)\n",
    "    data['st_dev']=np.std(data[orig],axis=1)\n",
    "    #data['skew']=skew(data[orig],axis=1)\n",
    "    #data['kurt']=kurtosis(data[orig],axis=1)\n",
    "    data['Q25']=np.quantile(data[orig],0.25,axis=1)\n",
    "    data['Q50']=np.quantile(data[orig],0.5,axis=1)\n",
    "    data['Q75']=np.quantile(data[orig],0.75,axis=1)\n",
    "    data['IQR']=data['Q75']-data['Q25']\n",
    "    #data['LogProd']=np.log((1+data[orig]).prod(axis=1))\n",
    "    data[[\"nb_inf4\", \"nb_inf3\", \"nb_inf2\", \"nb_sup6\", \"nb_sup7\", \"nb_sup8\"]] = 0\n",
    "    for f in orig:\n",
    "        data.loc[data[f] <=4 , \"nb_inf4\"] += 1\n",
    "        data.loc[data[f] >=6 , \"nb_sup6\"] += 1\n",
    "        data.loc[data[f] <=3 , \"nb_inf3\"] += 1\n",
    "        data.loc[data[f] >=7 , \"nb_sup7\"] += 1\n",
    "        data.loc[data[f] <=2 , \"nb_inf2\"] += 1\n",
    "        data.loc[data[f] >=8 , \"nb_sup8\"] += 1\n",
    "    data=data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Data_Transform",
    "notebook_id": 29,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Data_Transform",
    "notebook_id": 31,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# 実際に実行\n",
    "\n",
    "# trainデータに対する処理\n",
    "train[\"Urbanization_Drainage_Ratio\"] = train.apply(lambda row: row[\"DrainageSystems\"] / row[\"Urbanization\"] if row[\"Urbanization\"] != 0 else 0, axis=1)\n",
    "\n",
    "# testデータに対する処理\n",
    "test[\"Urbanization_Drainage_Ratio\"] = test.apply(lambda row: row[\"DrainageSystems\"] / row[\"Urbanization\"] if row[\"Urbanization\"] != 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Data_Transform",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 対数変換によるスケーリング\n",
    "\n",
    "# 対数変換対象の特徴量リスト\n",
    "features = [\n",
    "    \"MonsoonIntensity\",\n",
    "    \"TopographyDrainage\",\n",
    "    \"RiverManagement\",\n",
    "    \"Deforestation\",\n",
    "    \"Urbanization\",\n",
    "    \"ClimateChange\",\n",
    "    \"DamsQuality\",\n",
    "    \"Siltation\",\n",
    "    \"AgriculturalPractices\",\n",
    "    \"Encroachments\",\n",
    "    \"IneffectiveDisasterPreparedness\",\n",
    "    \"DrainageSystems\",\n",
    "    \"CoastalVulnerability\",\n",
    "    \"Landslides\",\n",
    "    \"Watersheds\",\n",
    "    \"DeterioratingInfrastructure\",\n",
    "    \"PopulationScore\",\n",
    "    \"WetlandLoss\",\n",
    "    \"InadequatePlanning\",\n",
    "    \"PoliticalFactors\"\n",
    "]\n",
    "\n",
    "# trainデータに対する対数変換\n",
    "for feature in features:\n",
    "    train[feature] = np.log1p(train[feature])\n",
    "\n",
    "# testデータに対する対数変換\n",
    "for feature in features:\n",
    "    test[feature] = np.log1p(test[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Transform",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# モデルの構築\n",
    "target = \"FloodProbability\"\n",
    "X = train.drop(columns=target)\n",
    "y = train[target]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    learning_rate=0.3,\n",
    "    max_depth=5,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.9)\n",
    "regressor = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Data_Transform",
    "notebook_id": 32,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Initialize RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Data_Transform",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prepare the submission file\n",
    "test_ids = test_data['id']\n",
    "test_features = test_data.drop(columns=['id', 'FloodProbability'])  # Exclude 'FloodProbability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Data_Transform",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = rf_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "flood_dataset_df = add_more_features(flood_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df[\"FloodProbability\"]=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def add_manipulated_features(df):    \n",
    "    df['all_row_MonsoonIntensity'] = df['MonsoonIntensity'] / df['MonsoonIntensity'].mean()   \n",
    "    df['all_row_TopographyDrainage'] = df['TopographyDrainage'] / df['TopographyDrainage'].mean() \n",
    "    df['all_row_RiverManagement'] = df['RiverManagement'] / df['RiverManagement'].mean() \n",
    "    df['all_row_Deforestation'] = df['Deforestation'] / df['Deforestation'].mean() \n",
    "    df['all_row_Urbanization'] = df['Urbanization'] / df['Urbanization'].mean() \n",
    "    df['all_row_ClimateChange'] = df['ClimateChange'] / df['ClimateChange'].mean() \n",
    "    df['all_row_DamsQuality'] = df['DamsQuality'] / df['DamsQuality'].mean() \n",
    "    df['all_row_Siltation'] = df['Siltation'] / df['Siltation'].mean() \n",
    "    df['all_row_AgriculturalPractices'] = df['AgriculturalPractices'] / df['AgriculturalPractices'].mean() \n",
    "    df['all_row_Encroachments'] = df['Encroachments'] / df['Encroachments'].mean() \n",
    "    df['all_row_IneffectiveDisasterPreparedness'] = df['IneffectiveDisasterPreparedness'] / df['IneffectiveDisasterPreparedness'].mean()\n",
    "    df['all_row_DrainageSystems'] = df['DrainageSystems'] / df['DrainageSystems'].mean() \n",
    "    df['all_row_CoastalVulnerability'] = df['CoastalVulnerability'] / df['CoastalVulnerability'].mean() \n",
    "    df['all_row_Landslides'] = df['Landslides'] / df['Landslides'].mean() \n",
    "    df['all_row_Watersheds'] = df['Watersheds'] / df['Watersheds'].mean() \n",
    "    df['all_row_DeterioratingInfrastructure'] = df['DeterioratingInfrastructure'] / df['DeterioratingInfrastructure'].mean() \n",
    "    df['all_row_PopulationScore'] = df['PopulationScore'] / df['PopulationScore'].mean() \n",
    "    df['all_row_WetlandLoss'] = df['WetlandLoss'] / df['WetlandLoss'].mean()\n",
    "    df['all_row_InadequatePlanning'] = df['InadequatePlanning'] / df['InadequatePlanning'].mean() \n",
    "    df['all_row_PoliticalFactors'] = df['PoliticalFactors'] / df['PoliticalFactors'].mean() \n",
    "    df['all_row_weather'] = df['weather'] / df['weather'].mean() \n",
    "    df['all_row_structure'] = df['structure'] / df['structure'].mean()\n",
    "    df['all_row_population'] = df['population'] / df['population'].mean() \n",
    "    df['all_row_soil_infrastructure'] = df['soil_infrastructure'] / df['soil_infrastructure'].mean() \n",
    "    df['all_row_preparedness'] = df['preparedness'] / df['preparedness'].mean() \n",
    "    \n",
    "    df['ClimateImpact'] = df['MonsoonIntensity'] + df['ClimateChange']\n",
    "    df['AnthropogenicPressure'] = df['Deforestation'] + df['Urbanization'] + df['AgriculturalPractices'] + df['Encroachments']\n",
    "    df['InfrastructureQuality'] = df['DamsQuality'] + df['DrainageSystems'] + df['DeterioratingInfrastructure']\n",
    "    df['CoastalVulnerabilityTotal'] = df['CoastalVulnerability'] + df['Landslides']\n",
    "    df['PreventiveMeasuresEfficiency'] = df['RiverManagement'] + df['IneffectiveDisasterPreparedness'] + df['InadequatePlanning']\n",
    "    df['EcosystemImpact'] = df['WetlandLoss'] + df['Watersheds']\n",
    "    df['SocioPoliticalContext'] = df['PopulationScore'] * df['PoliticalFactors']\n",
    "\n",
    "\n",
    "    df['FloodVulnerabilityIndex'] = (df['AnthropogenicPressure'] + df['InfrastructureQuality'] +\n",
    "                                     df['CoastalVulnerabilityTotal'] + df['PreventiveMeasuresEfficiency']) / 4\n",
    "    \n",
    "    df['PopulationDensityImpact'] = df['PopulationScore'] * (df['Urbanization'] + df['Encroachments'])\n",
    "    \n",
    "    df['DeforestationUrbanizationRatio'] = df['Deforestation'] / df['Urbanization']\n",
    "    \n",
    "    df['AgriculturalEncroachmentImpact'] = df['AgriculturalPractices'] * df['Encroachments']\n",
    "    \n",
    "    df['DamDrainageInteraction'] = df['DamsQuality'] * df['DrainageSystems']\n",
    "    \n",
    "    df['LandslideSiltationInteraction'] = df['Landslides'] * df['Siltation']\n",
    "    \n",
    "    df['WatershedWetlandRatio'] = df['Watersheds'] / df['WetlandLoss']\n",
    "    \n",
    "    df['PoliticalPreparednessInteraction'] = df['PoliticalFactors'] * df['IneffectiveDisasterPreparedness']\n",
    "    \n",
    "    \n",
    "    df['TopographyDrainageSiltation'] = df['TopographyDrainage'] + df['Siltation']\n",
    "    \n",
    "    df['ClimateAnthropogenicInteraction'] = df['ClimateImpact'] * df['AnthropogenicPressure']\n",
    "    \n",
    "    df['InfrastructurePreventionInteraction'] = df['InfrastructureQuality'] * df['PreventiveMeasuresEfficiency']\n",
    "    \n",
    "    df['CoastalEcosystemInteraction'] = df['CoastalVulnerabilityTotal'] * df['EcosystemImpact']\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df = add_manipulated_features(flood_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.to_csv('train_preprocessing.csv', index=False)\n",
    "del flood_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "del flood_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df = pd.read_csv(\"/kaggle/working/train_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "flood_dataset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "dataX = flood_dataset_df.drop(['FloodProbability'], axis = 1)\n",
    "datay = flood_dataset_df['FloodProbability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Data_Transform",
    "notebook_id": 33,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataX, datay, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Hyperparam_Tuning",
    "notebook_id": 0,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "best_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Hyperparam_Tuning",
    "notebook_id": 0,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_hps.values.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Hyperparam_Tuning",
    "notebook_id": 0,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def build_fixed_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(242, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(12, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[r2_score_metric]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "fixed_model = build_fixed_model()\n",
    "\n",
    "# Print the summary of the model\n",
    "fixed_model.summary()\n",
    "\n",
    "# Train the model\n",
    "fixed_model.fit(X_train_scaled, y_train, epochs=5, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Hyperparam_Tuning",
    "notebook_id": 0,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Evaluate the model on the test set\n",
    "y_pred = fixed_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print detailed metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R² Score of the fixed model:\", r2)\n",
    "print(\"Mean Squared Error of the fixed model:\", mse)\n",
    "print(\"Mean Absolute Error of the fixed model:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Hyperparam_Tuning",
    "notebook_id": 0,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "\n",
    "test1_df = test_df.drop('id',axis=1)\n",
    "\n",
    "# 3. Make Predictions\n",
    "X_test = scaler.transform(test1_df)  # Preprocess the test data\n",
    "predictions = fixed_model.predict(X_test)  # Make predictions\n",
    "\n",
    "# 4. Prepare Submission File\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],  # Assuming 'id' is the identifier column\n",
    "    'FloodProbability': predictions.flatten()  # Assuming 'FloodProbability' is the target column\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_tuner(model, X, y, XGB=False):\n",
    "    \n",
    "    r2_scores = []\n",
    "    for trn_idx,val_idx in kf.split(X, y.astype(int)):\n",
    "        x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        if XGB: x_trn, x_val = cp.array(x_trn), cp.array(x_val)\n",
    "        \n",
    "        model.fit(x_trn, y_trn)\n",
    "        y_prd = model.predict(x_val)\n",
    "        fold_r2 = skm.r2_score(y_val, y_prd)\n",
    "        r2_scores.append(fold_r2)\n",
    "        \n",
    "    return np.mean(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "fixed_params_xgr = {\n",
    "    'device'      : 'cuda',\n",
    "    'n_estimators': 500,\n",
    "    'tree_method' : 'hist',\n",
    "    'objective'   : 'reg:squarederror',\n",
    "    'n_jobs'      : -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate':     trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "        'max_depth':         trial.suggest_int('max_depth', 1, 12),\n",
    "        'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.05, 1),\n",
    "        'subsample':         trial.suggest_float('subsample', 0.05, 1),\n",
    "        'min_child_weight':  trial.suggest_float('min_child_weight', 1, 20)\n",
    "    }\n",
    "    \n",
    "    gc.collect()\n",
    "    xgr = XGBRegressor(**params, **fixed_params_xgr)\n",
    "    r2_score = cross_validate_tuner(xgr, X, y, XGB=True)\n",
    "    \n",
    "    return r2_score\n",
    "\n",
    "TPESampler = optuna.samplers.TPESampler(multivariate=True, group=True)\n",
    "optimize_r2_xgr = optuna.create_study(direction='maximize', sampler=TPESampler, study_name='Optimizing R2 for XGBRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "optimize_r2_xgr.optimize(objective, timeout=3*60*60, show_progress_bar=True)\n",
    "dump(optimize_r2_xgr,'Optimizing R2 for XGBRegressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "fixed_params_ctr = {\n",
    "    'verbose'       : False,\n",
    "    'task_type'     : 'GPU',\n",
    "    'thread_count'  : -1,\n",
    "    'iterations'    : 500,\n",
    "    'max_bin'       : 2540,\n",
    "    'bootstrap_type': 'Bernoulli'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate':     trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "        'depth':             trial.suggest_int('depth', 1, 10),\n",
    "        'subsample':         trial.suggest_float('subsample', 0.05, 1),\n",
    "        'min_data_in_leaf':  trial.suggest_float('min_data_in_leaf', 1, 100)\n",
    "    }\n",
    "    \n",
    "    gc.collect()\n",
    "    cbr = CatBoostRegressor(**params, **fixed_params_ctr)\n",
    "    r2_score = cross_validate_tuner(cbr, X, y)\n",
    "    \n",
    "    return r2_score\n",
    "\n",
    "TPESampler = optuna.samplers.TPESampler(multivariate=True, group=True)\n",
    "optimize_r2_cbr = optuna.create_study(direction='maximize', sampler=TPESampler, study_name='Optimizing R2 for CatBoostRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "optimize_r2_cbr.optimize(objective, timeout=3*60*60, show_progress_bar=True)\n",
    "dump(optimize_r2_cbr,'Optimizing R2 for CatBoostRegressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "fixed_params_lbr = {\n",
    "    'verbosity'   : -1,\n",
    "    'device'      : 'gpu',\n",
    "    'n_jobs'      : -1,\n",
    "    'n_estimators': 500,\n",
    "    'objective'   : 'regression',\n",
    "    'metric'      : 'rmse',\n",
    "    'bagging_freq': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate':    trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "        'num_leaves':       trial.suggest_int('num_leaves', 2, 2**8),\n",
    "        'subsample':        trial.suggest_float('subsample', 0.05, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.05, 1),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "    }\n",
    "    \n",
    "    gc.collect()\n",
    "    lbr = LGBMRegressor(**params, **fixed_params_lbr)\n",
    "    r2_score = cross_validate_tuner(lbr, X, y)\n",
    "    \n",
    "    return r2_score\n",
    "\n",
    "TPESampler = optuna.samplers.TPESampler(multivariate=True, group=True)\n",
    "optimize_r2_lbr = optuna.create_study(direction='maximize', sampler=TPESampler, study_name='Optimizing R2 for LGBMRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "optimize_r2_lbr.optimize(objective, timeout=3*60*60, show_progress_bar=True)\n",
    "dump(optimize_r2_lbr,'Optimizing R2 for LGBMRegressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "optimize_r2_xgrf.optimize(objective, timeout=3*60*60, show_progress_bar=True)\n",
    "dump(optimize_r2_xgrf,'Optimizing R2 for XGRF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'alpha':    trial.suggest_float('alpha', 1e-6, 1e2, log=True)\n",
    "    }\n",
    "    \n",
    "    ridge = Ridge(**params)\n",
    "    r2_score = cross_validate_tuner(ridge, X, y)\n",
    "    \n",
    "    return r2_score\n",
    "\n",
    "TPESampler = optuna.samplers.TPESampler()\n",
    "optimize_r2_ridge = optuna.create_study(direction='maximize', sampler=TPESampler, study_name='Optimizing R2 for Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "optimize_r2_ridge.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "dump(optimize_r2_ridge,'Optimizing R2 for Ridge.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=7, shuffle=True, random_state=77)\n",
    "FOLDS = 7\n",
    "\n",
    "def cross_validate_predict(model, X, y, test_data, repeat=2):\n",
    "    '''\n",
    "    Function to make the train preds and test preds using cross validation.\n",
    "    The resultant ensemble of preds will be further used to make the final test prediction.\n",
    "    '''\n",
    "    start_time = time()\n",
    "    scores = []\n",
    "    oof_preds_full = np.full_like(y, np.nan, dtype=float)\n",
    "    test_pred_final = np.zeros(len(test_data), dtype=float)\n",
    "    \n",
    "    for fold,(train_idx, val_idx) in enumerate(kf.split(X, y.astype(str))):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        y_val_pred = np.zeros_like(y_val, dtype=float)\n",
    "        y_pred = np.zeros(len(test_data), dtype=float)\n",
    "        \n",
    "        for i in range(repeat):\n",
    "            m = clone(model)\n",
    "            if repeat > 1:\n",
    "                mm = m\n",
    "                if isinstance(mm, Pipeline):\n",
    "                    mm = mm[-1]\n",
    "                mm.set_params(random_state=i)\n",
    "            m.fit(X_train, y_train)\n",
    "            y_val_pred += m.predict(x_val)\n",
    "            y_pred += m.predict(test_data)\n",
    "        y_val_pred /= repeat\n",
    "        y_pred /= repeat\n",
    "        \n",
    "        score = skm.r2_score(y_val, y_val_pred)\n",
    "        print(f'# Fold {fold}: R2 Score = {score:0.5f}')\n",
    "        scores.append(score)\n",
    "        oof_preds_full[val_idx] = y_val_pred\n",
    "        test_pred_final += y_pred\n",
    "        \n",
    "    test_pred_final /= FOLDS\n",
    "    \n",
    "    total_time = time() - start_time\n",
    "    if isinstance(m, Pipeline):\n",
    "        model_name = m[-1].__class__.__name__\n",
    "    else:\n",
    "        model_name = m.__class__.__name__\n",
    "        \n",
    "    print(f'{BlueBold}# Mean R2 Score = {np.mean(scores):0.5f} {RedBold}± {np.std(scores):0.5f} {BlueBold}for {model_name}\\n'\n",
    "          f'Time Elapsed: {np.round((total_time / 60),0)} Min {end}\\n')\n",
    "\n",
    "    return oof_preds_full, test_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Getting the best parameters obtained from Hyperparameter Tuning\n",
    "xgr_params = optimize_r2_xgr.best_trial.params\n",
    "cbr_params = optimize_r2_cbr.best_trial.params\n",
    "lbr_params = optimize_r2_lbr.best_trial.params\n",
    "xgrf_params = optimize_r2_xgrf.best_trial.params\n",
    "ridge_params = optimize_r2_ridge.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xgr_tr_pred1, xgr_ts_pred1 = cross_validate_predict(XGBRegressor(**fixed_params_xgr, **xgr_params),\n",
    "                                                    X, y, test_df)\n",
    "\n",
    "cbr_tr_pred2, cbr_ts_pred2 = cross_validate_predict(CatBoostRegressor(**fixed_params_ctr, **cbr_params),\n",
    "                                                    X, y, test_df)\n",
    "\n",
    "lgr_tr_pred3, lgr_ts_pred3 = cross_validate_predict(LGBMRegressor(**fixed_params_lbr, **lbr_params),\n",
    "                                                    X, y, test_df)\n",
    "\n",
    "xgrf_tr_pred4, xgrf_ts_pred4 = cross_validate_predict(XGBRegressor(**fixed_params_xgrf, **xgrf_params),\n",
    "                                                      X, y, test_df)\n",
    "\n",
    "ridge_tr_pred5, ridge_ts_pred5 = cross_validate_predict(Ridge(**ridge_params), X, y, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ensemble_test[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    weights = [trial.suggest_float(f'w{i}', 0, 1) for i in range(1,6)]   # weight suggestions\n",
    "    weights = np.array(weights) / np.sum(weights)                        # normalizing\n",
    "    \n",
    "    ensemble_pred = ensemble_train.dot(weights)\n",
    "    r2_score = skm.r2_score(y, ensemble_pred)\n",
    "    return r2_score\n",
    "\n",
    "TPESampler = optuna.samplers.TPESampler(multivariate=True, group=True)\n",
    "optimize_weights = optuna.create_study(direction='maximize', sampler=TPESampler, study_name='Ensemble Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "optimize_weights.optimize(objective, n_trials=1000, show_progress_bar=True)\n",
    "dump(optimize_weights,'Ensemble Weights.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": 47,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "weights = optimize_weights.best_trial.params\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": 48,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Normalizing the weights\n",
    "weights = np.array(list(weights.values()))\n",
    "weights /= np.sum(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": 49,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['FloodProbability'] = ensemble_test.dot(weights)\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": 50,
    "class": "Hyperparam_Tuning",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return 1 - ss_res / (ss_tot + K.epsilon())\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8))\n",
    "\n",
    "    for i in range(hp.Int(\"num_hidden_layers\", min_value=8, max_value=80)):\n",
    "        number_of_nodes = hp.Int(\"number_of_nodes_\" + str(i), min_value=8, max_value=1024, step=16)\n",
    "        activation_function = hp.Choice(\"activation_\" + str(i), values=[\"relu\", \"tanh\", \"sigmoid\"])\n",
    "        model.add(Dense(number_of_nodes, activation=activation_function))\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"rmsprop\", \"adam\", \"nadam\", \"adadelta\", \"sgd\"])\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[r_squared])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=kt.Objective(\"val_r_squared\", direction=\"max\"),\n",
    "    max_trials=50,\n",
    "    directory=\"mydir\",\n",
    "    project_name=\"testings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_model.fit(x_train , y_train , epochs = 150 , batch_size = 2056 , initial_epoch = 6 , validation_data = (x_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_id": 54,
    "class": "Hyperparam_Tuning",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.01),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[r_squared])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Hyperparam_Tuning",
    "notebook_id": 9,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize') #创建study对像，寻找r2的最大值\n",
    "study.optimize(objective, n_trials=100)  #调优开始，进行100次试验，找出最优参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Hyperparam_Tuning",
    "notebook_id": 9,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Hyperparam_Tuning",
    "notebook_id": 9,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cat_params = {\n",
    "#     'n_estimators': 2000,                  # Number of boosting iterations\n",
    "#     'random_state': 0,                     \n",
    "#     'learning_rate': 0.011277016304363601, # 学习率\n",
    "#     'depth': 8,                            # 树深度\n",
    "#     'subsample': 0.8675506657380021,       # Subsample ratio of the training instances\n",
    "#     # 'colsample_bylevel': 0.7183884158632279, # Subsample ratio of columns for each level (commented out)\n",
    "#     'min_data_in_leaf': 98,                # 最小叶子树\n",
    "#     'task_type': 'GPU',                    # 使用GPU\n",
    "#     'bootstrap_type': 'Bernoulli'          # 随机抽样类型\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Hyperparam_Tuning",
    "notebook_id": 11,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'bayesian_ridge': BayesianRidge(),\n",
    "    'elastic_net': ElasticNetCV(cv=5),\n",
    "    'linear_reg': LinearRegression(),\n",
    "    'lasso': LassoCV(cv=5),\n",
    "    'ridge': RidgeCV(cv=5)\n",
    "}\n",
    "\n",
    "# Define the parameter grids for each model\n",
    "param_grids = {\n",
    "    'bayesian_ridge': {\n",
    "        'alpha_1': [1e-6, 1e-5],\n",
    "        'alpha_2': [1e-6, 1e-4],\n",
    "        'lambda_1': [1e-6, 1e-5],\n",
    "        'lambda_2': [1e-6,1e-5]\n",
    "    },\n",
    "    'elastic_net': {\n",
    "    },\n",
    "    'linear_reg': {\n",
    "        'fit_intercept': [True, False]\n",
    "    },\n",
    "    'lasso': {\n",
    "    },\n",
    "    'ridge': {\n",
    "        'alphas': [(0.1, 1.0, 10.0)]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the GridSearchCV for each model\n",
    "grid_searches = {name: GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "                 for name, (model, param_grid) in zip(models.keys(), zip(models.values(), param_grids.values()))}\n",
    "\n",
    "\n",
    "# Assume you have a dataset X (features) and y (target)\n",
    "best_estimators = {}\n",
    "\n",
    "# Fit the GridSearchCV for each model\n",
    "for name, gs in grid_searches.items():\n",
    "    print(f\"Running GridSearchCV for {name}\")\n",
    "    gs.fit(X, y)\n",
    "    print(f\"Best parameters for {name}: {gs.best_params_}\")\n",
    "    print(f\"Best score for {name}: {gs.best_score_}\")\n",
    "    best_estimators[name] = gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Hyperparam_Tuning",
    "notebook_id": 14,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "param=[{'alpha':[0.05,0.1,0.5,0.8]},{'solver':['auto','saga']}]\n",
    "gv=GridSearchCV(ri,param_grid=param,cv=5,return_train_score=True)\n",
    "gv.fit(X_train_t,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cell_id": 57,
    "class": "Hyperparam_Tuning",
    "notebook_id": 16,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "estimators = [(\"catBoost\",cat_model),(\"linearReg\",linear),(\"xgBoost\",xg_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cell_id": 62,
    "class": "Hyperparam_Tuning",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cell_id": 65,
    "class": "Hyperparam_Tuning",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# xg_model = XGBRegressor()\n",
    "# xg_model.fit(X, y)\n",
    "\n",
    "# y_pred_xg = xg_model.predict(test_set)\n",
    "# print(f\"Training score {xg_model.score(X,y)}\")\n",
    "# # Training score 0.8690384222081213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cell_id": 74,
    "class": "Hyperparam_Tuning",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_pred_LG = pd.DataFrame(y_pred_LG)\n",
    "output_LG = test_set_id\n",
    "output_LG[\"FloodProbability\"] = pd.DataFrame(y_pred_LG)\n",
    "output_LG = output_LG.set_index(\"id\")\n",
    "output_LG.to_csv(\"FloodProbability_SS_project_FEng_LGBM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Hyperparam_Tuning",
    "notebook_id": 19,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(16, activation='relu', input_dim=X_train.shape[1]),    \n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "\n",
    "])\n",
    "\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['r2_score'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Hyperparam_Tuning",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_loss = history3.history['loss']\n",
    "val_loss = history3.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(tr_loss))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Hyperparam_Tuning",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "max(history3.history['val_r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Hyperparam_Tuning",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "call_back4 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Hyperparam_Tuning",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "history4 = model4.fit(X_train, y_train, epochs=100, batch_size=32, callbacks= call_back4 , validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Hyperparam_Tuning",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_loss = history4.history['loss']\n",
    "val_loss = history4.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(tr_loss))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Hyperparam_Tuning",
    "notebook_id": 22,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define a function that fits and the train the model on the training data for all parameters while using \n",
    "# cross-validation\n",
    "def hyperparameter_tuning(model, params, X_train):\n",
    "    clf = GridSearchCV(estimator = model, \n",
    "                       param_grid = params, \n",
    "                       scoring = 'neg_mean_squared_error', \n",
    "                       n_jobs = -1,\n",
    "                       return_train_score = True,\n",
    "                       refit = True,\n",
    "                       cv = 5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best estimator: ', clf.best_estimator_)\n",
    "    print('Best score: ', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Hyperparam_Tuning",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "params_ridge = {'alpha': [0.1, 0, 1, 1.5]}\n",
    "hyperparameter_tuning(ridge, params_ridge, X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Hyperparam_Tuning",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "ridge = Ridge(alpha = 0)\n",
    "kn_reg = KNeighborsRegressor(n_neighbors = 9)\n",
    "tree = DecisionTreeRegressor(min_samples_leaf = 2, min_samples_split = 5)\n",
    "xgb = XGBRegressor(learning_rate = 0.1, max_depth = 7,\n",
    "                   min_child_weight = 3, n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Hyperparam_Tuning",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "models_need_scaling = [lin_reg, ridge, kn_reg]\n",
    "models_names_need_scaling = ['Linear Regression', 'Ridge', 'k-Neighbors Regression']\n",
    "\n",
    "train_score, test_score, r2, mae, rmse = [], [], [], [], []\n",
    "\n",
    "for model, model_name in zip(models_need_scaling, models_names_need_scaling):\n",
    "    building_model(model, model_name, X_train_scaled, X_val_scaled)\n",
    "\n",
    "scores_df3 = pd.DataFrame({'model': models_names_need_scaling,\n",
    "                          'train_score': train_score,\n",
    "                          'test_score': test_score,\n",
    "                          'r2_score': r2,\n",
    "                          'mean_absolute_error': mae,\n",
    "                          'root_mean_squared_error': rmse}).sort_values(by = 'r2_score',\n",
    "                                                                        ascending = False).set_index('model')\n",
    "scores_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Hyperparam_Tuning",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "median = results['predicted_proba'].median()\n",
    "mean = results['predicted_proba'].mean()\n",
    "\n",
    "y_pred.plot(kind = 'hist', color = '#2CBD8F')\n",
    "plt.axvline(x = median, linestyle = '-', color = '#B136EA', label = 'median')\n",
    "plt.axvline(x = mean, linestyle = '--', color = '#EA3690', label = 'mean')\n",
    "\n",
    "plt.xlabel('predicted proba')\n",
    "plt.title('Distribution of the Flood Predicted Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators' : [300,400,500,600,800,900,1100,1000],\n",
    "    'eta' : [0.1,0.01,1,0.5, 0.05,5],\n",
    "    'alpha' : [1,5,10,15,20],\n",
    "    'reg_lambda': [1,5,10,15,20],\n",
    "    'max_depth' : [1,3,5,7,9,12],\n",
    "    'colsample_bytree' : [0.3,0.5,0.7,1],\n",
    "    'subsample' : [0.3,0.5,0.7,1],\n",
    "    'min_child_weight': [1,3,5,7,9,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xg_cv = RandomizedSearchCV(estimator = XGBRegressor(), param_distributions = params, cv = 3, scoring = 'r2',verbose = 1,n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "XGBooster = XGBRegressor(subsample = 1, eta =  0.5, alpha = 10, max_depth = 1, n_estimators = 400, reg_lambda = 10, min_child_weight = 3,colsample_bytree = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "catBooster = CatBoostRegressor(subsample = 1, max_depth = 10, learning_rate = 0.1, l2_leaf_reg = 5, iterations = 800, bootstrap_type = 'Bernoulli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "catBooster.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# light_cv.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": 48,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_id": 51,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# gb_cv.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": 52,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate=0.5, max_depth=3, max_features='log2', min_samples_leaf=6, min_samples_split=8, n_estimators=700, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_id": 53,
    "class": "Hyperparam_Tuning",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "gb.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Hyperparam_Tuning",
    "notebook_id": 27,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def r2_score_metric(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return 1 - SS_res/(SS_tot + K.epsilon())\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_train_df, cleaned_target_df, test_size=0.3, random_state=11)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l1_l2(\n",
    "                l1=hp.Float('l1_' + str(i), 1e-5, 1e-2, sampling='LOG'),\n",
    "                l2=hp.Float('l2_' + str(i), 1e-5, 1e-2, sampling='LOG')\n",
    "            )\n",
    "        ))\n",
    "        model.add(tf.keras.layers.Dropout(hp.Float('dropout_' + str(i), 0.0, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')\n",
    "        ),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[r2_score_metric]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create a tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train, epochs=11, validation_split=0.2)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score of the best model:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Hyperparam_Tuning",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_hps.values.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "'''\n",
    "    Best hyperparameters:\n",
    "num_layers: 1\n",
    "units_0: 256\n",
    "l1_0: 2.3699222722321995e-05\n",
    "l2_0: 0.0005694007711882117\n",
    "dropout_0: 0.1\n",
    "learning_rate: 0.0016212150201753844\n",
    "units_1: 288\n",
    "l1_1: 1.3965518320658789e-05\n",
    "l2_1: 3.8408860301375645e-05\n",
    "dropout_1: 0.1\n",
    "units_2: 416\n",
    "l1_2: 6.66931421001826e-05\n",
    "l2_2: 0.0005722594832996224\n",
    "dropout_2: 0.30000000000000004'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Hyperparam_Tuning",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def build_fixed_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(242, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(12, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[r2_score_metric]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "fixed_model = build_fixed_model()\n",
    "\n",
    "# Print the summary of the model\n",
    "fixed_model.summary()\n",
    "\n",
    "# Train the model\n",
    "fixed_model.fit(X_train_scaled, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Hyperparam_Tuning",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Evaluate the model on the test set\n",
    "y_pred = fixed_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print detailed metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"R² Score of the fixed model:\", r2)\n",
    "print(\"Mean Squared Error of the fixed model:\", mse)\n",
    "print(\"Mean Absolute Error of the fixed model:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Hyperparam_Tuning",
    "notebook_id": 27,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "est1_df = test_df.drop('id',axis=1)\n",
    "\n",
    "\n",
    "X_test = scaler.transform(test1_df)  # Preprocess the test data\n",
    "predictions = fixed_model.predict(X_test)  # Make predictions\n",
    "\n",
    "# 4. Prepare Submission File\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],  # Assuming 'id' is the identifier column\n",
    "    'FloodProbability': predictions.flatten()  # Assuming 'FloodProbability' is the target column\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('FE_NN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "def cvr_sequences(model,x_train,target,folds=10,n_rounds=10,n_jobs=1,scorer='',output=False,graphs=False):\n",
    "    '''\n",
    "    Function to get the sequence of features up to the first random feature or the max CVS in the sequence.\n",
    "    Is a wrapper for \"rank_feats\" and \"get_rank\" functions.\n",
    "    Output:\n",
    "        a dictionary with the sequence of features as key and its CVS as value. \n",
    "        The sequences are those explored in \"rank_feats\" plus the mean rank sequence computed with \"get_ranks\".\n",
    "    '''\n",
    "    if not scorer:\n",
    "        print('scorer must be a valid sklearn scorer')\n",
    "    ranking=rank_feats(model,x_train,target,n_jobs=n_jobs,n_rounds=n_rounds,scorer=scorer,output=output)\n",
    "    scores=get_ranks(ranking,x_train,target,n_jobs=n_jobs,scorer=scorer,graphs=graphs)\n",
    "    sqd={}\n",
    "    for s,numf,*_ in ranking:\n",
    "        seq=[]\n",
    "        # At most up to the sequence with the highest CVS\n",
    "        for f in s[:numf]:\n",
    "            if  f.startswith('random_'):\n",
    "                break\n",
    "            seq.append(f)\n",
    "        sqd[tuple(sorted(seq))]=cross_val_score(model,x_train[seq],target,scoring=scorer,cv=folds).mean()\n",
    "    # Computes the mean rank sequence\n",
    "    seq=[]\n",
    "    for f in scores.keys():\n",
    "        if f.startswith('random_'):\n",
    "            break\n",
    "        seq.append(f)\n",
    "    \n",
    "    sqd[tuple(sorted(seq))]=cross_val_score(model,x_train[seq],target,scoring=scorer,cv=folds).mean()\n",
    "    \n",
    "    return dict(sorted(sqd.items(),key=lambda x:x[1]))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def perf_estimation(model,X_train,y_train,score=None ,scorer='r2',folds=10,output=True,graphs=True,n_jobs=-1):\n",
    "    '''\n",
    "    Computes the sequence of CVS corresponding to the sequence of features defined in X_train. That is, given a sequence of features {f0, f1, ..., fn}\n",
    "    computes the sequence [CVS(f0),CVS(f0, f1),....,CVS(f0, f1, ..., fn)]\n",
    "    Input\n",
    "        * model: A model (classificator or regressor) sklearn cross_val_score compatible.\n",
    "        * X_train: Pandas dataframe with features as columns.\n",
    "        * y_train: Pandas series with the target\n",
    "        * score: The order in which features are added. It could be:\n",
    "            +None: default. The X_train columns order\n",
    "            +Any string: random order\n",
    "            +list: a ordered list with the name of features (X_train columns)\n",
    "        * scorer: Any sklearn cross_val_score valid scorer\n",
    "        * folds: Integer. Number of folds for cross validation\n",
    "        * output, graphs: Boolean. Defect True. If False no graphs or no print output\n",
    "        * n_jobs: Integer. Default -1. sklearn n_jobs for cross_val_score\n",
    "\n",
    "    Output:\n",
    "        * A list of tuples, one for each sequence [{f0}, {f0, f1}, ..., {f0, f1, ..., fn}]: \n",
    "            [(#features, time spent in computation, list of features used, list with score of each fold), ....]\n",
    "        * If 'output' is True prints #features in the sequence, last feature added to the sequence, mean +- std cross_val_score, computation time\n",
    "            for each iteration\n",
    "        * If 'graphs' is True displays 3 plots: The box-plot of the folds scores for each iteration and the mean and median line plot. \n",
    "            \n",
    "    '''\n",
    "    from time import time\n",
    "    result=[]\n",
    "    time00=time()\n",
    "    if type(score)==type(None):\n",
    "        score=pd.Series(list(range(X_train.shape[1])),index=X_train.columns)\n",
    "    elif isinstance(score,str):\n",
    "        from random import shuffle\n",
    "        a=X_train.columns.to_list()\n",
    "        shuffle(a)\n",
    "        score=pd.Series(list(range(X_train.shape[1])),index=a)\n",
    "    elif isinstance(score,list):\n",
    "        score=pd.Series(list(range(len(score))),index=score)\n",
    "    \n",
    "                        \n",
    "    sequence=[]\n",
    "    for nf in score.index.to_list():\n",
    "        \n",
    "        sequence.append(nf)\n",
    "        if output:\n",
    "             print(f'num. feats.: {len(sequence):3.0f} ({nf:>35})',end='    ')\n",
    "        \n",
    "        \n",
    "        time0=time()\n",
    "        cv_score=cross_val_score(model,X_train[sequence],y_train,scoring=scorer,n_jobs=n_jobs,cv=folds)\n",
    "        result.append((len(sequence),time()-time0,nf,cv_score)),\n",
    "        if output:\n",
    "             print(f'\\t cv score: {result[-1][-1].mean():0.4f} ± {result[-1][-1].std():0.4f}\\t time: {result[-1][1]:0.2f}s')\n",
    "    \n",
    "    if output:\n",
    "             print(f'Total time: {time()-time00}')\n",
    "    if graphs:\n",
    "        nf,tm,feats,cvtrain=transpose(result)\n",
    "\n",
    "\n",
    "        values=[[numf,val] for numf,values in zip(nf,cvtrain) for val in values]\n",
    "        values=pd.DataFrame(values,columns=['nf','score'])\n",
    "        values.boxplot('score',by='nf',figsize=(15,6))\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(18,6))\n",
    "        plt.subplot(1,2,1)\n",
    "        grouped=values.groupby('nf').mean()\n",
    "        top=grouped.max().values[0]\n",
    "        bottom=(grouped.min().values[0]+grouped.max().values[0])/2\n",
    "        delta=(top-bottom)/50\n",
    "        plt.plot(grouped.index,grouped.score)\n",
    "        plt.hlines(top,1,X_train.shape[1],color='red',linestyles='dashed')\n",
    "        lg=f'Max: {top:0.4f}'\n",
    "        plt.text(0,top+delta,lg)\n",
    "        plt.vlines(np.argmax(grouped)+1,bottom,top,color='red',linestyles='dashed')\n",
    "        lg=f'#feats: {np.argmax(grouped)+1}'\n",
    "        plt.text(np.argmax(grouped)+1,bottom+delta,lg)\n",
    "        plt.grid()\n",
    "        plt.ylim(bottom=bottom)\n",
    "        plt.title('cv Mean')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        grouped=values.groupby('nf').median()\n",
    "        top=grouped.max().values[0]\n",
    "        bottom=(grouped.min().values[0]+grouped.max().values[0])/2\n",
    "        delta=(top-bottom)/50\n",
    "        plt.plot(grouped.index,grouped.score)\n",
    "        plt.hlines(top,1,X_train.shape[1],color='red',linestyles='dashed')\n",
    "        lg=f'Max: {top:0.4f}'\n",
    "        plt.text(0,top+delta,lg)\n",
    "        plt.vlines(np.argmax(grouped)+1,bottom,top,color='red',linestyles='dashed')\n",
    "        lg=f'#feats: {np.argmax(grouped)+1}'\n",
    "        plt.text(np.argmax(grouped)+1,bottom+delta,lg)\n",
    "        plt.grid()\n",
    "        plt.ylim(bottom=bottom)\n",
    "        plt.title('cv Median')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def rank_feats(model,dt,y,scorer='r2',folds=10,n_rounds=5,n_jobs=-1,output=True,initial=[]):\n",
    "    '''\n",
    "    Computes the increment in cross_val_score due i-th feature from a permutation of features. \n",
    "    Then sorts the features sequence by this increment and repeat the process.\n",
    "    Input:\n",
    "        * model: A model (classificator or regressor) sklearn \"cross_val_score\" compatible.\n",
    "        * dt: : Pandas dataframe with features as columns.\n",
    "        * y: Pandas series with the target.\n",
    "        * scorer: Any sklearn \"cross_val_score\" valid scorer.\n",
    "        * folds: Integer. Number of folds for cross validation.\n",
    "        * n_jobs: Integer. Default -1. sklearn n_jobs for \"cross_val_score\"\n",
    "        * n_rounds: Integer. Default 5. How many of times the algorithm is repeated.\n",
    "    Output:\n",
    "        A list with a tuple for each repetition: \n",
    "        [(sequence of features,  #features max CV mean, max CV mean,  #features max CV median, max CV median), ...]\n",
    "\n",
    "\n",
    "    '''\n",
    "    from time import time\n",
    "    ranking=[]\n",
    "    time0=time()\n",
    "    if output:\n",
    "            print('Initial round', end=' .... ')\n",
    "    for col in dt:\n",
    "        ranking.append([col,cross_val_score(model,dt[[col]],y,scoring=scorer,cv=folds,n_jobs=n_jobs).mean()])\n",
    "        rankf,cv=transpose(sorted(ranking,key=lambda x: x[1],reverse=True))\n",
    "    if output:\n",
    "            print(f'Done! ({round(time()-time0,1)} s)')\n",
    "    \n",
    "    rounds=[]\n",
    "    for i in range(n_rounds):\n",
    "        if output:\n",
    "            print(f'Round {i+1}',end=': ')\n",
    "        \n",
    "        result=perf_estimation(model,dt,y,score=list(rankf),scorer=scorer,output=False,graphs=False,n_jobs=n_jobs,folds=folds)\n",
    "        max_mean=np.argmax([item[-1].mean() for item in result])\n",
    "        max_median=np.argmax([np.median(item[-1]) for item in result])\n",
    "        \n",
    "        rounds.append((rankf,result[max_mean][0],result[max_mean][-1].mean(),result[max_median][0],np.median(result[max_median][-1])))\n",
    "        if output:\n",
    "            print(f'mean: {rounds[-1][1]} ({rounds[-1][2]:0.5f})  median: {rounds[-1][3]} ({rounds[-1][4]:0.5f})')\n",
    "        ranking=[[result[0][2],result[0][3].mean()]]\n",
    "        prev=ranking[-1][-1]\n",
    "        for nf,tm,col,cv in result[1:]:\n",
    "            ranking.append([col,cv.mean()-prev])\n",
    "            prev=cv.mean()\n",
    "        rankf,cv=transpose(sorted(ranking,key=lambda x: x[1],reverse=True))\n",
    "    return rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def get_ranks(ranking,dt=None,y=None,n_jobs=-1,scorer='',graphs=True,model=''):\n",
    "    '''\n",
    "    Assigns the ranks to each feature. The rank is the order number of the feature in the sequence. \n",
    "    Then computes de mean and standard deviation for the ranks of each feature. Finally sort the features by mean rank.\n",
    "    Input:\n",
    "        * ranking: the `rank_feats` output.\n",
    "        * dt: Optional. Only active if \"graphs\" is True. Pandas dataframe with features as columns.\n",
    "        * y: Optional. Only active if \"graphs\" is True. Pandas series with the target.\n",
    "        * scorer: Optional. Only active if \"graphs\" is True. Any sklearn cross_val_score valid scorer.\n",
    "        * n_jobs: Optional. Only active if \"graphs\" is True. Integer. Default -1. sklearn n_jobs for cross_val_score\n",
    "    Output:\n",
    "        * An ordered  dictionary:\n",
    "            {feature name: (mean rank, std rank), ....}\n",
    "        * If \"graphs\"=True and \"dt\", \"y\", \"scorer\" are defined runs `perf_estimation` for the sequence of features sorted by mean rank.\n",
    "        * If graphs=True displays a line plot for the mean rank. The line is surrounded by +- std rank red area\n",
    "   \n",
    "    '''\n",
    "    rank={key:[] for key in ranking[0][0]}\n",
    "    for r,*_ in ranking[1:]:\n",
    "        for i,f in enumerate(r):\n",
    "            rank[f].append(i)\n",
    "    rank={key:(np.mean(val),np.std(val)) for key,val in rank.items()}\n",
    "    rank=dict(sorted(rank.items(),key=lambda x:x[1]))\n",
    "\n",
    "    if graphs:\n",
    "        if model:\n",
    "            res=perf_estimation(model,dt,y,list(rank.keys()),scorer=scorer,n_jobs=n_jobs)\n",
    "    \n",
    "        ticks=list(rank.keys())\n",
    "        y_val=[]\n",
    "        y_err=[]\n",
    "        for avg,sqtd in rank.values():\n",
    "            \n",
    "            y_val.append(avg)\n",
    "            y_err.append(sqtd)\n",
    "\n",
    "        if len(rank)>30:\n",
    "            plt.figure(figsize=(18,6))\n",
    "            \n",
    "        plt.plot(ticks,y_val)\n",
    "        plt.xticks(rotation=80)#yerr=y_err)\n",
    "        plt.fill_between(ticks,np.array(y_val)+np.array(y_err),np.array(y_val)-np.array(y_err),alpha=0.15,color='red')\n",
    "        plt.xticks(rotation=80)#yerr=y_err)\n",
    "        plt.ylabel('mean rank')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        plt.close\n",
    "\n",
    "\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def MI(x,y,func=None,random_seed=0,discrete_features='auto'):\n",
    "    '''\n",
    "    Wrapper for sklearn \"mutual_info_classif/regression\". These are statistical estimators that have some subtleties.\n",
    "    Input:\n",
    "        x: Pandas dataframe or numpy array with features as columns\n",
    "        y: Pandas dataframe or numpy array with the target \n",
    "        func: A function for compute the mutual information. sklearn \"mutual_info_classif/regression\". \n",
    "            If it is None, the function will be automatically selected based on the number of unique values of the target.\n",
    "        random_seed: Integer. A value for the \"random_state\" parameter \n",
    "        discrete_features: sklearn discrete_features parameter\n",
    "    Output:\n",
    "        A numpy array with the I(X_i,Y) values.\n",
    "    '''\n",
    "    if not func:\n",
    "        if np.unique(y).shape[0]<=10:\n",
    "            func=mutual_info_classif\n",
    "            y=y.astype(int)\n",
    "        else:\n",
    "            func=mutual_info_regression\n",
    "       \n",
    "    return func(x,y,random_state=random_seed,discrete_features=discrete_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def mi_score(orig,crossmi,criterion='relative',weight=1.0): \n",
    "    '''\n",
    "    Computes M_i scores: M_i=I(X_i,Y)-weight*sum(I(X_i,X_j))\n",
    "    Input:\n",
    "        orig: first output from \"get_mutual_info\"\n",
    "        crossmi: MI between features. Second output from \"get_mutual_info\"\n",
    "        criterion: String. If it is \"relative\", normalizes I(X,Y) as I(X,Y)/H(Y) and the cross I(X_i,X_j) as  I(X_i,X_j)/min(H(X_i),H(X_j)). \n",
    "            In other case does nothing.\n",
    "        weight: Float. The weight for the penalty of the cross mutual info between features.\n",
    "    Output:\n",
    "        Pandas Series with features as index and the M_i score as value.\n",
    "    '''\n",
    "        \n",
    "    mi=pd.Series(orig['mi'])\n",
    "    H=pd.Series(orig['Sh'])\n",
    "    mi=mi.sort_values()\n",
    "    penalty=pd.Series(np.zeros_like(mi),index=mi.index)\n",
    "    score=mi.copy()\n",
    "    \n",
    "    \n",
    "    cols=score.sort_values().index.to_list()\n",
    "    selected=[]\n",
    "    while cols:\n",
    "        #feature selected\n",
    "        pivot=cols.pop(-1)\n",
    "\n",
    "        #update penalties for remaining features\n",
    "        for c in cols:\n",
    "            if criterion=='relative':\n",
    "                penalty[c]+=crossmi.loc[c,pivot]/min(H[c],H[pivot])\n",
    "            else:\n",
    "                penalty[c]+=crossmi.loc[c,pivot]\n",
    "\n",
    "        #update scores, cols and selected\n",
    "        selected.append(pivot)\n",
    "        if criterion=='relative':\n",
    "            score[cols]=(mi/H['target']-weight*penalty/len(selected))[cols]\n",
    "        else:\n",
    "            score[cols]=(mi-weight*penalty/len(selected))[cols]\n",
    "        cols=score.sort_values().index.to_list()\n",
    "        cols=[item for item in cols if not item in selected]\n",
    "    \n",
    "    \n",
    "    return (score).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "penalty_weight=0.2 #weight of MIR penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seqs=cvr_sequences(model,dt_class,y_class,n_jobs=n_jobs,n_rounds=10,scorer='accuracy',output=True,graphs=True)\n",
    "\n",
    "seqs=(sorted(seqs.items(),key=lambda x: x[1],reverse=True))\n",
    "for s,c in seqs:\n",
    "    print(f'{c:0.5f} {\", \".join(s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=RFECV(model,cv=10,scoring='accuracy',n_jobs=n_jobs)\n",
    "selector.fit(dt_class,y_class)\n",
    "seq=sorted(dt_class.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_class[seq],y_class,scoring='accuracy',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='forward', scoring='accuracy', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=1e-4)\n",
    "selector.fit(dt_class,y_class)\n",
    "seq=sorted(dt_class.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_class[seq],y_class,scoring='accuracy',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='backward', scoring='accuracy', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=-1e-4)\n",
    "selector.fit(dt_class,y_class)\n",
    "seq=sorted(dt_class.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_class[seq],y_class,scoring='accuracy',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "#sklearn make_regression stuff\n",
    "\n",
    "num_inf=10\n",
    "num_features=int(np.ceil(1.5*(num_inf)))\n",
    "columns=[f'I_{item}' for item in range(num_inf)]\n",
    "i=0\n",
    "while len(columns)<num_features:\n",
    "    columns.append(f'random_{i}')\n",
    "    i+=1\n",
    "dt_reg,y_reg=make_regression(n_samples=n_samples,\n",
    "                         n_informative=num_inf,\n",
    "                         \n",
    "                         n_features=num_features,\n",
    "                        \n",
    "                         shuffle=False)\n",
    "dt_reg=pd.DataFrame(dt_reg,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model=LGBMRegressor(verbose=-1,random_state=0)#HistGradientBoostingRegressor(random_state=0)#\n",
    "n_jobs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seqs=dict(cvr_sequences(model,dt_reg,y_reg,n_jobs=n_jobs,n_rounds=10,scorer='r2',output=True,graphs=True))\n",
    "seqs=(sorted(seqs.items(),key=lambda x: x[1],reverse=True))\n",
    "for s,c in seqs:\n",
    "    print(f'{c:0.5f} {\", \".join(s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=RFECV(model,cv=10,scoring='r2',n_jobs=n_jobs)\n",
    "selector.fit(dt_reg,y_reg)\n",
    "seq=sorted(dt_reg.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_reg[seq],y_reg,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='forward', scoring='r2', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=1e-4)\n",
    "selector.fit(dt_reg,y_reg)\n",
    "seq=sorted(dt_reg.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_reg[seq],y_reg,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='backward', scoring='r2', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=-1e-4)\n",
    "selector.fit(dt_reg,y_reg)\n",
    "seq=sorted(dt_reg.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_reg[seq],y_reg,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model=LGBMRegressor(verbose=-1,random_state=0)#HistGradientBoostingRegressor(random_state=0)#\n",
    "n_jobs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model=LGBMRegressor(verbose=-1,random_state=0)#HistGradientBoostingRegressor(random_state=0)#\n",
    "n_jobs=1\n",
    "\n",
    "\n",
    "seqs=dict(cvr_sequences(model,dt_gen,y_gen,n_jobs=n_jobs,n_rounds=10,scorer='r2',output=True,graphs=True))\n",
    "\n",
    "seqs=(sorted(seqs.items(),key=lambda x: x[1],reverse=True))\n",
    "for s,c in seqs:\n",
    "    print(f'{c:0.5f} {\", \".join(s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=RFECV(model,cv=10,scoring='r2',n_jobs=n_jobs)\n",
    "selector.fit(dt_gen,y_gen)\n",
    "seq=sorted(dt_gen.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_gen[seq],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='forward', scoring='r2', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=1e-4)\n",
    "selector.fit(dt_gen,y_gen)\n",
    "cvs=cross_val_score(model,dt_gen[seq],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='backward', scoring='r2', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=-1e-4)\n",
    "selector.fit(dt_gen,y_gen)\n",
    "cvs=cross_val_score(model,dt_gen[seq],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ent,crossmi,mi_sc=get_mutual_info(dt_gen,y_gen,weight=penalty_weight)\n",
    "\n",
    "seq_mir=[]\n",
    "for f in mi_sc.index:\n",
    "    if f.startswith('random_'):\n",
    "        break\n",
    "    seq_mir.append(f)\n",
    "seq_mir=sorted(seq_mir)\n",
    "cvs_mir=cross_val_score(model,dt_gen[seq_mir],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs_mir:0.5f}  {\", \".join(seq_mir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model=LGBMRegressor(verbose=-1,random_state=0)#HistGradientBoostingRegressor(random_state=0)#\n",
    "n_jobs=1\n",
    "\n",
    "\n",
    "seqs=dict(cvr_sequences(model,dt_gen,y_gen,n_jobs=n_jobs,n_rounds=10,scorer='r2',output=True,graphs=True))\n",
    "\n",
    "seqs=(sorted(seqs.items(),key=lambda x: x[1],reverse=True))\n",
    "for s,c in seqs:\n",
    "    print(f'{c:0.5f} {\", \".join(s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=RFECV(model,cv=10,scoring='r2',n_jobs=n_jobs)\n",
    "selector.fit(dt_gen,y_gen)\n",
    "seq=sorted(dt_gen.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_gen[seq],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='forward', scoring='r2', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=1e-4)\n",
    "selector.fit(dt_gen,y_gen)\n",
    "seq=sorted(dt_gen.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_gen[seq],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Hyperparam_Tuning",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "selector=SequentialFeatureSelector(model, direction='backward', scoring='r2', cv=10, n_jobs=n_jobs,n_features_to_select='auto',tol=-1e-4)\n",
    "selector.fit(dt_gen,y_gen)\n",
    "seq=sorted(dt_gen.columns[selector.support_])\n",
    "cvs=cross_val_score(model,dt_gen[seq],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs:0.5f}  {\", \".join(seq)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Hyperparam_Tuning",
    "notebook_id": 31,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# ファイル操作\n",
    "import os\n",
    "\n",
    "# 数値計算系\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# データ操作・表計算系\n",
    "import pandas as pd\n",
    "\n",
    "# グラフ描写系\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 機械学習モデル\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# エラー処理用\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.stderr = open(os.devnull, \"w\")  # silence stderr\n",
    "# sys.stderr = sys.__stderr__  # unsilence stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Model_Interpretation",
    "notebook_id": 12,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "eda.run_full_eda(train_data, run_collinear=False, generate_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Model_Interpretation",
    "notebook_id": 28,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "def get_mutual_info(X_orig,y_orig,graphics=True,discrete_limit=10,crossmi=True,weight=1.0,criterion='relative'):\n",
    "    '''\n",
    "    Function for compute entropy based information about features and target.\n",
    "    Input:\n",
    "        X_orig: Pandas dataframe or numpy array with the features as columns.\n",
    "        y_orig: Pandas Series or numpy array with the target.\n",
    "        graphics: Boolean. If it is True displays available graphs\n",
    "        discrete_limit: int. The number of unique values below of which a feature is considered discrete, \n",
    "            in the sense of the sklearn \"discrete_features\" parameter.\n",
    "        crossmi: Boolean. If it is True computes the cross mutual information between features.\n",
    "        weight: Float. The weight for the penalty of the cross mutual info between features. Only active if \"crossmi\" is True.\n",
    "        criterion: String. The \"mi_score\" \"criterion\" parameter.\n",
    "    Output:\n",
    "        Three items:\n",
    "        * First item: a dictionary with the items:\n",
    "            +'mi': list of mutual info between each feature and the target.\n",
    "            +'Sh': list with entropies of target and each feature.\n",
    "            +'noise': list with the noise (H(X_i)-I(X_i,Y)) of each feature\n",
    "        * Second item: If \"crossmi\" is set to True a numpy array with I(X_i,X_j), else None\n",
    "        * Third item: If \"crossmi\" is set to True the output of \"mi_score\", else None.\n",
    "        * If \"graphs\" is set to True:\n",
    "            + A bar-plot for the I(X_i,Y) with the features sorted by score.\n",
    "            If \"crossmi\" is set to True:\n",
    "                +A bar-plot with the noise of each feature\n",
    "                +A bar-plot with the signal/noise ratio\n",
    "                +A heat map with the I(X_i,X_j)\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    mutual_array=[]\n",
    "    ccols=classify_columns(X_orig,cat_limit=discrete_limit)\n",
    "    cat_cols=ccols['cat_cols']\n",
    "    d_cols=[i for i,c in enumerate(X_orig.columns) if c in  cat_cols+ccols['disc_cols']]\n",
    "    \n",
    "    if len(d_cols)<1:\n",
    "        d_cols='auto'\n",
    "    S=[MI(np.array(y_orig).reshape(-1,1),y_orig)[0]] #estimate target entropy\n",
    "\n",
    "    #remove NaNs\n",
    "    x_train=X_orig.dropna()\n",
    "    #encode catagoricals\n",
    "    if cat_cols:\n",
    "        x_train[cat_cols]=OrdinalEncoder().fit_transform(x_train[cat_cols])\n",
    "\n",
    "    mutual_array=pd.Series(MI(x_train,y_orig,discrete_features=d_cols),index=x_train.columns)\n",
    "    interfeat=[]\n",
    "    if crossmi:\n",
    "        for i,col in enumerate(X_orig.columns):\n",
    "            interfeat.append(MI(x_train,x_train[col],discrete_features=d_cols))\n",
    "            S.append(interfeat[-1][i])\n",
    "        for i in range(len(interfeat)):\n",
    "            interfeat[i][i]=0\n",
    "        interfeat=pd.DataFrame(interfeat,columns=X_orig.columns,index=X_orig.columns)\n",
    "    else:\n",
    "        S+=[0]*len(X_orig.columns)\n",
    "       \n",
    "    S=np.array(S)\n",
    "    mi_orig=pd.Series(mutual_array,index=X_orig.columns)\n",
    "    Sh=pd.Series(S,index=['target']+X_orig.columns.to_list())\n",
    "    noise=Sh[1:]-mi_orig\n",
    "    original={'mi':mi_orig.to_dict(),'Sh':Sh.to_dict(),'noise':noise.to_dict()}\n",
    "    score=None\n",
    "    if crossmi:\n",
    "        score=mi_score(original,interfeat,weight=weight,criterion=criterion)\n",
    "\n",
    "    if graphics:\n",
    "        sorted_features=list(score.keys())\n",
    "        \n",
    "        heigh=10 if X_orig.shape[1]<20 else X_orig.shape[1]//2\n",
    "        plt.figure(figsize=(20,heigh))\n",
    "        plt.subplot(2,2,1)\n",
    "        sns.barplot(y=sorted_features,x=mutual_array[sorted_features])\n",
    "        plt.ylabel('features sorted by rank')\n",
    "        plt.xlabel('I(X,Y)')\n",
    "        plt.title('features-label mutual information')\n",
    "        plt.grid()\n",
    "        \n",
    "        \n",
    "        if crossmi:\n",
    "            plt.subplot(2,2,2)\n",
    "            sns.barplot(y=sorted_features,x=noise[sorted_features]/Sh[sorted_features])\n",
    "            plt.xlim(left=min(noise[sorted_features]/Sh[sorted_features])*0.9)\n",
    "            plt.title('% noise')\n",
    "            plt.ylabel('')\n",
    "            plt.xlabel('1-I(X,Y)/H(X)')\n",
    "            plt.grid()\n",
    "        \n",
    "            \n",
    "            plt.subplot(2,2,3)\n",
    "            sns.barplot(y=sorted_features,x=mutual_array[sorted_features]/noise[sorted_features])\n",
    "            plt.title('Signal/noise')\n",
    "            plt.ylabel('')\n",
    "            plt.xlabel('I(X,Y)/[1-I(X,Y)/H(X)]')\n",
    "            plt.grid()\n",
    "            \n",
    "            plt.subplot(2,2,4)\n",
    "            to_show=interfeat.loc[sorted_features,sorted_features]\n",
    "            \n",
    "            for coli in sorted_features:\n",
    "                for colj in sorted_features:\n",
    "                    to_show.loc[coli,colj]=interfeat.loc[coli,colj]/min(original['Sh'][coli],original['Sh'][colj])\n",
    "                \n",
    "            sns.heatmap(to_show,cmap='viridis',mask=~np.tri(X_orig.shape[1],dtype=bool))\n",
    "            \n",
    "            plt.title('Features mutual information (relative)')\n",
    "            plt.ylabel('')\n",
    "            plt.xlabel('I(X_i,X_j)/min(H(X_i),H(X_j))')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return original,interfeat,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Interpretation",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ent,crossmi,mi_sc=get_mutual_info(dt_class,y_class,weight=penalty_weight)\n",
    "\n",
    "seq_mir=[]\n",
    "for f in mi_sc.index:\n",
    "    if f.startswith('random_'):\n",
    "        break\n",
    "    seq_mir.append(f)\n",
    "seq_mir=sorted(seq_mir)\n",
    "cvs_mir=cross_val_score(model,dt_class[seq_mir],y_class,scoring='accuracy',cv=10).mean()\n",
    "print(f'{cvs_mir:0.5f}  {\", \".join(seq_mir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Model_Interpretation",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ent,crossmi,mi_sc=get_mutual_info(dt_gen,y_gen,weight=penalty_weight)\n",
    "\n",
    "seq_mir=[]\n",
    "for f in mi_sc.index:\n",
    "    if f.startswith('random_'):\n",
    "        break\n",
    "    seq_mir.append(f)\n",
    "seq_mir=sorted(seq_mir)\n",
    "cvs_mir=cross_val_score(model,dt_gen[seq_mir],y_gen,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs_mir:0.5f}  {\", \".join(seq_mir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Model_Interpretation",
    "notebook_id": 30,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "all_scores = {}\n",
    "ascending = True\n",
    "for r in range(n_repeats):\n",
    "    for m in [f for f in oofs[r].columns if f not in [target]]:\n",
    "        if r == 0:\n",
    "            all_scores[m] = []\n",
    "        all_scores[m].append(score_(train[target], oofs[r][m]))\n",
    "        \n",
    "all_scores = pd.DataFrame(all_scores)\n",
    "_col_order = list(all_scores.mean(axis=0).sort_values(ascending = ascending).index)\n",
    "all_scores = all_scores[_col_order]\n",
    "\n",
    "_t = list(all_scores.mean(axis=0).sort_values(ascending = ascending).values)\n",
    "_labels = [f\"{l:15} ({v:.5})\" for l,v in zip(_col_order, _t)]\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize = (10, int(all_scores.shape[1] * 1/2)))\n",
    "ax.boxplot(all_scores, vert = False, labels = _labels)\n",
    "ax.set_title(\"OOFS R2\")\n",
    "ax.set_xlabel(\"R2 (higher is better)\")\n",
    "ax.xaxis.set_ticks_position(\"top\")\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 5,
    "class": "Model_Interpretation",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def hierarchical_clustering(data, title):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10), dpi=120)\n",
    "    correlations = data.corr()\n",
    "    converted_corr = 1 - np.abs(correlations)\n",
    "    Z = linkage(squareform(converted_corr), 'complete')\n",
    "    \n",
    "    dn = dendrogram(Z, labels = data.columns, ax = ax, above_threshold_color = '#ff0000', orientation = 'right')\n",
    "    hierarchy.set_link_color_palette(None)\n",
    "    plt.grid(axis='x')\n",
    "    plt.title(f'Hierarchical clustering, Dendrogram - part {title} ', fontsize=18, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(n_repeats):\n",
    "    hierarchical_clustering(oofs[i][models], title = f\"{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Model_Train",
    "notebook_id": 1,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 2,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Model_Train",
    "notebook_id": 3,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    # Initialize the transformer with a key\n",
    "    def __init__(self, key):\n",
    "        # Store the provided key as an instance variable\n",
    "        self.key = key\n",
    "\n",
    "    # The fit method is required but doesn't need to do anything for this transformer\n",
    "    def fit(self, X, y=None):\n",
    "        # Return self to allow for method chaining\n",
    "        return self\n",
    "\n",
    "    # The transform method selects and returns the column specified by the key\n",
    "    def transform(self, X):\n",
    "        # Use the key to select the column from the DataFrame X and return it\n",
    "        return X[[self.key]]\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Initialize variables to track the best model and its R-squared score\n",
    "best_model = None\n",
    "best_r2 = float('-inf')\n",
    "\n",
    "# Iterate over each model in the models dictionary\n",
    "for name, model in models.items():\n",
    "\n",
    "\n",
    "    # List to store transformers for each column\n",
    "    final_transformers = []\n",
    "    \n",
    "    # Create a pipeline for each column in the training set\n",
    "    for col in X_train.columns:\n",
    "        pipeline = Pipeline([\n",
    "            ('selector', NumberSelector(key=col)),  # Select the column\n",
    "            ('scaler', StandardScaler()),\n",
    "        ])\n",
    "        final_transformers.append((col, pipeline))\n",
    "    \n",
    "    # Combine all column transformers into a FeatureUnion\n",
    "    feats = FeatureUnion(final_transformers)\n",
    "    \n",
    "    # Create a pipeline for feature processing\n",
    "    feature_processing = Pipeline([('feats', feats)])\n",
    "    \n",
    "    # Create the final pipeline including the feature processing and the classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('features', feature_processing),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # Check if hyperparameters for the current model are defined in the params dictionary\n",
    "    if name in params:\n",
    "        # If hyperparameters are defined, perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(pipeline, params[name], cv=5, scoring=rmse_scorer)\n",
    "    else:\n",
    "        # If hyperparameters are not defined, perform grid search with default hyperparameters\n",
    "        grid_search = GridSearchCV(pipeline, {}, cv=5, scoring=rmse_scorer)\n",
    "      \n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared score and RMSE on the test set\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse_val = rmse(y_test, y_pred)\n",
    "    \n",
    "    # Update the best model and its R-squared score if the current model performs better\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_model = grid_search\n",
    "    \n",
    "    # Append the results to the results list\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'R-Squared Score': r2,\n",
    "        'RMSE Score': rmse_val,\n",
    "        'Best Parameters': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Model_Train",
    "notebook_id": 3,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Calculate standard deviation of residuals\n",
    "sigma = np.std(residuals)\n",
    "\n",
    "# Create a list for hue parameter\n",
    "hue = list(map(lambda x: abs(x) < sigma, residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.scatterplot(x=y_pred, y=residuals, hue=hue, palette = ['#E5C287', '#007F79'], s=100)\n",
    "# plt.axhline(y=0, color='#A79277', linestyle='--', lw=1)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Residuals')\n",
    "# plt.title('Residual Plot')\n",
    "# plt.savefig('./images/residuals.png')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Model_Train",
    "notebook_id": 4,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Getting the model performances\n",
    "xgr_model = make_pipeline(StandardScaler(),\n",
    "                          XGBRegressor(device='cuda'))\n",
    "\n",
    "cbr_model = make_pipeline(StandardScaler(),\n",
    "                          CatBoostRegressor(verbose=False, task_type='GPU'))\n",
    "\n",
    "cross_validate_print(xgr_model, X, y)\n",
    "cross_validate_print(cbr_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Model_Train",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ensemble_train[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": 35,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = best_model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/kaggle/input/playground-series-s4e5/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": 52,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_id": 53,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_id": 55,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train , y_train , epochs = 500 , batch_size = 1024 , validation_data = (x_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_id": 56,
    "class": "Model_Train",
    "notebook_id": 5,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_id": 55,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "model2=XGBRegressor(random_state=0,learning_rate=.1,max_depth=10,subsample=0.70,booster=\"gbtree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_id": 56,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# model2=MLPRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_id": 58,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_id": 59,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# ytrain=np.array(ytrain).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_id": 60,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# y.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cell_id": 61,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "prediction=model2.predict(xtrain)\n",
    "testy=model2.predict(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cell_id": 62,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# p=model.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cell_id": 64,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cell_id": 65,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# neural net-mlp regressor train score= 0.8509\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cell_id": 66,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "r2_score(ytrain,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_id": 67,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_id": 70,
    "class": "Model_Train",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "predict=model2.predict(testf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Model_Train",
    "notebook_id": 7,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train , y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = lr_model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = lr_model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Model_Train",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the AdaBoost Regressor model\n",
    "ada_model = AdaBoostRegressor()\n",
    "\n",
    "# Train the AdaBoost Regressor model on the training data\n",
    "ada_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = ada_model.predict(x_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = ada_model.predict(x_test)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Calculate RMSE, MSE, and MAE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training set:\")\n",
    "print(\"RMSE:\", rmse_train)\n",
    "print(\"MSE:\", mse_train)\n",
    "print(\"MAE:\", mae_train)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"RMSE:\", rmse_test)\n",
    "print(\"MSE:\", mse_test)\n",
    "print(\"MAE:\", mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Model_Train",
    "notebook_id": 7,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "outputs = ada_model.predict(x_target)\n",
    "output_df = pd.DataFrame(outputs , columns =  [\"FloodProbability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "def create_model(num_layers, num_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Input((20,)))\n",
    "    print(\"Model Created\")\n",
    "    model.add(Dense(num_neurons, activation=LeakyReLU(negative_slope=0.01)))\n",
    "    #model.add(Dropout(0.2, seed=42))\n",
    "    model.add(Dense(num_neurons, activation=LeakyReLU(negative_slope=0.01)))\n",
    "    model.add(Dense(num_neurons, activation=LeakyReLU(negative_slope=0.01)))\n",
    "    model.add(Dense(num_neurons, activation=LeakyReLU(negative_slope=0.01)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[R2Score()])\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"r2_score\", # watch the val loss metric\n",
    "                               patience = 5,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='r2_score', factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = create_model(5, 8)\n",
    "        \n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[\n",
    "                        early_stopping,\n",
    "                        reduce_lr\n",
    "    ],\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Assuming y_test_actual contains the actual target values\n",
    "# Assuming y_test_predicted contains the predicted target values\n",
    "y_predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(x_train, y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Model_Train",
    "notebook_id": 8,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "'''#Predict probabilities on the test set\n",
    "y_pred = rf_model.predict(x_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Model intialization\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = lr_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "sgd_model = SGDRegressor()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = sgd_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "rfr_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(rfr_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "rfr_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(rfr_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Create a base linear regression\n",
    "base_regressor = LinearRegression()\n",
    "\n",
    "# Create a bagging regressor with linear regressin\n",
    "bagged_regressor = BaggingRegressor(base_regressor, n_estimators=10)\n",
    "\n",
    "# Train the bagged regressor on your data\n",
    "bagged_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_pred = bagged_regressor.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "bgr_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(bgr_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# R-square score\n",
    "bgr_r2 = r2_score(y_val, y_pred)\n",
    "print(f'R-Squared Score: {np.round(bgr_r2 * 100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "gbr_model = GradientBoostingRegressor()\n",
    "gbr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = gbr_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": 36,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "svr_model = SVR()\n",
    "\n",
    "svr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": 37,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = svr_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "svr_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(svr_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": 39,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "svr_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(svr_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LGBM_model = LGBMRegressor(n_estimators=100)\n",
    "\n",
    "LGBM_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": 42,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = LGBM_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "lgbm_mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Absolute Error: {np.round(lgbm_mae, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": 44,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "lgbm_mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {np.round(lgbm_mse, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Model_Train",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Model':['LinearRegression', 'SGDRegressor', 'RandomForestRegressor', 'BaggingRegressor', 'GradientBoostingRegressor', 'SVR', 'LGBM'],\n",
    "                       'MAE': [lr_mae, sgd_mae, rfr_mae, bgr_mae, gbr_mae, svr_mae, lgbm_mae],\n",
    "                       'MSE': [lr_mse, sgd_mse, rfr_mse, bgr_mse, gbr_mse, svr_mse, lgbm_mse],\n",
    "                       'R2': [lr_r2, sgd_r2, rfr_r2, bgr_r2, gbr_r2, svr_r2, lgbm_r2]})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Model_Train",
    "notebook_id": 11,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "!pip install lazypredict\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, VotingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Options\n",
    "pd.set_option('display.max_columns',50)\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Model_Train",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    ('bayesian ridge', BayesianRidge()),\n",
    "    ('elastic net',ElasticNetCV()),\n",
    "    ('linear_reg', LinearRegression()),\n",
    "    ('lasso',LassoCV()),\n",
    "    ('ridge',RidgeCV())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Model_Train",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "evals = {}\n",
    "for clf, model in regressors:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    evals[clf] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Model_Train",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "evals_df = pd.DataFrame({'model':evals.keys(),'r2_score':evals.values()})\n",
    "evals_df.sort_values('r2_score', inplace = True)\n",
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 23,
    "class": "Model_Train",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('bayesian_ridge', best_estimators['bayesian_ridge']),\n",
    "    ('elastic_net', best_estimators['elastic_net']),\n",
    "    ('linear_reg', best_estimators['linear_reg']),\n",
    "    ('lasso', best_estimators['lasso']),\n",
    "    ('ridge', best_estimators['ridge'])\n",
    "])\n",
    "\n",
    "# Fit the VotingRegressor on the dataset\n",
    "voting_regressor.fit(X, y)\n",
    "y_preds = voting_regressor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Model_Train",
    "notebook_id": 13,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "!pip install -q catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Model_Train",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor()\n",
    "cat_model = CatBoostRegressor(verbose=False)\n",
    "lgb_model = lgb.LGBMRegressor(verbose=-1)\n",
    "\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "stacked = StackingRegressor(estimators=[\n",
    "    ('xgb', xgb_model),\n",
    "    ('cat', cat_model),\n",
    "    ('lgb', lgb_model)],\n",
    "    final_estimator=meta_model)\n",
    "\n",
    "stacked.fit(X_train, y_train)\n",
    "preds = stacked.predict(X_val)\n",
    "\n",
    "print(\"Stacked R2:\", r2_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Model_Train",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators = 8000, max_depth = 9,\n",
    "                   learning_rate =  0.05371502553155743,\n",
    "                   subsample = 0.85715838272758116,\n",
    "                   colsample_bytree = 0.892390046436166,\n",
    "                   gamma = 0.012984290742285246,\n",
    "                   min_child_weight = 3,\n",
    "                   random_state = 0)\n",
    "\n",
    "cat_model = CatBoostRegressor(n_estimators = 8000, learning_rate = 0.011277016304363601,\n",
    "                       depth = 8, min_data_in_leaf = 98, random_state = 0, devices='0', verbose=False)\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(boosting_type = 'gbdt', n_estimators = 2000,\n",
    "                    learning_rate =  0.012, num_leaves = 250,\n",
    "                    subsample_for_bin = 165700, min_child_samples = 114,\n",
    "                    reg_alpha = 2.075e-06, reg_lambda = 3.839e-07,\n",
    "                    colsample_bytree = 0.9634, subsample = 0.9592,\n",
    "                    max_depth = 10, random_state = 0, verbose = 0)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "cat_model.fit(X_train, y_train)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_val)\n",
    "cat_pred = cat_model.predict(X_val)\n",
    "lgb_pred = lgb_model.predict(X_val)\n",
    "\n",
    "y_pred = 0.33*xgb_pred + 0.33*cat_pred + 0.34*lgb_pred\n",
    "print(\"Stacked R2:\", r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Model_Train",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X_train.shape[1], ))\n",
    "\n",
    "x = Dense(512, activation='gelu')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.15)(x)\n",
    "\n",
    "x = Dense(256, activation='gelu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Dense(128, activation='gelu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.05)(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.001)(x)\n",
    "\n",
    "output_layer = Dense(1, activation='linear')(x)\n",
    "\n",
    "my_model = Model(input_layer, output_layer)\n",
    "opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.9999, epsilon=1e-01)\n",
    "my_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=\"/content/best_model.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\")\n",
    "\n",
    "history = my_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=512,\n",
    "    verbose=1,\n",
    "    callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Model_Train",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model(\"/content/best_model.keras\")\n",
    "y_pred = best_model.predict(X_val)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(\"R^2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Model_Train",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 14,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "ri.fit(X_train_t,y_train)\n",
    "ri.score(X_train_t,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Train",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ri.score(X_test_t,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Model_Train",
    "notebook_id": 14,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_data_t=pipe.transform(test_data_new)\n",
    "test_final=gv.predict(test_data_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 15,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the instance on the data and then predict the expected value\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_score(lr_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Model_Train",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_ids = test_df['id']\n",
    "\n",
    "# Remove 'id' column from df_test\n",
    "test_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Create a new column 'fsum' which is the sum of all feature columns for each row\n",
    "test_df['fsum'] = test_df.sum(axis=1) \n",
    "\n",
    "# Scale data\n",
    "test_df = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": 46,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "\n",
    "linear.fit(X_train,y_train)\n",
    "print(f\"Training score {linear.score(X_train,y_train)}\")\n",
    "y_pred = linear.predict(X_test)\n",
    "print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "linear_score = r2_score(y_test,y_pred)\n",
    "linear_Tscore = linear.score(X_train,y_train)\n",
    "# without dropping\n",
    "# Training score 0.8457594591756623\n",
    "# R2: 0.8454697171996348\n",
    "# after dropping\n",
    "# Training score 0.8459854314345968\n",
    "# R2: 0.8446050432676502\n",
    "\n",
    "# BETTER TRAIN, WORSE TEST\n",
    "\n",
    "# Training score 0.8449632386720447\n",
    "# R2: 0.8448671419805959\n",
    "\n",
    "# Training score 0.8451228724650743\n",
    "# R2: 0.8450173448266534\n",
    "\n",
    "# linear complete data\n",
    "# Training score 0.8488268363920475\n",
    "# R2: 0.8484823666612045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": 47,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cat_model = CatBoostRegressor()\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat_model.predict(X_test)\n",
    "print(f\"Training score {cat_model.score(X_train,y_train)}\")\n",
    "print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "CatBoost_score = r2_score(y_test,y_pred)\n",
    "CatBoost_Tscore = cat_model.score(X_train,y_train)\n",
    "\n",
    "# without dropping\n",
    "# Training score 0.849059370869179\n",
    "# R2: 0.8458341178802313\n",
    "# after dropping\n",
    "# Training score 0.8495838425142408\n",
    "# R2: 0.8450550512464129\n",
    "\n",
    "# BETTER TRAIN, WORSE TEST\n",
    "\n",
    "# Training score 0.8511034268861708\n",
    "# R2: 0.8484659428975101\n",
    "\n",
    "# Training score 0.8510983395654057\n",
    "# R2: 0.8482567996850483\n",
    "\n",
    "# with high corr only\n",
    "# Training score 0.8689939905594077\n",
    "# R2: 0.8671051110548669\n",
    "\n",
    "# Training score 0.8692380657333689\n",
    "# R2: 0.8673866049021248\n",
    "\n",
    "# cat complete data\n",
    "# Training score 0.8712936535722917\n",
    "# R2: 0.8684364777340219\n",
    "\n",
    "# Training score 0.8713026887254586\n",
    "# R2: 0.868381238518181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": 48,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "xg_model = XGBRegressor()\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xg_model.predict(X_test)\n",
    "print(f\"Training score {xg_model.score(X_train,y_train)}\")\n",
    "print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "XGBoost_score = r2_score(y_test,y_pred)\n",
    "XGBoost_Tscore = xg_model.score(X_train,y_train)\n",
    "\n",
    "# without dropping\n",
    "# Training score 0.8185763391684946\n",
    "# R2: 0.8092899007536791\n",
    "# after dropping\n",
    "# Training score 0.818278893261753\n",
    "# R2: 0.8075431863252942\n",
    "\n",
    "# BETTER TRAIN, WORSE TEST\n",
    "\n",
    "# Training score 0.8320398257448948\n",
    "# R2: 0.8265681584631458\n",
    "\n",
    "# Training score 0.8370201885233045\n",
    "# R2: 0.8313670522106444\n",
    "\n",
    "# with high corr only\n",
    "# Training score 0.8694170389349443\n",
    "# R2: 0.8668235370658703\n",
    "\n",
    "# Training score 0.8698661310623312\n",
    "# R2: 0.8672521384497449\n",
    "\n",
    "# xg complete data\n",
    "# Training score 0.8717124360778755\n",
    "# R2: 0.8681429795144493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_id": 56,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# ABC_model = AdaBoostRegressor(estimator=bc_model)\n",
    "# ABC_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = ABC_model.predict(X_test)\n",
    "# print(f\"Training score {ABC_model.score(X_train,y_train)}\")\n",
    "# print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "# ABC_score = r2_score(y_test,y_pred)\n",
    "# ABC_Tscore = ABC_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_id": 58,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "vc_model = VotingRegressor(estimators)\n",
    "vc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = vc_model.predict(X_test)\n",
    "print(f\"Training score {vc_model.score(X_train,y_train)}\")\n",
    "print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "VR_score = r2_score(y_test,y_pred)\n",
    "VR_Tscore = vc_model.score(X_train,y_train)\n",
    "\n",
    "# without dropping\n",
    "# Training score 0.8456583210297507\n",
    "# R2: 0.8417872917459406\n",
    "# after dropping\n",
    "# Training score 0.8459156228601873\n",
    "# R2: 0.8408403700058219\n",
    "\n",
    "# BETTER TRAIN, WORSE TEST\n",
    "\n",
    "# Training score 0.8477804436778823\n",
    "# R2: 0.8451736968761587\n",
    "\n",
    "# Training score 0.8486829862581831\n",
    "# R2: 0.8459588292860563\n",
    "\n",
    "# with high corr only\n",
    "# Training score 0.8661221100918872\n",
    "# R2: 0.8645853469530693\n",
    "\n",
    "# Training score 0.8664405855516222\n",
    "# R2: 0.8649047721345305\n",
    "\n",
    "# voting complete data\n",
    "# Training score 0.8684375143959511\n",
    "# R2: 0.8661693484135519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_id": 59,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "SC_model = StackingRegressor(estimators)\n",
    "SC_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = SC_model.predict(X_test)\n",
    "print(f\"Training score {SC_model.score(X_train,y_train)}\")\n",
    "print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "StackReg_score = r2_score(y_test,y_pred)\n",
    "StackReg_Tscore = SC_model.score(X_train,y_train)\n",
    "\n",
    "# Training score 0.8486827459210073\n",
    "# R2: 0.8454175629190451\n",
    "# after dropping\n",
    "# Training score 0.8488442450516133\n",
    "# R2: 0.8450995697555888\n",
    "\n",
    "# BETTER TRAIN, WORSE TEST\n",
    "\n",
    "# Training score 0.8513106187494396\n",
    "# R2: 0.8484909488287333\n",
    "\n",
    "# Training score 0.8508926163373516\n",
    "# R2: 0.8482738572320817\n",
    "\n",
    "# with high corr only\n",
    "# Training score 0.8692084944453877\n",
    "# R2: 0.8671144372609388\n",
    "\n",
    "# Training score 0.8695405752611133\n",
    "# R2: 0.8674593045005337\n",
    "\n",
    "# complete data\n",
    "# Training score -0.8129348173408533\n",
    "# R2: -0.8206480970793406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_id": 60,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LG_model = LGBMRegressor(boosting_type = 'gbdt', \n",
    "                         n_estimators=2000, \n",
    "                         learning_rate =  0.012,\n",
    "                         num_leaves = 250, \n",
    "                         subsample_for_bin= 165700, \n",
    "                         min_child_samples= 114, \n",
    "                         reg_alpha= 2.075e-06, \n",
    "                         reg_lambda= 3.839e-07, \n",
    "                         colsample_bytree= 0.9634,\n",
    "                         subsample= 0.9592, \n",
    "                         max_depth= 10,\n",
    "                         random_state=0,\n",
    "                         verbosity=-1)\n",
    "LG_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LG_model.predict(X_test)\n",
    "print(f\"Training score {LG_model.score(X_train,y_train)}\")\n",
    "print(f\"R2: {r2_score(y_test,y_pred)}\")\n",
    "LGReg_score = r2_score(y_test,y_pred)\n",
    "LGReg_Tscore = LG_model.score(X_train,y_train)\n",
    "\n",
    "# without dropping\n",
    "# Training score 0.7722033445629952\n",
    "# R2: 0.7656664606302841\n",
    "# after dropping\n",
    "# Training score 0.7736411682470161\n",
    "# R2: 0.765641172682489\n",
    "\n",
    "# BETTER TRAIN, WORSE TEST\n",
    "\n",
    "# 0.8355890630044472\n",
    "# R2: 0.8330412134653961\n",
    "\n",
    "# Training score 0.8179158545212489\n",
    "# R2: 0.8154329421048914\n",
    "\n",
    "# with high corr only\n",
    "# Training score 0.8677071132111231\n",
    "# R2: 0.8670502864448657\n",
    "\n",
    "# Training score 0.8680294090677185\n",
    "# R2: 0.8673631191473345\n",
    "\n",
    "# LGBM complete data\n",
    "# Training score 0.8693953938884129\n",
    "# R2: 0.8684146412104383\n",
    "\n",
    "# [LightGBM] [Info] Start training from score 0.504480\n",
    "# Training score 0.8693418511330352\n",
    "# R2: 0.868388306489848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cell_id": 61,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# result = [\n",
    "#     {\"Model\": \"Linear\", \"Training score\": linear_score , \"R2\": linear_Tscore},\n",
    "#     {\"Model\": \"CatBoost\", \"Training score\": CatBoost_score , \"R2\": CatBoost_Tscore},\n",
    "#     {\"Model\": \"XGBoost\", \"Training score\": XGBoost_score , \"R2\": XGBoost_Tscore ,\n",
    "#     {\"Model\": \"SVR\", \"Training score\": SVR_score, \"R2\": SVR_Tscore },\n",
    "#     {\"Model\": \"KNN\", \"Training score\": KNN_score , \"R2\": KNN_Tscore },\n",
    "#     {\"Model\": \"Decision Tree\", \"Training score\": DT_score , \"R2\": DT_Tscore },\n",
    "#     {\"Model\": \"Random Forest\", \"Training score\": RF_score , \"R2\": RF_Tscore },\n",
    "#     {\"Model\": \"Bagging\", \"Training score\": BagReg_score , \"R2\": BagReg_Tscore },\n",
    "#     {\"Model\": \"Extra Trees\", \"Training score\": ET_score , \"R2\": ET_Tscore },\n",
    "#     {\"Model\": \"AdaBoost\", \"Training score\": ABC_score , \"R2\": ABC_Tscore },\n",
    "#     {\"Model\": \"VotingRegressor\", \"Training score\": VR_score , \"R2\": VR_Tscore },\n",
    "#     {\"Model\": \"Stacking\", \"Training score\": StackReg_score , \"R2\": StackReg_Tscore ,\n",
    "#     {\"Model\": \"LGBMRegressor\", \"Training score\": LGReg_score , \"R2\": LGReg_Tscore \n",
    "# ]\n",
    "\n",
    "# result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cell_id": 63,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# result_df = result_df.sort_values(by='Training score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_id": 67,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cat_model = CatBoostRegressor()\n",
    "# cat_model.fit(X, y)\n",
    "\n",
    "# y_pred_cat = cat_model.predict(test_set)\n",
    "# print(f\"Training score {cat_model.score(X,y)}\")\n",
    "\n",
    "# # Training score 0.8688006661365003\n",
    "\n",
    "# # Training score 0.8690503412244763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_id": 69,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# y_pred_SC = pd.DataFrame(y_pred_SC)\n",
    "# output_SC = test_set_id\n",
    "# output_SC[\"FloodProbability\"] = pd.DataFrame(y_pred_SC)\n",
    "# output_SC = output_SC.set_index(\"id\")\n",
    "# output_SC.to_csv(\"FloodProbability_OHE_project_FEng_SC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cell_id": 73,
    "class": "Model_Train",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LG_model = LGBMRegressor(boosting_type = 'gbdt', \n",
    "                         n_estimators=2000, \n",
    "                         learning_rate =  0.012,\n",
    "                         num_leaves = 250, \n",
    "                         subsample_for_bin= 165700, \n",
    "                         min_child_samples= 114, \n",
    "                         reg_alpha= 2.075e-06, \n",
    "                         reg_lambda= 3.839e-07, \n",
    "                         colsample_bytree= 0.9634,\n",
    "                         subsample= 0.9592, \n",
    "                         max_depth= 10,\n",
    "                         random_state=0,\n",
    "                         verbosity=-1)\n",
    "LG_model.fit(X, y)\n",
    "\n",
    "y_pred_LG = LG_model.predict(test_set)\n",
    "print(f\"Training score {LG_model.score(X,y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model_1 = XGBRegressor()\n",
    "model_1.fit(\n",
    "    X_train, Y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Train",
    "notebook_id": 18,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "mse = mean_absolute_error(y_test, predictions1)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['r2_score'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "call_back = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, callbacks= call_back , validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(tr_loss))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "max(history.history['val_r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "call_back2 = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train, y_train, epochs=100, batch_size=64, callbacks= call_back2 , validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "call_back3 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "history3 = model3.fit(X_train, y_train, epochs=100, batch_size=64, callbacks= call_back3 , validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(8, activation='relu', input_dim=X_train.shape[1]),    \n",
    "    Dense(1, activation='linear'),\n",
    "\n",
    "])\n",
    "\n",
    "model4.compile(optimizer=SGD(learning_rate=0.001), loss='mean_squared_error', metrics=['r2_score'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 28,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "max(history4.history['val_r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_pred = model3.predict(test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# make y_pred a 1d array\n",
    "y_pred = y_pred.reshape(y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Model_Train",
    "notebook_id": 19,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test.index.values, 'FloodProbability': y_pred}, columns=['id', 'FloodProbability'])\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Model_Train",
    "notebook_id": 20,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "y_pred=np.ndarray.flatten(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 21,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# lets run polynomial regression on our data due to it's best results\n",
    "\n",
    "# Create a polynomial features object with degree 2\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_poly = poly_reg.fit_transform(testing)\n",
    "\n",
    "\n",
    "FloodProbability = model.predict(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Model_Train",
    "notebook_id": 22,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# Instantiate baseline regression algorithms\n",
    "lin_reg = LinearRegression()\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "svr = SVR()\n",
    "lgbm = LGBMRegressor()\n",
    "xgb_reg = XGBRegressor()\n",
    "kn_reg = KNeighborsRegressor()\n",
    "tree = DecisionTreeRegressor(random_state = 42)\n",
    "forest = RandomForestRegressor(random_state = 42)\n",
    "grad_boost = GradientBoostingRegressor(random_state = 42)\n",
    "\n",
    "# Define a function that fits and trains training data then test it on the test data \n",
    "def building_model(model, model_name, X_train, X_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "        \n",
    "    train_score.append(round(model.score(X_train, y_train), 3))\n",
    "    test_score.append(round(model.score(X_val, y_val), 3))\n",
    "    r2.append(round(r2_score(y_val, y_pred), 3))\n",
    "    mae.append(round(mean_absolute_error(y_val, y_pred), 3))\n",
    "    rmse.append(round(np.sqrt(mean_squared_error(y_val, y_pred)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": 45,
    "class": "Model_Train",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_pred = pd.Series(y_pred, index = X_test.index, name = 'predicted_proba')\n",
    "results = pd.concat([y_test, y_pred], axis = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 23,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 23,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "y_predict=pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "XGBooster.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": 47,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LGBMBooster.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cell_id": 64,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "voter.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_id": 69,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "#Builing a Stacking classifier\n",
    "stack = StackingRegressor(estimators = estimators, final_estimator = final_estimator, cv = 3, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_id": 70,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "stack.fit(X,np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cell_id": 75,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "stack_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cell_id": 76,
    "class": "Model_Train",
    "notebook_id": 24,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "stack_result.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Train",
    "notebook_id": 25,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Spliting Data\n",
    "X = train.drop([\"id\", \"FloodProbability\"], axis=1)\n",
    "y = train[\"FloodProbability\"]\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Model_Train",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# List of models to test\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'XGBOOST': xgb.XGBRegressor(),\n",
    "    'LGBM' : ltb.LGBMRegressor()\n",
    "}\n",
    "\n",
    "# DataFrame to store model performances\n",
    "performance = pd.DataFrame(columns=['Model', 'MSE'])\n",
    "\n",
    "# Fit models and calculate performances\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train[feats], y_train)\n",
    "    X_test[f'{name}_pred'] = model.predict(X_test[feats])\n",
    "    mse = mean_squared_error(y_test, X_test[f'{name}_pred'])\n",
    "    performance = pd.concat([performance, pd.DataFrame({'Model': [name], 'MSE': [mse]})], ignore_index=True)\n",
    "\n",
    "# Display model performances\n",
    "print(performance)\n",
    "\n",
    "# Visualize residuals for each model\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    plt.subplot(4, 2, i)\n",
    "    X_test['residuals'] = y_test - X_test[f'{name}_pred']\n",
    "    sns.boxplot(x=X_test['residuals'])\n",
    "    plt.title(f'Residuals for {name}')\n",
    "    plt.xlabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 21,
    "class": "Model_Train",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Model combination\n",
    "model_1 = Ridge()\n",
    "model_2 = xgb.XGBRegressor()\n",
    "\n",
    "# Training of models on train\n",
    "model_1.fit(X_train[feats], y_train)\n",
    "model_2.fit(X_train[feats], y_train)\n",
    "\n",
    "# Predictions of models on train\n",
    "pred_train_1 = model_1.predict(X_train[feats])\n",
    "pred_train_2 = model_2.predict(X_train[feats])\n",
    "residu_train_1 = pred_train_1 - y_train\n",
    "\n",
    "# Combination of predictions on train\n",
    "stacked_predictions_train = np.column_stack((pred_train_1, pred_train_2))\n",
    "\n",
    "# Meta motel\n",
    "meta_model = ltb.LGBMRegressor()\n",
    "meta_model.fit(stacked_predictions_train, y_train)\n",
    "\n",
    "# Prediction of models on test\n",
    "pred_test_1 = model_1.predict(X_test[feats])\n",
    "pred_test_2 = model_2.predict(X_test[feats])\n",
    "residu_test_1 = pred_test_1 - y_test\n",
    "\n",
    "# Combinaison of prediction on test\n",
    "stacked_predictions_test = np.column_stack((pred_test_1, pred_test_2))\n",
    "\n",
    "# Laste prediction of meta model\n",
    "final_predictions = meta_model.predict(stacked_predictions_test)\n",
    "\n",
    "# Evaluation model\n",
    "mse = mean_squared_error(y_test, final_predictions)\n",
    "print(\"score\", r2_score(y_test, final_predictions))\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Model_Train",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_id =test.copy()\n",
    "model_final = meta_model\n",
    "model_final.fit(X_train[feats], y_train)\n",
    "y_pred = model_final.predict(X_test[feats])\n",
    "print(r2_score(y_test, y_pred))\n",
    "test_id.loc[:,\"FloodProbability\"] = model_final.predict(test[feats])\n",
    "submission = test_id[[\"id\", \"FloodProbability\"]]\n",
    "submission.to_csv(\"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 24,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "LRout=LinearRegression()\n",
    "LRout.fit(Xout1_train,yout1_train)\n",
    "LRoutPred=LRout.predict(Xout1_test)\n",
    "mseout=mean_squared_error(yout1_test,LRoutPred)\n",
    "rmseout=np.sqrt(mseout)\n",
    "maeout=mean_absolute_error(yout1_test,LRoutPred)\n",
    "r2outscore=r2_score(yout1_test,LRoutPred)\n",
    "print('Mean Squared Error : ', mseout)\n",
    "print('Root Mean Squared Error : ', rmseout)\n",
    "print('Mean Absolute Error : ', maeout)\n",
    "print('R2 Score : ' ,r2outscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "Xall_train,Xall_test,yall_train,yall_test=train_test_split(Xall,yall,test_size=.3,random_state=42)\n",
    "print(Xall_train.shape,Xall_test.shape,yall_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": 29,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LR=LinearRegression()\n",
    "LR.fit(Xall_train_std,yall_train)\n",
    "LR_pred=LR.predict(Xall_test_std)\n",
    "mseall=mean_squared_error(yall_test,LR_pred)\n",
    "rmseall=np.sqrt(mseall)\n",
    "maeall=mean_absolute_error(yall_test,LR_pred)\n",
    "r2scoreall = r2_score(yall_test,LR_pred)\n",
    "print('Mean Squared Error : ', mseall)\n",
    "print('Root Mean Squared Error : ', rmseall)\n",
    "print('Mean Absolute Error : ', maeall)\n",
    "print('R2 Score : ' ,r2scoreall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": 30,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "LRallPredTrain=LR.predict(Xall_train_std)\n",
    "LRallPredTest=LR.predict(Xall_test_std)\n",
    "\n",
    "alltrain_error = mean_absolute_error(yall_train, LRallPredTrain)\n",
    "alltest_error = mean_absolute_error(yall_test, LRallPredTest)\n",
    "\n",
    "print(\"Training Error:\", alltrain_error)\n",
    "print(\"Validation Error:\", alltest_error)\n",
    "\n",
    "r2allscoreTrain=r2_score(yall_train,LRallPredTrain)\n",
    "r2allscoreTest=r2_score(yall_test,LRallPredTest)\n",
    "\n",
    "print(\"Training R2score:\", r2allscoreTrain)\n",
    "print(\"Validation R2score:\", r2allscoreTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(yall_test, kde=True, color='green', label='Test', stat='density')\n",
    "sns.histplot(LR_pred, kde=True, color='orange', label='Predicted', stat='density')\n",
    "plt.title('Distribution Plot of Test and Predicted Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": 32,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": 33,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(Xall_train_std, yall_train)\n",
    "yreg_pred = ridge.predict(Xall_test_std)\n",
    "msereg=mean_squared_error(yall_test,yreg_pred)\n",
    "rmsereg=np.sqrt(msereg)\n",
    "maereg=mean_absolute_error(yall_test,yreg_pred)\n",
    "r2scorereg = r2_score(yall_test,yreg_pred)\n",
    "print('Mean Squared Error : ', msereg)\n",
    "print('Root Mean Squared Error : ', rmsereg)\n",
    "print('Mean Absolute Error : ', maereg)\n",
    "print('R2 Score : ' ,r2scorereg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": 34,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": 38,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "StdScaTest = StandardScaler()\n",
    "test_std=StdScaTest.fit_transform(df_test.iloc[:,1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": 40,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'FloodProbability': test_predictions\n",
    "})\n",
    "submission.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": 41,
    "class": "Model_Train",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Save the submission file\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 25,
    "class": "Model_Train",
    "notebook_id": 28,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ent,crossmi,mi_sc=get_mutual_info(dt_reg,y_reg,weight=penalty_weight)\n",
    "\n",
    "seq_mir=[]\n",
    "for f in mi_sc.index:\n",
    "    if f.startswith('random_'):\n",
    "        break\n",
    "    seq_mir.append(f)\n",
    "seq_mir=sorted(seq_mir)\n",
    "cvs_mir=cross_val_score(model,dt_reg[seq_mir],y_reg,scoring='r2',cv=10).mean()\n",
    "print(f'{cvs_mir:0.5f}  {\", \".join(seq_mir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "!pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "import lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 3,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 1000 * 3600\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "task = Task('reg', loss='mse', metric='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "automl = TabularAutoML(\n",
    "    task = task,\n",
    "    timeout = 600 * 3600,\n",
    "    cpu_limit = N_THREADS,\n",
    "    general_params = {'use_algos':[['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "    selection_params ={'mode' : 0},\n",
    "    tuning_params = {'max_tuning_time': 1200},\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    ")\n",
    "\n",
    "out_of_fold_predictions = automl.fit_predict(\n",
    "    train_data,\n",
    "    roles = {\n",
    "        'target': 'FloodProbability',\n",
    "        'drop': ['id']\n",
    "    }, \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "CONFIG_PATH = os.path.join(lightautoml.automl.presets.tabular_presets._base_dir, 'tabular_configs')\n",
    "\n",
    "configs_list = [os.path.join(CONFIG_PATH, x) for x in [\n",
    "    \"conf_1_sel_type_1.yml\",\n",
    "    \"conf_3_sel_type_1_no_inter_lgbm.yml\",\n",
    "]]\n",
    "\n",
    "automl_utilized = TabularUtilizedAutoML(\n",
    "    task = task, \n",
    "    timeout = TIMEOUT,\n",
    "    cpu_limit = N_THREADS,\n",
    "    general_params ={'use_algos':[['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "    tuning_params = {'max_tuning_time': 1200},\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "    configs_list = configs_list,\n",
    "    max_runs_per_config=4\n",
    ")\n",
    "\n",
    "out_of_fold_predictions_utilized = automl_utilized.fit_predict(\n",
    "    train_data,\n",
    "    roles = {\n",
    "        'target': 'FloodProbability',\n",
    "        'drop': ['id', 'fskew', 'fkurtosis']\n",
    "            }, \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_predictions = automl.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test_predictions_utilized = automl_utilized.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print(f'OOF score: {r2_score(train_data[\"FloodProbability\"].values, out_of_fold_predictions.data[:, 0])}')\n",
    "print(f'OOF score utilized: {r2_score(train_data[\"FloodProbability\"].values, out_of_fold_predictions_utilized.data[:, 0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_data.id.values,\n",
    "    'FloodProbability': 0.7 * test_predictions_utilized.data[:, 0] + 0.3 * test_predictions.data[:, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 29,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "final_models = [ m for m in models if m not in [\"autog3\", \"autog5\"]]\n",
    "\n",
    "params = {\"alpha\": .01, \"random_state\": seed, \"fit_intercept\" : False}\n",
    "\n",
    "all_intercepts, all_coefs, blend_scores = [], [], []\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    new_model = {\n",
    "        \"train\"       : oofs[r], \n",
    "        \"test\"        : preds[r], \n",
    "        \"features\"    : final_models,\n",
    "        \"my_model\"    : Ridge(**params), \n",
    "    }\n",
    "    res = do_ensemble(**new_model, do_feat_imp = False)\n",
    "    all_intercepts.extend(res[\"intercept\"]) ; all_coefs.append(res[\"coefs\"])\n",
    "    blend_scores.append(res[\"oofs_score\"])\n",
    "    \n",
    "print(f\"{bold}Final mean RMSE {bold_blue}{np.mean(blend_scores):.6f}{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(n_repeats, 1, figsize = (10, int(all_coefs[0].shape[1] * 0.5 * n_repeats)), \n",
    "                       sharex = True, tight_layout = True)\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    ax[i].boxplot(all_coefs[i], vert = False, labels = all_coefs[i].columns)\n",
    "    ax[i].axvline(x = 0, color = 'green')\n",
    "    ax[i].set_title(f\"Regression results over folds in repetition n° {i+1}\")\n",
    "    ax[i].set_xlabel(\"Coefficients values\")\n",
    "    ax[i].xaxis.set_ticks_position(\"top\")\n",
    "    ax[i].xaxis.set_label_position('top')\n",
    "    ax[i].spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for n in range(n_repeats):\n",
    "    for df in [oofs[n], preds[n]]:\n",
    "        df[\"cb7_9_12\"] = (df[\"cb7\"] + df[\"cb9\"] + df[\"cb12\"]) / 3\n",
    "\n",
    "for m in [\"cb7_9_12\"]:\n",
    "    if m not in models:\n",
    "        models.append(m)\n",
    "\n",
    "final_models = [ m for m in models if m not in [\"autog3\", \"autog5\", \"cb7\", \"cb9\", \"cb12\"]]\n",
    "\n",
    "params = {\"alpha\": .01, \"random_state\": seed, \"fit_intercept\" : False}\n",
    "\n",
    "all_intercepts, all_coefs, blend_scores = [], [], []\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    new_model = {\n",
    "        \"train\"       : oofs[r], \n",
    "        \"test\"        : preds[r], \n",
    "        \"features\"    : final_models,\n",
    "        \"my_model\"    : Ridge(**params), \n",
    "    }\n",
    "    res = do_ensemble(**new_model, do_feat_imp = False)\n",
    "    all_intercepts.extend(res[\"intercept\"]) ; all_coefs.append(res[\"coefs\"])\n",
    "    blend_scores.append(res[\"oofs_score\"])\n",
    "    \n",
    "print(f\"{bold}Final mean RMSE {bold_blue}{np.mean(blend_scores):.6f}{end}\")\n",
    "\n",
    "_, ax = plt.subplots(n_repeats, 1, figsize = (10, int(all_coefs[0].shape[1] * 0.5 * n_repeats)), \n",
    "                       sharex = True, tight_layout = True)\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    ax[i].boxplot(all_coefs[i], vert = False, labels = all_coefs[i].columns)\n",
    "    ax[i].axvline(x = 0, color = 'green')\n",
    "    ax[i].set_title(f\"Regression results over folds in repetition n° {i+1}\")\n",
    "    ax[i].set_xlabel(\"Coefficients values\")\n",
    "    ax[i].xaxis.set_ticks_position(\"top\")\n",
    "    ax[i].xaxis.set_label_position('top')\n",
    "    ax[i].spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for n in range(n_repeats):\n",
    "    for df in [oofs[n], preds[n]]:\n",
    "        df[\"cb7_9_12\"] = (df[\"cb7\"] + df[\"cb9\"] + df[\"cb12\"]) / 3\n",
    "        df[\"xgb11_12_13\"] = (df[\"xgb11\"] + df[\"xgb12\"] + df[\"xgb13\"]) / 3\n",
    "        df[\"cb2_3\"] = (df[\"cb2\"] + df[\"cb3\"]) / 2\n",
    "        df[\"lgbm5_xgb10\"] = (df[\"lgbm5\"] + df[\"xgb10\"]) / 2\n",
    "        df[\"cb2_cb3_lgbm5_xgb10\"] = (df[\"cb2\"] + df[\"cb3\"] + df[\"lgbm5\"] + df[\"xgb10\"]) / 4\n",
    "\n",
    "for m in [\"cb7_9_12\", \"xgb11_12_13\", \"cb2_3\", \"lgbm5_xgb10\", \"cb2_cb3_lgbm5_xgb10\"]:\n",
    "    if m not in models:\n",
    "        models.append(m)\n",
    "\n",
    "final_models = [ m for m in models if m not in [\n",
    "    \"autog3\", \"autog5\", \"xgb3\", \"lgbm10\", \"lgbm6\", \"lgbm14\", \"lgbm15\", \"lgbm7\", \"xgb9\", \"lgbm12\",\n",
    "    \"cb10\", \"lgbm17\", \"rf1\", \"cb6\", \"cb11\", \"cb4\", \"cb5\", \"xgb6\", \"cb7\", \"cb9\", \"cb12\",\n",
    "    \"xgb11\", \"xgb12\", \"xgb13\", \"et1\", \"xgb4\", \"lgbm11\", \"cb2\", \"cb3\", \"lgbm5\", \"xgb10\",\n",
    "    \"bestlgbm2\", \"cb2_3\", \"lgbm5_xgb10\",\n",
    "]]\n",
    "\n",
    "params = {\"alpha\": .01, \"random_state\": seed, \"fit_intercept\" : False}\n",
    "\n",
    "all_intercepts, all_coefs, blend_scores = [], [], []\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    new_model = {\n",
    "        \"train\"       : oofs[r], \n",
    "        \"test\"        : preds[r], \n",
    "        \"features\"    : final_models,\n",
    "        \"my_model\"    : Ridge(**params), \n",
    "    }\n",
    "    res = do_ensemble(**new_model, do_feat_imp = True)\n",
    "    all_intercepts.extend(res[\"intercept\"]) ; all_coefs.append(res[\"coefs\"])\n",
    "    blend_scores.append(res[\"oofs_score\"])\n",
    "    \n",
    "print(f\"{bold}Final mean RMSE {bold_blue}{np.mean(blend_scores):.6f}{end}\")\n",
    "\n",
    "_, ax = plt.subplots(n_repeats, 1, figsize = (10, int(all_coefs[0].shape[1] * 0.5 * n_repeats)), \n",
    "                       sharex = True, tight_layout = True)\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    ax[i].boxplot(all_coefs[i], vert = False, labels = all_coefs[i].columns)\n",
    "    ax[i].axvline(x = 0, color = 'green')\n",
    "    ax[i].set_title(f\"Regression results over folds in repetition n° {i+1}\")\n",
    "    ax[i].set_xlabel(\"Coefficients values\")\n",
    "    ax[i].xaxis.set_ticks_position(\"top\")\n",
    "    ax[i].xaxis.set_label_position('top')\n",
    "    ax[i].spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "all_scores = {}\n",
    "ascending = True\n",
    "for r in range(n_repeats):\n",
    "    for m in final_models:\n",
    "        if r == 0:\n",
    "            all_scores[m] = []\n",
    "        all_scores[m].append(score_(train[target], oofs[r][m]))\n",
    "        \n",
    "all_scores[\"Ensemble\"] = blend_scores\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores)\n",
    "_col_order = list(all_scores.mean(axis=0).sort_values(ascending = ascending).index)\n",
    "all_scores = all_scores[_col_order]\n",
    "\n",
    "_t = list(all_scores.mean(axis=0).sort_values(ascending = ascending).values)\n",
    "_labels = [f\"{l:15} ({v:.5})\" for l,v in zip(_col_order, _t)]\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize = (10, int(all_scores.shape[1] * 1/2)))\n",
    "ax.boxplot(all_scores, vert = False, labels = _labels)\n",
    "ax.set_title(\"OOFS R2\")\n",
    "ax.set_xlabel(\"R2 (higher is better)\")\n",
    "ax.xaxis.set_ticks_position(\"top\")\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print(final_models)\n",
    "_oofs = oofs[0][final_models].copy()\n",
    "_preds = preds[0][final_models].copy()\n",
    "\n",
    "for m in final_models:\n",
    "    for n in range(n_repeats):\n",
    "        _oofs[m] += oofs[n][m] / n_repeats\n",
    "        _preds[m] += preds[n][m] / n_repeats\n",
    "    \n",
    "model = Ridge(**params)\n",
    "model.fit(_oofs, train[target])\n",
    "y_oof = model.predict(_oofs)\n",
    "print(f\"R2 score on train : {score_(train[target], y_oof):.6f}\")\n",
    "y_pred = pd.Series(model.predict(_preds), index=test.index, name=target)\n",
    "y_pred.to_csv(f\"submission_without_autogluon.csv\")\n",
    "!head submission_without_autogluon.csv\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize = (15, int(len(final_models) * 1/2)))\n",
    "sns.barplot(x = model.coef_, y = final_models, ax = ax, color = \"blue\")\n",
    "plt.gca().invert_yaxis()\n",
    "ax.axvline(x = 0, color = 'green')\n",
    "ax.xaxis.set_ticks_position(\"top\")\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.spines[[\"right\", \"bottom\"]].set_visible(False)\n",
    "ax.set_title(f\"Coefficient values with all mean of oofs files\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "models = [m for m in models if m not in [\"cb7_9_12\", \"xgb11_12_13\", \"cb2_3\", \"lgbm5_xgb10\", \"cb2_cb3_lgbm5_xgb10\"]]\n",
    "\n",
    "for n in range(n_repeats):\n",
    "    for df in [oofs[n], preds[n]]:\n",
    "        df[\"cb7_9_12\"] = (df[\"cb7\"] + df[\"cb9\"] + df[\"cb12\"]) / 3\n",
    "        df[\"xgb12_13\"] = (df[\"xgb12\"] + df[\"xgb13\"]) / 2\n",
    "        df[\"autog3_5\"] = (df[\"autog3\"] + df[\"autog5\"]) / 2\n",
    "        df[\"cb2_3\"] = (df[\"cb2\"] + df[\"cb3\"]) / 2\n",
    "        df[\"lgbmcorr_xgb8_lgbm9\"] = (df[\"bestlgbmcorr\"] + df[\"xgb8\"] + df[\"lgbm9\"]) / 3\n",
    "\n",
    "for m in [\"cb7_9_12\", \"xgb12_13\", \"cb2_3\", \"autog3_5\", \"lgbmcorr_xgb8_lgbm9\"]:\n",
    "    if m not in models:\n",
    "        models.append(m)\n",
    "\n",
    "final_models = [ m for m in models if m not in \n",
    "                [\n",
    "                 \"lgbm12\", \"lgbm6\", \"cb4\", \"lgbm7\", \"xgb4\", \"cb6\",\n",
    "                 \"cb10\", \"cb5\", \"xgb3\", \"xgb9\", \"xgb6\", \n",
    "                 \"xgb12\", \"xgb13\", \"rf1\", \"xgb10\", \"lgbm15\", \"et1\", \"lgbm10\", # le 24 mai, avec xgb12, 13 et 12_13\n",
    "                 \"lgbm11\", # le 25 mai avec ajout autog1\n",
    "                 \"cb11\", \"xbg11\", # le 25 mai avec ajout cb12 et cb13\n",
    "                 \"bestlgbm2\", \"xgb11\", \"lgbm14\",# le 26 mai, ajout d'un 2ème fold autogluon, et erreur sur libellé xgb11\n",
    "                 \n",
    "                 \"cb7\", \"cb9\", \"cb12\", #\"cb7_9_12\", \n",
    "                 \"cb2\", \"cb3\", # \"cb2_3\", \n",
    "                 \"autog4\",\n",
    "                 \"lgbm17\", \"lgbm16\", # le 28 mai ajout lgbm16 et 17\n",
    "#                 \"autog3_5\", \n",
    "                 \"autog3\", \"autog5\", \n",
    "                 \"bestlgbmcorr\", \"xgb8\", \"lgbm9\"\n",
    "                ]]\n",
    "\n",
    "params = {\"alpha\": .001, \"random_state\": seed, \"fit_intercept\" : False}#, \"positive\": True}\n",
    "all_intercepts, all_coefs, blend_scores = [], [], []\n",
    "\n",
    "oof_mean = pd.Series(0.0, index = train.index, name= target)\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    new_model = {\n",
    "        \"train\"       : oofs[r], \n",
    "        \"test\"        : preds[r], \n",
    "        \"features\"    : final_models,\n",
    "        \"my_model\"    : Ridge(**params), \n",
    "    }\n",
    "    res = do_ensemble(**new_model, do_feat_imp = True)\n",
    "    all_intercepts.extend(res[\"intercept\"]) ; all_coefs.append(res[\"coefs\"])\n",
    "    blend_scores.append(res[\"oofs_score\"]) ; \n",
    "    oof_mean += res[\"oofs\"] / n_repeats\n",
    "\n",
    "print(f\"{bold}Final mean RMSE {bold_blue}{np.mean(blend_scores):.6f}{end}\")\n",
    "\n",
    "_, ax = plt.subplots(n_repeats, 1, figsize = (10, int(all_coefs[0].shape[1] * 0.5 * n_repeats)), \n",
    "                       sharex = True, tight_layout = True)\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    ax[i].boxplot(all_coefs[i], vert = False, labels = all_coefs[i].columns)\n",
    "    ax[i].axvline(x = 0, color = 'green')\n",
    "    ax[i].set_title(f\"Regression results over folds in repetition n° {i+1}\")\n",
    "    ax[i].set_xlabel(\"Coefficients values\")\n",
    "    ax[i].xaxis.set_ticks_position(\"top\")\n",
    "    ax[i].xaxis.set_label_position('top')\n",
    "    ax[i].spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "all_scores = {}\n",
    "ascending = True\n",
    "for r in range(n_repeats):\n",
    "    for m in final_models:\n",
    "        if r == 0:\n",
    "            all_scores[m] = []\n",
    "        all_scores[m].append(score_(train[target], oofs[r][m]))\n",
    "        \n",
    "all_scores[\"Ensemble\"] = blend_scores\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores)\n",
    "_col_order = list(all_scores.mean(axis=0).sort_values(ascending = ascending).index)\n",
    "all_scores = all_scores[_col_order]\n",
    "\n",
    "_t = list(all_scores.mean(axis=0).sort_values(ascending = ascending).values)\n",
    "_labels = [f\"{l:15} ({v:.5})\" for l,v in zip(_col_order, _t)]\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize = (10, int(all_scores.shape[1] * 1/2)))\n",
    "ax.boxplot(all_scores, vert = False, labels = _labels)\n",
    "ax.set_title(\"OOFS R2\")\n",
    "ax.set_xlabel(\"R2 (higher is better)\")\n",
    "ax.xaxis.set_ticks_position(\"top\")\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.spines[[\"right\", \"bottom\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "print(final_models)\n",
    "_oofs = oofs[0][final_models].copy()\n",
    "_preds = preds[0][final_models].copy()\n",
    "\n",
    "for m in final_models:\n",
    "    for n in range(n_repeats):\n",
    "        _oofs[m] += oofs[n][m] / n_repeats\n",
    "        _preds[m] += preds[n][m] / n_repeats\n",
    "    \n",
    "model = Ridge(**params)\n",
    "model.fit(_oofs, train[target])\n",
    "y_oof = model.predict(_oofs)\n",
    "print(f\"R2 score on train : {score_(train[target], y_oof):.6f}\")\n",
    "y_pred = pd.Series(model.predict(_preds), index = test.index, name = target)\n",
    "y_pred.to_csv(f\"submission_with_autogluon.csv\")\n",
    "!head submission_with_autogluon.csv\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize = (15, int(len(final_models) * 1/2)))\n",
    "sns.barplot(x = model.coef_, y = final_models, ax = ax, color = \"blue\")\n",
    "plt.gca().invert_yaxis()\n",
    "ax.axvline(x = 0, color = 'green')\n",
    "ax.xaxis.set_ticks_position(\"top\")\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.spines[[\"right\", \"bottom\"]].set_visible(False)\n",
    "ax.set_title(f\"Coefficient values with all mean of oofs files\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = n_splits, random_state = seed, shuffle = True)\n",
    "for fold, (_, val_idx) in enumerate(folds.split(train, (train[target]*400).astype(np.int16).astype(\"category\"))):\n",
    "    print(f\"   Fold {fold+1} : R2 {score_(train.loc[val_idx, target], oof_mean.loc[val_idx]):.6f}\")    \n",
    "\n",
    "print(f\"Mean of oof R2 score : {score_(train[target], oof_mean):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "oofs_other = pd.DataFrame(index = train.index)\n",
    "for m in final_models:\n",
    "    oofs_other[f\"{m}\"] = 0 \n",
    "    for r in range(n_repeats):\n",
    "        oofs_other[f\"{m}\"] += oofs[r][m] / n_repeats\n",
    "    \n",
    "oofs_other[target] = train[target]\n",
    "\n",
    "new_model = {\n",
    "    \"train\"       : oofs_other, \n",
    "    \"test\"        : preds[0], \n",
    "    \"features\"    : final_models,\n",
    "    \"my_model\"    : Ridge(**params), \n",
    "}\n",
    "_ = do_ensemble(**new_model, do_feat_imp = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Model_Train",
    "notebook_id": 30,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "blend_scores = []\n",
    "oof_mean2 = pd.Series(0.0, index = train.index, name= target)\n",
    "for r in range(n_repeats):\n",
    "    new_model = {\n",
    "        \"train\"       : oofs[r], \n",
    "        \"test\"        : preds[r], \n",
    "        \"features\"    : final_models,\n",
    "        \"my_model\"    : Ridge(**params), \n",
    "        \"folds\"       : StratifiedKFold(n_splits = n_splits, random_state = seed + 10, shuffle = True), \n",
    "    }\n",
    "    res = do_ensemble(**new_model, do_feat_imp = True)\n",
    "    all_intercepts.extend(res[\"intercept\"]) ; all_coefs.append(res[\"coefs\"])\n",
    "    blend_scores.append(res[\"oofs_score\"]) ; \n",
    "    oof_mean2 += res[\"oofs\"] / n_repeats\n",
    "    \n",
    "print(f\"{bold}Final mean RMSE {bold_blue}{np.mean(blend_scores):.6f}{end}\")\n",
    "print(f\"R2 score oof_mean {score_(train[target], oof_mean):.6f} | oof_mean2 {score_(train[target], oof_mean2):.6f} | \", end='')\n",
    "print(f\"oof_mean + oof_mean2 : {score_(train[target], .5 * (oof_mean + oof_mean2)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Model_Train",
    "notebook_id": 31,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# モデルの訓練\n",
    "_ = regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Model_Train",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 予測\n",
    "pred = regressor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": 20,
    "class": "Model_Train",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# 指定形式へ変換 (sample_submissionの\"Rings\"列を予測値で入替)\n",
    "sub[target] = pred\n",
    "sub.to_csv('submit.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Model_Train",
    "notebook_id": 32,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Model_Train",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 32,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model using training data\n",
    "y_pred = rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Model_Train",
    "notebook_id": 33,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "            \n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'n_estimators':2000, \n",
    "    'learning_rate' :  0.012,\n",
    "    'num_leaves' : 250, \n",
    "    'subsample_for_bin': 165700, \n",
    "    'min_child_samples': 114, \n",
    "    'reg_alpha': 2.075e-06, \n",
    "    'reg_lambda': 3.839e-07, \n",
    "    'colsample_bytree': 0.9634,\n",
    "    'subsample': 0.9592, \n",
    "    'max_depth': 10,\n",
    "    'random_state':0,\n",
    "    'verbosity':-1}\n",
    "\n",
    "lgbm = LGBMRegressor(**lgb_params)\n",
    "\n",
    "lgbm_model = lgbm.fit(X_train , Y_train)\n",
    "\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "\n",
    "lgbm_rmse_calculator = np.sqrt(mean_squared_error(np.log(Y_test), np.log(y_pred_lgbm)))\n",
    "lgbm_r2_metric = r2_score(Y_test, y_pred_lgbm)\n",
    "\n",
    "print(f\"Light Gradient Boosting RMSE Metric: {lgbm_rmse_calculator}\")\n",
    "print(f\"Light Gradient Boosting R-squared Metric: {lgbm_r2_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Model_Train",
    "notebook_id": 34,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Model_Train",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "clf = LassoCV()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score of the Lasso Regression model is: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Model_Train",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test = scaler.transform(df_test)\n",
    "y_pred_test = clf.predict(test).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Model_Train",
    "notebook_id": 34,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': df_test.index, 'FloodProbability': y_pred_test})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Model_Train",
    "notebook_id": 35,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load training and testing data from CSV files\n",
    "train_data = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop(columns=['FloodProbability'])\n",
    "y_train = train_data['FloodProbability']\n",
    "X_test = test_data\n",
    "\n",
    "# Handling missing values (consider other imputation methods)\n",
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "X_test.fillna(X_test.median(), inplace=True)\n",
    "\n",
    "# Normalizing features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape data for CNN (assuming 1D CNN)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2, padding='same'),  # Adjust padding strategy\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2, padding='same'),  # Adjust padding strategy\n",
    "    Conv1D(256, 3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2, padding='same'),  # Adjust padding strategy\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train = model.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(f\"R2 Score on Training Data: {r2_train:.4f}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({'id': test_data['id'], 'FloodProbability': y_test_pred.flatten()})\n",
    "\n",
    "# Save submission DataFrame to CSV\n",
    "submission_df.to_csv('submission_cnn.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Visualization",
    "notebook_id": 1,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df.corr(numeric_only=True),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Visualization",
    "notebook_id": 1,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Urbanization', y='FloodProbability', data=train)\n",
    "plt.title('Urbanization vs Flood Probability')\n",
    "plt.xlabel('Urbanization')\n",
    "plt.ylabel('Flood Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Visualization",
    "notebook_id": 2,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df[\"WetlandLoss\"], label=\"WetLandLoss feature\")\n",
    "s = np.random.poisson(5, df.shape[0])\n",
    "plt.hist(s, label=\"Poisson, lambda=5\", alpha=0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Visualization",
    "notebook_id": 4,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Plotting the distribution of each features for Train and Test\n",
    "ncol = 4\n",
    "nrow = int(np.ceil(len(orig_features) / 4))\n",
    "plt.figure(figsize=(ncol*3, nrow*2.5))\n",
    "for i,col in enumerate(orig_features):\n",
    "    ax = plt.subplot(nrow, ncol, i+1)\n",
    "    sb.countplot(train,x=col,ax=ax,palette='viridis')\n",
    "    sb.countplot(test,x=col,ax=ax,palette='autumn')\n",
    "    ax.set_title(col)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Visualization",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Checking the target distribution\n",
    "plt.figure(figsize=(8,2))\n",
    "sb.histplot(train[\"FloodProbability\"], kde=True, \\\n",
    "            bins=np.linspace(train[\"FloodProbability\"].min(), train[\"FloodProbability\"].max(), 88), color='r');\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Visualization",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# cheking the correlation\n",
    "plt.figure(figsize=(12,8))\n",
    "corr = train.iloc[:,1:].corr()\n",
    "mask = np.triu(np.ones_like(corr))\n",
    "sb.heatmap(corr, vmax=1, vmin=-1, center=0, mask=mask, annot=True, fmt='0.1f', cmap='inferno');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Visualization",
    "notebook_id": 4,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(7,4))\n",
    "sb.lineplot(pca.explained_variance_ratio_.cumsum())\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Visualization",
    "notebook_id": 6,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df[\"MonsoonIntensity\"],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": 19,
    "class": "Visualization",
    "notebook_id": 6,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'column' is the column you want to filter\n",
    "# Q1 = df.quantile(0.05)\n",
    "# Q3 = df.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# # Define bounds for what is considered an outlier\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# # Filter out outliers and keep only the valid values\n",
    "# df_filtered = (df >= lower_bound) & (df <= upper_bound)\n",
    "# test=(test>=lower_bound)&(test<=upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Visualization",
    "notebook_id": 10,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "columns = list(train_df.columns)[1:-1]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(len(columns)):\n",
    "    ax = plt.subplot(5, 4, i + 1)\n",
    "    sns.histplot(train_df[columns[i]], kde=True, ax=ax)\n",
    "    ax.set_xlabel(str(columns[i]).capitalize())\n",
    "    ax.grid(False)\n",
    "    \n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "fig.text(0.04, 0.5, 'Frequency', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "plt.tight_layout(rect=[0.05, 0, 1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 7,
    "class": "Visualization",
    "notebook_id": 10,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = train_df.drop(columns=['id']).corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Visualization",
    "notebook_id": 11,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    fig, ax = plt.subplots(figsize=(6,2))\n",
    "    max_val = round(train[col].max()) + 1\n",
    "    train[col].hist(density=True,bins = np.arange(0,max_val,1), ax=ax)\n",
    "    plt.xticks(np.arange(0,20,1))\n",
    "    plt.title(col)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Visualization",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "round(test.agg(['min','mean','median','max','var','std','skew']),2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Visualization",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr = train.drop('FloodProbability', axis=1).corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
    "\n",
    "sns.heatmap(corr, mask = mask,linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Visualization",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "corr = train.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
    "\n",
    "sns.heatmap(corr, mask = mask,linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Visualization",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "train.drop('FloodProbability', axis=1).plot(kind='box',vert=False)\n",
    "plt.title('Boxplot of train variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Visualization",
    "notebook_id": 11,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "test.plot(kind='box',vert=False)\n",
    "plt.title('Boxplot of test variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Visualization",
    "notebook_id": 13,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Plotting the Skewness of each column\n",
    "skewness_df = pd.DataFrame(skew).T\n",
    "skewness_df.columns = ['Skewness']\n",
    "\n",
    "skewness_df.plot(kind='bar', color='skyblue', figsize=(10, 6))\n",
    "plt.title('Skewness of Numeric Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Visualization",
    "notebook_id": 13,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4 * 5, 5 * 4))\n",
    "\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 5, i)\n",
    "    sns.countplot(data=data, x=col);\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Visualization",
    "notebook_id": 14,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(co_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Visualization",
    "notebook_id": 15,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=train_df['MonsoonIntensity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Visualization",
    "notebook_id": 15,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.scatter(y_test, lr_pred, alpha=.5)\n",
    "\n",
    "ax.set(xlabel='Ground truth', \n",
    "       ylabel='Predictions',\n",
    "       title='Flood Predictions vs Truth, using Linear Regression');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Visualization",
    "notebook_id": 16,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 120))\n",
    "countplot_idx = 1\n",
    "boxplot_idx = 2\n",
    "for column in cat_columns:\n",
    "    ax = plt.subplot(20, 2, countplot_idx)\n",
    "    sns.countplot(x=train_set[column], palette=\"rocket\", hue=train_set[column], dodge=False)\n",
    "    ax.set_title(f\"Count Plot of {column}\")\n",
    "    countplot_idx += 2\n",
    "    \n",
    "    plt.subplot(20, 2, boxplot_idx)\n",
    "    sns.boxplot(x=train_set[column])\n",
    "    plt.title(f'Box plot for {column}')\n",
    "    boxplot_idx += 2        \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Visualization",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_set[cat_columns].skew(), columns= [\"skew\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Visualization",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21,8))\n",
    "sns.heatmap(train_set.corr(), annot=True, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": 43,
    "class": "Visualization",
    "notebook_id": 16,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21,8))\n",
    "sns.heatmap(X[corr_more_02].join(y).corr(), annot=True, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 4,
    "class": "Visualization",
    "notebook_id": 17,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(flood_train.drop([\"id\", \"FloodProbability\"], axis = 1))\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": 17,
    "class": "Visualization",
    "notebook_id": 18,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Visualization",
    "notebook_id": 20,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 2,
    "class": "Visualization",
    "notebook_id": 21,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# histogram for all columns with seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for column in Data.columns:\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.histplot(Data[column])\n",
    "    plt.title(f\"Histogram of {column}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": 14,
    "class": "Visualization",
    "notebook_id": 22,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# Define a function that plots a count plot of the features\n",
    "def count_plot(df, col, re):\n",
    "    plt.subplot(df.shape[1], 1, re + 1)\n",
    "    sns.countplot(data = df, x = col, palette = palette)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('count')\n",
    "    plt.title(f'Count of the Values of the {col} Feature')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": 15,
    "class": "Visualization",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "for col_name, re in zip(X_train.columns, range(X_train.shape[1])):\n",
    "    plt.figure(figsize = (12, 50))\n",
    "    count_plot(X_train, col_name, re)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": 16,
    "class": "Visualization",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Define a cat plot of the features vs the flood probability\n",
    "def cat_plot(df, col, re):\n",
    "    sns.catplot(data = df, x = col, y = 'FloodProbability', kind = 'boxen', palette = palette)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('count')\n",
    "    plt.title(f'Categorical Plot for the Values of the {col} Feature vs. Flood Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": 18,
    "class": "Visualization",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Construct a triangular heatmap to study the correlation in the training data\n",
    "corr = train_df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, center=0, annot=True,\n",
    "            fmt='.2f', square=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 26,
    "class": "Visualization",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Construct a regression plot\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "for col_name, re in zip(features, range(len(features))):\n",
    "    plt.subplot(2, 2, re + 1)\n",
    "    sns.regplot(data = X_train_1, x = col_name, y = y_train)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel('flood probability')\n",
    "    plt.title(f'Flood Probability by {col_name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 27,
    "class": "Visualization",
    "notebook_id": 22,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "# Construct a triangular heat map\n",
    "train_new = pd.concat([X_train_1[features], y_train], axis = 1)\n",
    "\n",
    "corr = train_new.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, center=0, annot=True,\n",
    "            fmt='.2f', square=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": 0,
    "class": "Visualization",
    "notebook_id": 23,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": 9,
    "class": "Visualization",
    "notebook_id": 25,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "print(\"Test Histogramme\")\n",
    "sns.set(rc={'figure.figsize': (20, 16)})\n",
    "test.hist(color='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 10,
    "class": "Visualization",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cols_test = test.columns\n",
    "fig, ax = plt.subplots(nrows=len(cols_test)//3+1, ncols=3, figsize=(24,20), constrained_layout=True)\n",
    "ax = ax.ravel()\n",
    "for i,j in enumerate(cols_test):\n",
    "    sns.boxplot(train, ax = ax[i], x=test[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Visualization",
    "notebook_id": 25,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "cols_train = train.columns\n",
    "fig, ax = plt.subplots(nrows=len(cols_train)//3+1, ncols=3, figsize=(24,20), constrained_layout=True)\n",
    "ax = ax.ravel()\n",
    "for i,j in enumerate(cols_train):\n",
    "    sns.boxplot(train, ax = ax[i], x=train[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Visualization",
    "notebook_id": 26,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "k=0\n",
    "fig,ax=plt.subplots(nrows=7,ncols=3,figsize=(18,30))\n",
    "for i,fea in enumerate(NumCols):\n",
    "    if i==0:\n",
    "        j=0\n",
    "        k=0\n",
    "    elif i%3==0:\n",
    "        j=j+1\n",
    "        k=0\n",
    "    else:\n",
    "        k=k+1\n",
    "\n",
    "    ax[j,k].set_xlabel(fea)\n",
    "    sns.scatterplot(data=df_train,x=df_train[fea].value_counts(),y=df_train['FloodProbability'],ax=ax[j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": 13,
    "class": "Visualization",
    "notebook_id": 26,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(nrows=21,ncols=2,figsize=(8,80))\n",
    "for i,fea in enumerate(NumCols):\n",
    "    sns.distplot(df_train[fea],ax=ax[i,0])\n",
    "    sns.boxplot(df_train.iloc[:,i:i+1],ax=ax[i,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": 22,
    "class": "Visualization",
    "notebook_id": 28,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(y_reg)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": 31,
    "class": "Visualization",
    "notebook_id": 28,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(y=(dt_gen.sum(axis=1)),x=y_gen)\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('$\\sum$ features')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 6,
    "class": "Visualization",
    "notebook_id": 30,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "class FeatureImportance():\n",
    "    \n",
    "    def __init__(self, n_permutations = None, lib_metric = None, digit = 4):\n",
    "        \n",
    "        self.n_permutations = n_permutations\n",
    "        self.lib_metric = lib_metric\n",
    "        self.differences = {}\n",
    "        self.digit = digit\n",
    "        \n",
    "        self.metric_max = [\"Accuracy\", \"AUC\", \"Recall@20\", \"cohen_kappa_score\", \"auc\", \"f1\", \"R2\"]\n",
    "        self.metric_min = [\"Logloss\", \"rmse\", \"RMSE\", \"mae\", \"Balanced log loss\", \"RMSLE\"]\n",
    "        if lib_metric not in self.metric_max + self.metric_min:\n",
    "            raise ValueError(f\"Unknown lib_metric : {lib_metric}.\")\n",
    "        \n",
    "    def append(self, feature, metric_value, metric_ref):\n",
    "        \n",
    "        if feature not in self.differences.keys():\n",
    "            self.differences[feature] = []\n",
    "            \n",
    "        self.differences[feature].append(metric_value - metric_ref)\n",
    "        \n",
    "    def build_dataframe(self):\n",
    "        \n",
    "        if self.differences == {}: return\n",
    "        \n",
    "        df_diff = pd.DataFrame(self.differences).transpose()\n",
    "        df_diff[\"mean\"] = df_diff.mean(axis=1)\n",
    "        df_diff.sort_values(\"mean\", ascending = self.lib_metric in self.metric_max, inplace=True)\n",
    "        \n",
    "        return df_diff\n",
    "        \n",
    "    def plot(self, title=\"\"):\n",
    "        \n",
    "        if self.differences == {}: return\n",
    "        \n",
    "        df_diff = self.build_dataframe()\n",
    "        \n",
    "        fk = next(iter(self.differences))\n",
    "        len_fk = len(self.differences[fk])\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize = (15, int(df_diff.shape[0] * 1/2)))\n",
    "            \n",
    "        ax[0].boxplot(df_diff[[c for c in range(len_fk)]][::-1].T,\n",
    "                          vert=False, labels=df_diff.index[::-1])\n",
    "        ax[0].axvline(x = 0, color = 'green')\n",
    "        ax[0].set_xlabel(f\"Distribution {self.lib_metric} difference after permutation of values\")\n",
    "            \n",
    "        sns.barplot(x = \"mean\", y = df_diff.index, data = df_diff, ax = ax[1], color = \"green\")\n",
    "        ax[1].bar_label(ax[1].containers[0], fmt = f'%.{self.digit}f', padding = 2)\n",
    "        ax[1].set_xlabel(f\"Mean {self.lib_metric} difference after permutation of values\")\n",
    "        ax[1].set_yticklabels([])\n",
    "        ax[1].set_yticks([])\n",
    "        \n",
    "        for ax_ in ax:\n",
    "            ax_.set_title(title)\n",
    "            ax_.xaxis.set_ticks_position(\"top\")\n",
    "            ax_.xaxis.set_label_position('top')\n",
    "            ax_.spines[[\"right\", \"bottom\"]].set_visible(False)\n",
    "        ax[1].spines[[\"left\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11,
    "class": "Visualization",
    "notebook_id": 31,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "# 目的変数に対する説明変数の分布\n",
    "\n",
    "cat_features = [\n",
    "    \"MonsoonIntensity\",\n",
    "    \"TopographyDrainage\",\n",
    "    \"RiverManagement\",\n",
    "    \"Deforestation\",\n",
    "    \"Urbanization\",\n",
    "    \"ClimateChange\",\n",
    "    \"DamsQuality\",\n",
    "    \"Siltation\",\n",
    "    \"AgriculturalPractices\",\n",
    "    \"Encroachments\",\n",
    "    \"IneffectiveDisasterPreparedness\",\n",
    "    \"DrainageSystems\",\n",
    "    \"CoastalVulnerability\",\n",
    "    \"Landslides\",\n",
    "    \"Watersheds\",\n",
    "    \"DeterioratingInfrastructure\",\n",
    "    \"PopulationScore\",\n",
    "    \"WetlandLoss\",\n",
    "    \"InadequatePlanning\",\n",
    "    \"PoliticalFactors\",\n",
    "]\n",
    "target = \"FloodProbability\"\n",
    "\n",
    "fig, ax = plt.subplots(len(cat_features), 1, figsize=(25, 4*len(cat_features)), dpi=150)\n",
    "ax = ax.flatten()\n",
    "for i, ft in enumerate(cat_features):\n",
    "    sns.histplot(\n",
    "        data=train,\n",
    "        x=target,\n",
    "        hue=ft,\n",
    "        multiple='stack',\n",
    "        edgecolor='.3',\n",
    "        linewidth=.5,\n",
    "        log_scale=False,\n",
    "        ax=ax[i],\n",
    "    )\n",
    "    ax[i].get_legend().remove()\n",
    "fig.suptitle(f'Train Categorical Features vs {target}\\n\\n\\n', ha='center', fontweight='bold', fontsize=25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 12,
    "class": "Visualization",
    "notebook_id": 31,
    "start_cell": false
   },
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df, title_name):\n",
    "    corr = df.corr()\n",
    "    fig, axes = plt.subplots(figsize=(20, 15))\n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(corr, mask=mask, linewidths=.5, annot=True)\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation_heatmap(train, 'Train Dataset Correlation')\n",
    "plot_correlation_heatmap(test, 'Test Dataset Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 8,
    "class": "Visualization",
    "notebook_id": 32,
    "start_cell": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(train_data['FloodProbability'])\n",
    "plt.title('Boxplot of FloodProbability')\n",
    "plt.xlabel('FloodProbability')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "visualization": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
